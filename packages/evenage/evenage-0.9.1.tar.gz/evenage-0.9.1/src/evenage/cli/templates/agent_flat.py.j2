"""
{{ name|capitalize }} agent definition and worker entry point
"""
from __future__ import annotations

import asyncio
import os
from dotenv import load_dotenv
from evenage import Agent, WorkerRunner
from evenage.llms import gemini, openai

# Load .env file for non-Docker environments
load_dotenv()

{% if is_coordinator %}# Coordinator-specific tool (placeholder)
from tools.communication_tools import delegate_task  # noqa: F401
TOOLS = [delegate_task]
{% else %}# Example web tools
from tools.web_tools import web_search, scrape_url, extract_links  # noqa: F401
TOOLS = [web_search, scrape_url, extract_links]
{% endif %}

{{ name }} = Agent(
    name="{{ name }}",
    role="{{ role }}",
    goal="{{ goal }}",
    backstory="""{{ backstory }}""",
    llm=gemini(
        model=os.getenv("{{ model_env }}", "{{ model }}"),
        temperature={{ temperature }}
    ),
    tools=TOOLS,
    {% if is_coordinator %}is_coordinator=True,
    available_agents={{ available_agents }},
    {% endif %}max_retries={{ max_retries }},
    max_iterations={{ max_iterations }},
    {% if is_coordinator %}max_tool_calls=3,  # Coordinators should delegate, not call many tools
    {% else %}max_tool_calls=6,  # Researchers should be efficient with tool usage
    {% endif %}timeout={{ timeout }},
    instructions="""
{% if is_coordinator %}You are an orchestration coordinator that manages complex tasks by delegating to specialist agents.

## Your Role
You break down complex requests into subtasks and delegate them to the appropriate specialist agents.
You NEVER perform research, web searches, or data gathering yourself - you have specialist agents for that.

## Available Specialist Agents
- **researcher**: Expert at web research, finding information, scraping websites, and analyzing web content

## Delegation Strategy (SIMPLE & EFFICIENT!)
1. **Analyze the Request**: Understand what the user is asking for
2. **Delegate Once**: 
   - For most queries, ONE delegation to researcher is sufficient
   - Provide clear, specific instructions in the delegation
   - ALWAYS use `system_delegate_task` tool with researcher agent
3. **Wait for Response**: 
   - Delegation is blocking - you'll receive the full response immediately
   - The response will be in the 'result' field
4. **Synthesize & Finish**: 
   - Once you receive the response, format it nicely and finish immediately
   - Don't re-delegate the same question multiple times
   - Don't second-guess the specialist's work

## CRITICAL: Avoid Re-Delegation
⚠️ **DO NOT** delegate the same task multiple times!
- If the first delegation times out, wait for it to complete
- If you already delegated a task, DON'T delegate it again in the next iteration
- The system detects semantically similar delegations and skips them
- Check your iteration history before delegating

## Response Format
For delegation:
{
  "type": "tool",
  "tool": "system_delegate_task",
  "params": {
    "agent_name": "researcher",
    "task": "Your specific, detailed instructions here",
    "wait_for_response": true
  }
}

When ready to finish (after receiving delegation response):
{
  "type": "finish",
  "answer": "Your final synthesized response based on the specialist's findings"
}

Remember: You orchestrate, specialists execute. Delegate ONCE, wait, synthesize, finish. Keep it simple!
{% else %}You are a research specialist with expertise in web research, information gathering, and content analysis.

## Your Role
You perform deep research tasks using your web tools to find, extract, and analyze information from the internet.
You have direct access to web search, URL scraping, and link extraction tools.

## Available Tools
- **web_search(query)**: Search the web for information using a search query
  - Use this to find relevant sources, articles, and information
  - Provide clear, specific search queries
  - Returns search results with titles, URLs, and snippets

- **scrape_url(url)**: Extract full content from a specific webpage
  - Use this to get detailed content from promising URLs
  - Returns the full text content of the page
  - Best for in-depth analysis of specific sources

- **extract_links(url)**: Get all links from a webpage
  - Use this to discover related resources
  - Returns a list of all URLs found on the page
  - Useful for finding additional relevant sources

## Research Strategy (BE EFFICIENT!)
1. **Understand the Query**: Analyze what information is needed
2. **Single Targeted Search**: 
   - Start with ONE well-crafted web_search query
   - Choose the most comprehensive, specific search terms
3. **Selective Deep Dive**: 
   - Pick the TOP 1-2 most promising URLs from search results
   - Use scrape_url ONLY on these highest-quality sources
   - Avoid scraping multiple similar sources
4. **Quick Synthesis**: 
   - Combine findings from your limited sources
   - Provide clear, accurate answers with source citations
5. **Finish Promptly**: 
   - Return comprehensive results after 2-4 tool calls maximum
   - Don't over-research - sufficient information is enough

## Quality Over Quantity
- ⚠️ CRITICAL: You have a limited tool budget (typically 6 calls)
- One great search + 1-2 quality scrapes > many mediocre attempts
- If initial search yields good results, scrape the best source and FINISH
- Don't waste calls on extract_links unless specifically needed
- Don't scrape sites that return errors (403, timeouts) - move on immediately

## Response Format
Use JSON action format for tool calls:
{
  "type": "tool",
  "tool": "web_search",
  "params": {
    "query": "your highly specific search query here"
  }
}

When finished (after 2-4 tool calls):
{
  "type": "finish",
  "answer": "Your comprehensive research findings with sources (URLs included)"
}

Remember: Efficiency is key. Find the best sources quickly and finish promptly.
{% endif %}
    """,
    # Artifact retrieval guidance:
    # - When delegating with wait_for_response=True, the 'response' typically contains the full result inline.
    # - Only use artifact retrieval tools when the response explicitly indicates data was stored and provides
    #   an artifact reference (e.g., artifact_id or bucket/key).
    # Tracing control: set trace_enabled=False to disable all traces for this agent
    # or use trace_mask to exclude specific event types like ["llm_call", "tool_result"]
    trace_enabled=True,
    trace_mask=[],  # Example: ["llm_call"] to skip LLM traces
)


# Worker entry point
async def main():
    """Run this agent as a worker."""
    runner = WorkerRunner(agent={{ name }})
    print(f"Starting {{ name }} worker...")
    await runner.start()


if __name__ == "__main__":
    asyncio.run(main())


# Current RAG Ingestion Strategy

## **ðŸ§­ Overview**

This document explains the current file ingestion strategy used in theÂ **Amini Ingestion KGraph**Â system.

The pipeline converts multiple file types (PDF, DOCX, XLS, XLSX) into markdown format and processes them throughÂ **LightRAG**Â for knowledge graph construction.

**Purpose**:

Serves as a reference for the â€œMultimodal Data Ingestionâ€ TRD project to understand and reuse the ingestion mechanisms.

### Remember

The Multimodal Data Ingestion responsibility here is just the conversion to Markdown, update the Knowledge Graph, this is with [**ðŸ“˜**Â Amini RAG](https://www.notion.so/Amini-RAG-28efd2e0589a809da984df12e4c5fe4d?pvs=21) 

---

## **ðŸ§° Libraries Used**

### **ðŸ“š Document Processing Libraries**

| **Library** | **Version** | **Precision Level** | **Purpose** | **File Types** | **Speed** |
| --- | --- | --- | --- | --- | --- |
| **docling** | 2.34.0 | Level 4 | Highest-quality conversion | PDF, DOCX, XLSX, XLS | ðŸ¢ Slowest (45sâ€“3600s) |
| **pymupdf4llm** | â‰¥0.0.5 | Level 2 | LLM-optimized markdown extraction (default) | PDF | âš™ï¸ Medium (0.5sâ€“35.7s) |
| **pdfplumber** | â‰¥0.7.0 | Level 3 | Table extraction | PDF | ðŸŒ Slow (1.2sâ€“120s) |
| **PyMuPDF (fitz)** | â‰¥1.23.0 | Level 1 | Fast parallel PDF text extraction | PDF | âš¡ Fastest (0.1sâ€“4.2s) |

### **ðŸ§  Knowledge Graph & Storage**

| **Library** | **Version** | **Purpose** |
| --- | --- | --- |
| **lightrag_hku** | 1.3.7 | Knowledge graph construction |
| **nano-vectordb** | â‰¥0.0.4.3 | Vector database for embeddings |
| **asyncpg** | 0.30.0 | Async PostgreSQL driver |
| **sqlalchemy** | 2.0.36 | ORM with async support |

### **ðŸ¤– LLM Integration**

| **Library** | **Version** | **Purpose** |
| --- | --- | --- |
| **openai** | â‰¥1.91.0 | LLM and embedding API integration |

---

## **ðŸ”„ High-Level Ingestion Pipeline**

```mermaid
flowchart TD
    A[ðŸ“¤ Phase 1: Upload & Validation] --> B[ðŸ§¾ Phase 2: Task Creation]
    B --> C[âš™ï¸ Phase 3: Background Processing]
    C --> D[ðŸ§© Phase 4: Document Conversion]
    D --> E[ðŸ§  Phase 5: Knowledge Graph Insertion]
    E --> F[âœ… Phase 6: Task Completion]
```

---

## **âš™ï¸ Detailed Phase Breakdown**

### **Phase 1 â€“ Upload & Validation**

**Files:**Â routers/v1/documents.py,Â services/document_service.py

1. File uploaded viaÂ /api/v1/projects/{slug}/documents/upload
2. Temporarily stored
3. SHA-256 hash for deduplication
4. Validation of format and readability

### **Phase 2 â€“ Task Creation & Queuing**

**File:**Â services/task_service.py

- Creates task with statusÂ **PENDING**
- Saves metadata:Â project_id,Â task_id,Â file_path,Â precision_level,Â callback_url

### **Phase 3 â€“ Background Processing (Worker)**

**File:**Â services/task_worker.py

- Polls DB for pending tasks every 5s
- Atomically claims and marks asÂ **PROCESSING**
- InvokesÂ DocumentProcessingService.process_single_document()

### **Phase 4 â€“ Document Conversion**

**Files:**Â services/document_conversion/*

1. Check deduplication by hash
2. Select converter based on precision level
3. Convert â†’ Markdown
4. Compute quality score (0â€“1.0)

**Selection Logic:**

```python
if has_tables:
    use PDFPlumber (Level 3)
elif file_size > 20MB:
    use ChunkedParallel (Level 1)
elif file_size < 2MB:
    use Docling (Level 4)
else:
    use PyMuPDF4LLM (Level 2)
```

**Fallback Order:**Â Level 2 â†’ Level 1 â†’ Level 3 â†’ Fail

---

## **ðŸ§© Knowledge Graph Insertion**

**File:**Â services/lightrag_service.py

- Markdown passed toÂ LightRAG.ainsert()
- Performs chunking, entity & relationship extraction, embedding, and graph construction
- Stores results in PostgreSQL (pgvector + AGE graph)

---

## **ðŸ“ File Type Handling**

| **File Type** | **Converters** | **Best Level** | **Notes** |
| --- | --- | --- | --- |
| PDF | All 4 | 2 | Fully supported |
| DOCX | Docling | 4 | Falls back on error |
| XLSX/XLS | Docling | 4 | Spreadsheet support |

---

## **ðŸ§¾ Markdown Conversion Strategy**

### **Why Markdown?**

- âœ… Preserves document structure
- ðŸ§  LLM-friendly syntax
- ðŸ” Improves entity extraction
- ðŸ”„ Consistent output format

---

## **ðŸ§® Quality Scoring**

Calculated inÂ base.pyÂ using:

```
Content Length (25%)
Structure (30%)
Formatting (20%)
Overall Content (25%)
â†’ Final = min(sum, 1.0)
```

---

## **ðŸ§  LightRAG Integration**

### **Data Flow**

```
Markdown â†’ LightRAG
  â†’ Chunking
  â†’ Entity Extraction
  â†’ Relationship Extraction
  â†’ Embedding Generation
  â†’ PostgreSQL Storage
```

**Multi-Project Isolation:**

Each project uses its own namespaced storage (project_{id}_entities_vdb, etc.)

---

## **ðŸ§© Key Design Decisions**

1. **Strategy Pattern**Â â€“ Easy extension of converters
2. **Markdown Intermediate**Â â€“ Consistent, LLM-friendly
3. **PostgreSQL for All Storage**Â â€“ ACID + multi-tenant safety
4. **Per-Project Isolation**Â â€“ No data leakage
5. **Deduplication by Hash**Â â€“ Save compute cost

---

## **âš¡ Performance Characteristics**

```
Level 1: 0.1sâ€“4.2s
Level 2: 0.5sâ€“35.7s (default)
Level 3: 1.2sâ€“120s
Level 4: 45sâ€“3600s
```

| **File Size** | **L1** | **L2** | **L3** | **L4** |
| --- | --- | --- | --- | --- |
| 200 KB | 0.1s | 0.5s | 1.2s | 45s |
| 1.2 MB | 0.3s | 2.1s | 5.2s | 180s |
| 3.2 MB | 1.8s | 8.4s | 25.1s | 900s |
| 13 MB | 4.2s | 35.7s | 120s | 3600s |

---

## **ðŸ§ª Example: Processing a PDF**

**API Flow**

```
POST /api/v1/projects/research/documents/upload
â†’ file: research-paper.pdf
â†’ precision_level: 2
â†’ callback_url: https://example.com/webhook
â†’ Returns: task_id = "task-xyz-789"
```

**Processing Flow**

1. File saved â†’ hashed â†’ task created
2. Worker polls â†’ claims task
3. Converts using Level 2 (PyMuPDF4LLM)
4. LightRAG extracts entities â†’ stores in PostgreSQL
5. Task markedÂ **COMPLETED**, webhook sent

---

## **ðŸš¨ Error Handling & Recovery**

- **Conversion fallback:**Â 2 â†’ 1 â†’ 3 â†’ legacy
- **Retries:**Â on failure, task marked FAILED; can retry via API
- **Timeouts:**Â per-storage safeguards
- **Logging:**Â detailed error context

---

## **ðŸ—‚ï¸ File Location Reference**

```
src/amini_ingestion_kgraph/services/
â”œâ”€â”€ document_conversion/
â”‚   â”œâ”€â”€ converters/
â”‚   â”‚   â”œâ”€â”€ chunked_parallel.py
â”‚   â”‚   â”œâ”€â”€ pymupdf4llm.py
â”‚   â”‚   â”œâ”€â”€ pdfplumber.py
â”‚   â”‚   â””â”€â”€ docling.py
â”œâ”€â”€ document_service.py
â”œâ”€â”€ lightrag_service.py
â”œâ”€â”€ task_service.py
â”œâ”€â”€ task_worker.py
â””â”€â”€ query_service.py
```

---

## **ðŸ’¡ Reuse in Multimodal Ingestion TRD**

| **Mechanism** | **Reusability** | **Possible Extension** |
| --- | --- | --- |
| Multi-Format Support | âœ… | Add image/audio/video |
| Markdown Intermediate | âœ… | Add multimodal embeds |
| Background Worker | âœ… | Long-running tasks |
| Multi-Tenant Isolation | âœ… | Extend to all media |
| Deduplication | âœ… | Cross-modal |
| Quality Scoring | âœ… | Adapt to multimodal |

---

## **ðŸ§¾ Summary**

TheÂ **Amini Ingestion KGraph**Â pipeline provides:

1. Flexible multi-level conversion
2. Uniform markdown structure
3. Robust PostgreSQL + LightRAG integration
4. Scalable async worker architecture
5. Fault-tolerant recovery
6. Per-project deduplication and isolation

**Key Insight**:

Markdown is the semantic bridge between raw data and LLM understanding.

---
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PItyy_S1W3U","outputId":"2a6fab21-3bd2-4c23-8027-af16f7bdc283"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Frequent Itemsets ===\n","{'A'} : Support = 0.8\n","{'E'} : Support = 0.4\n","{'B'} : Support = 0.6\n","{'C'} : Support = 0.6\n","{'B', 'E'} : Support = 0.4\n","{'C', 'A'} : Support = 0.6\n","{'B', 'A'} : Support = 0.4\n","{'C', 'B'} : Support = 0.4\n","{'C', 'B', 'A'} : Support = 0.4\n","\n","=== Strong Association Rules (Confidence â‰¥ 0.7) ===\n","{'E'} â†’ {'B'} (Confidence = 1.0)\n","{'B', 'A'} â†’ {'C'} (Confidence = 1.0)\n","{'C', 'B'} â†’ {'A'} (Confidence = 1.0)\n","{'A'} â†’ {'C'} (Confidence = 0.75)\n","{'C'} â†’ {'A'} (Confidence = 1.0)\n"]}],"source":["from itertools import combinations  # Used to generate item combinations\n","\n","# ðŸ§© Step 1: Input Dataset\n","transactions = [\n","    ['A', 'B', 'C'],\n","    ['A', 'C'],\n","    ['A', 'D'],\n","    ['B', 'E'],\n","    ['A', 'B', 'C', 'E']\n","]\n","\n","# Minimum thresholds for support and confidence\n","min_support = 0.4      # 40%\n","min_confidence = 0.7   # 70%\n","\n","# ðŸ“Š Step 2: Function to calculate support of an itemset\n","def get_support(itemset, transactions):\n","    count = sum(1 for t in transactions if itemset.issubset(t))  # Count transactions containing the itemset\n","    return count / len(transactions)  # Support = count / total transactions\n","\n","# âš™ï¸ Step 3: Function to generate candidate itemsets of size k\n","def generate_candidates(freq_sets, k):\n","    # Combine itemsets to create larger ones of size k\n","    return {i | j for i in freq_sets for j in freq_sets if len(i | j) == k}\n","\n","# ðŸ” Step 4: Filter itemsets that meet minimum support\n","def get_frequent_itemsets(candidates, transactions, min_support):\n","    freq_sets, support_data = set(), {}  # Store frequent sets and their supports\n","    for itemset in candidates:\n","        support = get_support(itemset, transactions)  # Calculate support\n","        if support >= min_support:  # Keep only those above threshold\n","            freq_sets.add(itemset)\n","        support_data[itemset] = support  # Store all supports\n","    return freq_sets, support_data\n","\n","# ðŸš€ Step 5: Main Apriori function\n","def apriori(transactions, min_support):\n","    # Start with all single items\n","    single_items = {frozenset([i]) for t in transactions for i in t}\n","\n","    # Get frequent 1-itemsets\n","    freq_sets, support_data = get_frequent_itemsets(single_items, transactions, min_support)\n","\n","    all_freq_sets, all_support = set(freq_sets), dict(support_data)  # To store all frequent sets\n","    k = 2  # Start combining into 2-itemsets\n","\n","    # Generate higher-order frequent itemsets\n","    while freq_sets:\n","        candidates = generate_candidates(freq_sets, k)  # Make new candidates\n","        freq_sets, item_support = get_frequent_itemsets(candidates, transactions, min_support)\n","        all_freq_sets |= freq_sets  # Add to global frequent sets\n","        all_support.update(item_support)  # Update support data\n","        k += 1\n","\n","    return all_freq_sets, all_support\n","\n","# ðŸ”— Step 6: Generate strong association rules\n","def generate_rules(freq_sets, support_data, min_confidence):\n","    rules = []\n","    for itemset in freq_sets:\n","        if len(itemset) > 1:  # Only for sets with 2+ items\n","            for consequent in map(frozenset, combinations(itemset, 1)):  # Try all possible consequents\n","                antecedent = itemset - consequent\n","                confidence = support_data[itemset] / support_data[antecedent]  # Calculate confidence\n","                if confidence >= min_confidence:\n","                    rules.append((set(antecedent), set(consequent), confidence))  # Store rule\n","    return rules\n","\n","# â–¶ï¸ Step 7: Execute Apriori\n","freq_sets, support_data = apriori(transactions, min_support)\n","rules = generate_rules(freq_sets, support_data, min_confidence)\n","\n","# ðŸ–¨ï¸ Step 8: Output results\n","print(\"=== Frequent Itemsets ===\")\n","for item, sup in support_data.items():\n","    if sup >= min_support:\n","        print(f\"{set(item)} : Support = {round(sup, 2)}\")\n","\n","print(\"\\n=== Strong Association Rules (Confidence â‰¥ 0.7) ===\")\n","for ant, con, conf in rules:\n","    print(f\"{ant} â†’ {con} (Confidence = {round(conf, 2)})\")\n"]},{"cell_type":"code","source":["import pandas as pd\n","from mlxtend.frequent_patterns import apriori, association_rules\n","\n","# Step 1: Dataset\n","dataset = [\n","    ['Milk', 'Bread', 'Butter'],\n","    ['Bread', 'Eggs'],\n","    ['Milk', 'Bread', 'Eggs', 'Butter'],\n","    ['Bread', 'Butter'],\n","    ['Milk', 'Eggs']\n","]\n","\n","# Step 2: Convert transactions into a DataFrame\n","items = sorted(list(set([item for t in dataset for item in t])))  # Unique list of all items\n","encoded_vals = []\n","\n","for transaction in dataset:\n","    encoded = {item: (item in transaction) for item in items}  # Encode each transaction as True/False\n","    encoded_vals.append(encoded)\n","\n","df = pd.DataFrame(encoded_vals)\n","\n","# Step 3: Apply Apriori Algorithm\n","frequent_itemsets = apriori(df, min_support=0.4, use_colnames=True)\n","\n","# Step 4: Generate Association Rules\n","rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n","\n","# Step 5: Display Results\n","print(\"=== Frequent Itemsets ===\")\n","print(frequent_itemsets)\n","\n","print(\"\\n=== Association Rules ===\")\n","print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zlkRMl492xkX","outputId":"f44e2351-ed49-4b3e-c7e6-b6785ad5d94e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Frequent Itemsets ===\n","   support               itemsets\n","0      0.8                (Bread)\n","1      0.6               (Butter)\n","2      0.6                 (Eggs)\n","3      0.6                 (Milk)\n","4      0.6        (Bread, Butter)\n","5      0.4          (Bread, Eggs)\n","6      0.4          (Bread, Milk)\n","7      0.4         (Milk, Butter)\n","8      0.4           (Milk, Eggs)\n","9      0.4  (Bread, Milk, Butter)\n","\n","=== Association Rules ===\n","      antecedents consequents  support  confidence      lift\n","0         (Bread)    (Butter)      0.6        0.75  1.250000\n","1        (Butter)     (Bread)      0.6        1.00  1.250000\n","2   (Bread, Milk)    (Butter)      0.4        1.00  1.666667\n","3  (Butter, Milk)     (Bread)      0.4        1.00  1.250000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}]}]}
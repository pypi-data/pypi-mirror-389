# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

import typing_extensions

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.agent_data import AgentData
from ...types.api_key import ApiKey
from ...types.api_key_query_response import ApiKeyQueryResponse
from ...types.api_key_type import ApiKeyType
from ...types.batch_file_status import BatchFileStatus
from ...types.batch_item_list_response import BatchItemListResponse
from ...types.batch_job_cancel_response import BatchJobCancelResponse
from ...types.batch_job_response import BatchJobResponse
from ...types.batch_job_status_response import BatchJobStatusResponse
from ...types.batch_job_type import BatchJobType
from ...types.delete_response import DeleteResponse
from ...types.directory_file_query_response import DirectoryFileQueryResponse
from ...types.directory_file_response import DirectoryFileResponse
from ...types.directory_query_response import DirectoryQueryResponse
from ...types.directory_response import DirectoryResponse
from ...types.file import File
from ...types.file_create import FileCreate
from ...types.file_filter import FileFilter
from ...types.file_query_response import FileQueryResponse
from ...types.filter_operation import FilterOperation
from ...types.http_validation_error import HttpValidationError
from ...types.item_processing_results_response import ItemProcessingResultsResponse
from ...types.llama_parse_parameters import LlamaParseParameters
from ...types.paginated_response_agent_data import PaginatedResponseAgentData
from ...types.paginated_response_aggregate_group import PaginatedResponseAggregateGroup
from ...types.paginated_response_quota_configuration import PaginatedResponseQuotaConfiguration
from ...types.paginated_response_spreadsheet_job import PaginatedResponseSpreadsheetJob
from ...types.parse_configuration import ParseConfiguration
from ...types.parse_configuration_create import ParseConfigurationCreate
from ...types.parse_configuration_filter import ParseConfigurationFilter
from ...types.parse_configuration_query_response import ParseConfigurationQueryResponse
from ...types.presigned_url import PresignedUrl
from ...types.spreadsheet_job import SpreadsheetJob
from ...types.spreadsheet_parsing_config import SpreadsheetParsingConfig
from ...types.spreadsheet_result_type import SpreadsheetResultType
from .types.batch_job_create_request_job_config import BatchJobCreateRequestJobConfig

try:
    import pydantic
    if pydantic.__version__.startswith("1."):
        raise ImportError
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class BetaClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def create_agent_data(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        data: typing.Dict[str, typing.Any],
        deployment_name: str,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].

            - deployment_name: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_agent_data(
            data={"string": {}},
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"data": data, "deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        count: typing.Optional[bool] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        first: typing.Optional[bool] = OMIT,
        group_by: typing.Optional[typing.List[str]] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to aggregate data for

            - count: typing.Optional[bool].

            - deployment_name: str. The agent deployment's name to aggregate data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - first: typing.Optional[bool].

            - group_by: typing.Optional[typing.List[str]].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if count is not OMIT:
            _request["count"] = count
        if filter is not OMIT:
            _request["filter"] = filter
        if first is not OMIT:
            _request["first"] = first
        if group_by is not OMIT:
            _request["group_by"] = group_by
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:aggregate"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAggregateGroup, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to delete from

            - deployment_name: str. The agent deployment's name to delete data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:delete"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to search within

            - deployment_name: str. The agent deployment's name to search within

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - include_total: typing.Optional[bool]. Whether to include the total number of items in the response

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        if include_total is not OMIT:
            _request["include_total"] = include_total
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:search"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_agent_data(
            item_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data: typing.Dict[str, typing.Any],
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_agent_data(
            item_id="string",
            data={"string": {}},
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"data": data}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_agent_data(
            item_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_api_keys(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        key_type: typing.Optional[ApiKeyType] = None,
    ) -> ApiKeyQueryResponse:
        """
        List API keys.

        If project_id is provided, validates user has access to that project.
        If project_id is not provided, scopes results to the current user.

        Args:
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by API key name
        project_id: Filter by project ID
        key_type: Filter by key type

        Returns:
        Paginated response with API keys

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - project_id: typing.Optional[str].

            - key_type: typing.Optional[ApiKeyType].
        ---
        from llama_cloud import ApiKeyType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_api_keys(
            key_type=ApiKeyType.USER,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/api-keys"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "project_id": project_id,
                    "key_type": key_type,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKeyQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_api_key(
        self,
        *,
        key_type: typing.Optional[ApiKeyType] = OMIT,
        name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[str] = OMIT,
    ) -> ApiKey:
        """
        Create a new API key.

        If project_id is specified, validates user has admin permissions for that project.

        Args:
        api_key_create: API key creation data
        user: Current user
        db: Database session

        Returns:
        The created API key with the secret key visible in redacted_api_key field

        Parameters:
            - key_type: typing.Optional[ApiKeyType].

            - name: typing.Optional[str].

            - project_id: typing.Optional[str].
        ---
        from llama_cloud import ApiKeyType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_api_key(
            key_type=ApiKeyType.USER,
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if key_type is not OMIT:
            _request["key_type"] = key_type
        if name is not OMIT:
            _request["name"] = name
        if project_id is not OMIT:
            _request["project_id"] = project_id
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/api-keys"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKey, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_api_key(self, api_key_id: str) -> ApiKey:
        """
        Get an API key by ID.

        Args:
        api_key_id: The ID of the API key
        user: Current user
        db: Database session

        Returns:
        The API key

        Parameters:
            - api_key_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_api_key(
            api_key_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/api-keys/{api_key_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKey, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_api_key(self, api_key_id: str) -> None:
        """
        Delete an API key.

        If the API key belongs to a project, validates user has admin permissions for that project.
        If the API key has no project, validates it belongs to the current user.

        Args:
        api_key_id: The ID of the API key to delete
        user: Current user
        db: Database session

        Parameters:
            - api_key_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_api_key(
            api_key_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/api-keys/{api_key_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_batch_job(
        self,
        *,
        continue_as_new_threshold: typing.Optional[int] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        item_ids: typing.Optional[typing.List[str]] = OMIT,
        job_config: BatchJobCreateRequestJobConfig,
        page_size: typing.Optional[int] = OMIT,
        project_id: typing.Optional[str] = OMIT,
    ) -> BatchJobResponse:
        """
        Create a new batch processing job for a directory.

        This endpoint creates a batch job that will process all files in the specified directory
        using a Temporal workflow. The job configuration determines what processing will be performed.

        Args:
        payload: Job configuration including directory_id, job_config, and workflow settings
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobResponse with job details and workflow ID

        Raises:
        HTTPException: If directory not found or user lacks permissions

        Example Request Body:
        `json { "directory_id": "dir_123", "job_config": { "job_name": "PARSE_RAW_FILE", "parameters": { "type": "PARSE", "parsing_instruction": "Extract all tables" } }, "page_size": 100, "continue_as_new_threshold": 1000 } `

        Parameters:
            - continue_as_new_threshold: typing.Optional[int].

            - directory_id: typing.Optional[str].

            - item_ids: typing.Optional[typing.List[str]].

            - job_config: BatchJobCreateRequestJobConfig. Job configuration for batch processing. Can be BatchParseJobRecordCreate or ClassifyJob.

            - page_size: typing.Optional[int]. Number of files to fetch per batch from the directory (only used in directory mode)

            - project_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_batch_job()
        """
        _request: typing.Dict[str, typing.Any] = {"job_config": job_config}
        if continue_as_new_threshold is not OMIT:
            _request["continue_as_new_threshold"] = continue_as_new_threshold
        if directory_id is not OMIT:
            _request["directory_id"] = directory_id
        if item_ids is not OMIT:
            _request["item_ids"] = item_ids
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if project_id is not OMIT:
            _request["project_id"] = project_id
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_item_processing_results(
        self, item_id: str, *, job_type: typing.Optional[BatchJobType] = None
    ) -> ItemProcessingResultsResponse:
        """
        Get all processing results for a specific item (lineage query).

        Shows complete processing history including what operations have been performed,
        with what parameters, and where outputs are stored. Useful for understanding
        what processing has already been done to avoid redundant work.

        Args:
        item_id: ID of the item (file) to query
        job_type: Optional filter to show only specific processing type
        user: Authenticated user making the request
        db: Database session

        Returns:
        ItemProcessingResultsResponse with all processing operations for this item

        Raises:
        HTTPException: If item not found or user lacks permissions

        Parameters:
            - item_id: str.

            - job_type: typing.Optional[BatchJobType]. Filter results by job type
        ---
        from llama_cloud import BatchJobType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_item_processing_results(
            item_id="string",
            job_type=BatchJobType.PARSE,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/batch-processing/items/{item_id}/processing-results",
            ),
            params=remove_none_from_dict({"job_type": job_type}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ItemProcessingResultsResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_batch_job_status(self, job_id: str) -> BatchJobStatusResponse:
        """
        Get detailed status of a batch processing job.

        Returns current progress, file counts, and estimated completion time.

        Args:
        job_id: ID of the batch job
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobStatusResponse with job details and progress information

        Raises:
        HTTPException: If job not found or user lacks permissions

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_batch_job_status(
            job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def cancel_batch_job(self, job_id: str, *, reason: typing.Optional[str] = OMIT) -> BatchJobCancelResponse:
        """
        Cancel a running batch processing job.

        Stops spawning new item processing tasks immediately. Items currently being
        processed will complete. Essential for cost control if a job was started in error.

        Args:
        job_id: ID of the batch job to cancel
        payload: Cancellation request with optional reason
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobCancelResponse with final job statistics

        Raises:
        HTTPException: If job not found, already completed, or user lacks permissions

        Parameters:
            - job_id: str.

            - reason: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.cancel_batch_job(
            job_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if reason is not OMIT:
            _request["reason"] = reason
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/cancel"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobCancelResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_batch_job_items(
        self,
        job_id: str,
        *,
        status: typing.Optional[BatchFileStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
    ) -> BatchItemListResponse:
        """
        List items in a batch job with optional status filtering.

        Useful for finding failed items, viewing completed items, or debugging issues.
        Results are paginated for performance.

        Args:
        job_id: ID of the batch job
        status_filter: Optional filter by item status
        limit: Maximum number of items to return (1-1000)
        offset: Number of items to skip for pagination
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchItemListResponse with paginated item details

        Raises:
        HTTPException: If job not found or user lacks permissions

        Parameters:
            - job_id: str.

            - status: typing.Optional[BatchFileStatus]. Filter items by status

            - limit: typing.Optional[int]. Maximum number of items to return

            - offset: typing.Optional[int]. Number of items to skip
        ---
        from llama_cloud import BatchFileStatus
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_batch_job_items(
            job_id="string",
            status=BatchFileStatus.PENDING,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/items"
            ),
            params=remove_none_from_dict({"status": status, "limit": limit, "offset": offset}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchItemListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_directories(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryQueryResponse:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - name: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_directories()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "name": name,
                    "data_source_id": data_source_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_directory(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        name: str,
    ) -> DirectoryResponse:
        """
        Create a new directory within the specified project.

        If data_source_id is provided, validates that the data source exists
        and belongs to the same project.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: str. Human-readable name for the directory.
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_directory(
            name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if data_source_id is not OMIT:
            _request["data_source_id"] = data_source_id
        if description is not OMIT:
            _request["description"] = description
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryResponse:
        """
        Retrieve a directory by its identifier.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_directory(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Permanently delete a directory.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_directory(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        description: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
    ) -> DirectoryResponse:
        """
        Update directory metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_directory(
            directory_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if description is not OMIT:
            _request["description"] = description
        if name is not OMIT:
            _request["name"] = name
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        display_name_contains: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryFileQueryResponse:
        """
        List all files within the specified directory with optional filtering and pagination.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - display_name_contains: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - file_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_directory_files(
            directory_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "display_name": display_name,
                    "display_name_contains": display_name_contains,
                    "unique_id": unique_id,
                    "file_id": file_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_directory_file(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        file_id: str,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Create a new file within the specified directory.

        The directory must exist and belong to the project passed in.
        The file_id must be provided and exist in the project.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - file_id: str. File ID for the storage location (required).

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.add_directory_file(
            directory_id="string",
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryFileResponse:
        """
        Get a file by its directory_file_id within the specified directory. If you're trying to get a file by its unique_id, use the list endpoint with a filter instead.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Delete a file from the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to delete a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Update file metadata within the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to update a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: FileCreate,
    ) -> File:
        """
        Create a new file in the project.

        Args:
        file_create: File creation data
        project: Validated project from dependency
        db: Database session

        Returns:
        The created file

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: FileCreate.
        ---
        from llama_cloud import FileCreate
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_file(
            request=FileCreate(
                name="string",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(File, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upsert_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: FileCreate,
    ) -> File:
        """
        Upsert a file (create or update if exists) in the project.

        Args:
        file_create: File creation/update data
        project: Validated project from dependency
        db: Database session

        Returns:
        The upserted file

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: FileCreate.
        ---
        from llama_cloud import FileCreate
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.upsert_file(
            request=FileCreate(
                name="string",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(File, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> FileQueryResponse:
        """
        Query files with flexible filtering and pagination.

        Args:
        request: The query request with filters and pagination
        project: Validated project from dependency
        db: Database session

        Returns:
        Paginated response with files

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[FileFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import FileFilter
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.query_files(
            filter=FileFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_file(
        self, file_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a single file from the project.

        Args:
        file_id: The ID of the file to delete
        project: Validated project from dependency
        db: Database session

        Returns:
        None (204 No Content on success)

        Parameters:
            - file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_file(
            file_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by configuration name
        creator: Filter by creator
        version: Filter by version

        Returns:
        Paginated response with parse configurations

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - creator: typing.Optional[str].

            - version: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_parse_configurations()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "creator": creator,
                    "version": version,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: ParseConfigurationCreate,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: ParseConfigurationCreate.
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParseConfigurationCreate,
            ParsingMode,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_parse_configuration(
            request=ParseConfigurationCreate(
                name="string",
                parameters=LlamaParseParameters(
                    parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                    priority=LlamaParseParametersPriority.LOW,
                    replace_failed_page_mode=FailPageMode.RAW_TEXT,
                ),
                version="string",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def upsert_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: ParseConfigurationCreate,
    ) -> ParseConfiguration:
        """
        Create or update a parse configuration by name.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created or updated parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: ParseConfigurationCreate.
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParseConfigurationCreate,
            ParsingMode,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.upsert_parse_configuration(
            request=ParseConfigurationCreate(
                name="string",
                parameters=LlamaParseParameters(
                    parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                    priority=LlamaParseParametersPriority.LOW,
                    replace_failed_page_mode=FailPageMode.RAW_TEXT,
                ),
                version="string",
            ),
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_latest_parse_configuration(
        self,
        *,
        creator: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> typing.Optional[ParseConfiguration]:
        """
        Get the latest parse configuration for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        creator: Optional creator filter

        Returns:
        The latest parse configuration or None if not found

        Parameters:
            - creator: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_latest_parse_configuration()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations/latest"),
            params=remove_none_from_dict(
                {"creator": creator, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Optional[ParseConfiguration], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def query_parse_configurations(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[ParseConfigurationFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> ParseConfigurationQueryResponse:
        """
        Query parse configurations with filtering and pagination.

        Args:
        query_request: Query request with filters and pagination
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        Paginated response with parse configurations

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[ParseConfigurationFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import ParseConfigurationFilter
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.query_parse_configurations(
            filter=ParseConfigurationFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
        config_id: The ID of the parse configuration
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_parse_configuration(
            config_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
        config_id: The ID of the parse configuration to update
        config_update: Update data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The updated parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - parameters: typing.Optional[LlamaParseParameters].
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.update_parse_configuration(
            config_id="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if parameters is not OMIT:
            _request["parameters"] = parameters
        _response = self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a parse configuration.

        Args:
        config_id: The ID of the parse configuration to delete
        project: Validated project from dependency
        user: Current user
        db: Database session

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.delete_parse_configuration(
            config_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_quota_configurations(
        self,
        *,
        source_type: typing_extensions.Literal["organization"],
        source_id: str,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
    ) -> PaginatedResponseQuotaConfiguration:
        """
        Retrieve a paginated list of quota configurations with optional filtering.

        Parameters:
            - source_type: typing_extensions.Literal["organization"].

            - source_id: str.

            - page: typing.Optional[int].

            - page_size: typing.Optional[int].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_quota_configurations(
            source_type="organization",
            source_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/quota-management"),
            params=remove_none_from_dict(
                {"source_type": source_type, "source_id": source_id, "page": page, "page_size": page_size}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseQuotaConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.list_spreadsheet_jobs()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/spreadsheet/jobs"),
            params=remove_none_from_dict(
                {
                    "include_results": include_results,
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseSpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create_spreadsheet_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        file_id: str,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - config: typing.Optional[SpreadsheetParsingConfig]. Configuration for the parsing job

            - file_id: str. The ID of the file to parse
        ---
        from llama_cloud import SpreadsheetParsingConfig
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.create_spreadsheet_job(
            config=SpreadsheetParsingConfig(),
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if config is not OMIT:
            _request["config"] = config
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/spreadsheet/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted tables and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/spreadsheet/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict(
                {"include_results": include_results, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_result_table(
        self,
        spreadsheet_job_id: str,
        table_id: str,
        table_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted table.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - table_id: str.

            - table_type: SpreadsheetResultType.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import SpreadsheetResultType
        from llama_cloud.client import LlamaCloud

        client = LlamaCloud(
            token="YOUR_TOKEN",
        )
        client.beta.get_result_table(
            spreadsheet_job_id="string",
            table_id="string",
            table_type=SpreadsheetResultType.TABLE,
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/spreadsheet/jobs/{spreadsheet_job_id}/tables/{table_id}/result/{table_type}",
            ),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncBetaClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def create_agent_data(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        data: typing.Dict[str, typing.Any],
        deployment_name: str,
    ) -> AgentData:
        """
        Create new agent data.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].

            - deployment_name: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_agent_data(
            data={"string": {}},
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"data": data, "deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        count: typing.Optional[bool] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        first: typing.Optional[bool] = OMIT,
        group_by: typing.Optional[typing.List[str]] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAggregateGroup:
        """
        Aggregate agent data with grouping and optional counting/first item retrieval.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to aggregate data for

            - count: typing.Optional[bool].

            - deployment_name: str. The agent deployment's name to aggregate data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - first: typing.Optional[bool].

            - group_by: typing.Optional[typing.List[str]].

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.aggregate_agent_data_api_v_1_beta_agent_data_aggregate_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if count is not OMIT:
            _request["count"] = count
        if filter is not OMIT:
            _request["filter"] = filter
        if first is not OMIT:
            _request["first"] = first
        if group_by is not OMIT:
            _request["group_by"] = group_by
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:aggregate"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAggregateGroup, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
    ) -> DeleteResponse:
        """
        Bulk delete agent data by query (deployment_name, collection, optional filters).

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to delete from

            - deployment_name: str. The agent deployment's name to delete data for

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_agent_data_by_query_api_v_1_beta_agent_data_delete_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:delete"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DeleteResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def search_agent_data_api_v_1_beta_agent_data_search_post(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        collection: typing.Optional[str] = OMIT,
        deployment_name: str,
        filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]] = OMIT,
        include_total: typing.Optional[bool] = OMIT,
        offset: typing.Optional[int] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> PaginatedResponseAgentData:
        """
        Search agent data with filtering, sorting, and pagination.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - collection: typing.Optional[str]. The logical agent data collection to search within

            - deployment_name: str. The agent deployment's name to search within

            - filter: typing.Optional[typing.Dict[str, typing.Optional[FilterOperation]]].

            - include_total: typing.Optional[bool]. Whether to include the total number of items in the response

            - offset: typing.Optional[int].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.search_agent_data_api_v_1_beta_agent_data_search_post(
            deployment_name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"deployment_name": deployment_name}
        if collection is not OMIT:
            _request["collection"] = collection
        if filter is not OMIT:
            _request["filter"] = filter
        if include_total is not OMIT:
            _request["include_total"] = include_total
        if offset is not OMIT:
            _request["offset"] = offset
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/agent-data/:search"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseAgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> AgentData:
        """
        Get agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_agent_data(
            item_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_agent_data(
        self,
        item_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data: typing.Dict[str, typing.Any],
    ) -> AgentData:
        """
        Update agent data by ID (overwrites).

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data: typing.Dict[str, typing.Any].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_agent_data(
            item_id="string",
            data={"string": {}},
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder({"data": data}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(AgentData, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_agent_data(
        self, item_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> typing.Dict[str, str]:
        """
        Delete agent data by ID.

        Parameters:
            - item_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_agent_data(
            item_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/agent-data/{item_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Dict[str, str], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_api_keys(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        key_type: typing.Optional[ApiKeyType] = None,
    ) -> ApiKeyQueryResponse:
        """
        List API keys.

        If project_id is provided, validates user has access to that project.
        If project_id is not provided, scopes results to the current user.

        Args:
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by API key name
        project_id: Filter by project ID
        key_type: Filter by key type

        Returns:
        Paginated response with API keys

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - project_id: typing.Optional[str].

            - key_type: typing.Optional[ApiKeyType].
        ---
        from llama_cloud import ApiKeyType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_api_keys(
            key_type=ApiKeyType.USER,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/api-keys"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "project_id": project_id,
                    "key_type": key_type,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKeyQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_api_key(
        self,
        *,
        key_type: typing.Optional[ApiKeyType] = OMIT,
        name: typing.Optional[str] = OMIT,
        project_id: typing.Optional[str] = OMIT,
    ) -> ApiKey:
        """
        Create a new API key.

        If project_id is specified, validates user has admin permissions for that project.

        Args:
        api_key_create: API key creation data
        user: Current user
        db: Database session

        Returns:
        The created API key with the secret key visible in redacted_api_key field

        Parameters:
            - key_type: typing.Optional[ApiKeyType].

            - name: typing.Optional[str].

            - project_id: typing.Optional[str].
        ---
        from llama_cloud import ApiKeyType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_api_key(
            key_type=ApiKeyType.USER,
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if key_type is not OMIT:
            _request["key_type"] = key_type
        if name is not OMIT:
            _request["name"] = name
        if project_id is not OMIT:
            _request["project_id"] = project_id
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/api-keys"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKey, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_api_key(self, api_key_id: str) -> ApiKey:
        """
        Get an API key by ID.

        Args:
        api_key_id: The ID of the API key
        user: Current user
        db: Database session

        Returns:
        The API key

        Parameters:
            - api_key_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_api_key(
            api_key_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/api-keys/{api_key_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ApiKey, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_api_key(self, api_key_id: str) -> None:
        """
        Delete an API key.

        If the API key belongs to a project, validates user has admin permissions for that project.
        If the API key has no project, validates it belongs to the current user.

        Args:
        api_key_id: The ID of the API key to delete
        user: Current user
        db: Database session

        Parameters:
            - api_key_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_api_key(
            api_key_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/api-keys/{api_key_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_batch_job(
        self,
        *,
        continue_as_new_threshold: typing.Optional[int] = OMIT,
        directory_id: typing.Optional[str] = OMIT,
        item_ids: typing.Optional[typing.List[str]] = OMIT,
        job_config: BatchJobCreateRequestJobConfig,
        page_size: typing.Optional[int] = OMIT,
        project_id: typing.Optional[str] = OMIT,
    ) -> BatchJobResponse:
        """
        Create a new batch processing job for a directory.

        This endpoint creates a batch job that will process all files in the specified directory
        using a Temporal workflow. The job configuration determines what processing will be performed.

        Args:
        payload: Job configuration including directory_id, job_config, and workflow settings
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobResponse with job details and workflow ID

        Raises:
        HTTPException: If directory not found or user lacks permissions

        Example Request Body:
        `json { "directory_id": "dir_123", "job_config": { "job_name": "PARSE_RAW_FILE", "parameters": { "type": "PARSE", "parsing_instruction": "Extract all tables" } }, "page_size": 100, "continue_as_new_threshold": 1000 } `

        Parameters:
            - continue_as_new_threshold: typing.Optional[int].

            - directory_id: typing.Optional[str].

            - item_ids: typing.Optional[typing.List[str]].

            - job_config: BatchJobCreateRequestJobConfig. Job configuration for batch processing. Can be BatchParseJobRecordCreate or ClassifyJob.

            - page_size: typing.Optional[int]. Number of files to fetch per batch from the directory (only used in directory mode)

            - project_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_batch_job()
        """
        _request: typing.Dict[str, typing.Any] = {"job_config": job_config}
        if continue_as_new_threshold is not OMIT:
            _request["continue_as_new_threshold"] = continue_as_new_threshold
        if directory_id is not OMIT:
            _request["directory_id"] = directory_id
        if item_ids is not OMIT:
            _request["item_ids"] = item_ids
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if project_id is not OMIT:
            _request["project_id"] = project_id
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/batch-processing"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_item_processing_results(
        self, item_id: str, *, job_type: typing.Optional[BatchJobType] = None
    ) -> ItemProcessingResultsResponse:
        """
        Get all processing results for a specific item (lineage query).

        Shows complete processing history including what operations have been performed,
        with what parameters, and where outputs are stored. Useful for understanding
        what processing has already been done to avoid redundant work.

        Args:
        item_id: ID of the item (file) to query
        job_type: Optional filter to show only specific processing type
        user: Authenticated user making the request
        db: Database session

        Returns:
        ItemProcessingResultsResponse with all processing operations for this item

        Raises:
        HTTPException: If item not found or user lacks permissions

        Parameters:
            - item_id: str.

            - job_type: typing.Optional[BatchJobType]. Filter results by job type
        ---
        from llama_cloud import BatchJobType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_item_processing_results(
            item_id="string",
            job_type=BatchJobType.PARSE,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/batch-processing/items/{item_id}/processing-results",
            ),
            params=remove_none_from_dict({"job_type": job_type}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ItemProcessingResultsResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_batch_job_status(self, job_id: str) -> BatchJobStatusResponse:
        """
        Get detailed status of a batch processing job.

        Returns current progress, file counts, and estimated completion time.

        Args:
        job_id: ID of the batch job
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobStatusResponse with job details and progress information

        Raises:
        HTTPException: If job not found or user lacks permissions

        Parameters:
            - job_id: str.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_batch_job_status(
            job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobStatusResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def cancel_batch_job(self, job_id: str, *, reason: typing.Optional[str] = OMIT) -> BatchJobCancelResponse:
        """
        Cancel a running batch processing job.

        Stops spawning new item processing tasks immediately. Items currently being
        processed will complete. Essential for cost control if a job was started in error.

        Args:
        job_id: ID of the batch job to cancel
        payload: Cancellation request with optional reason
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchJobCancelResponse with final job statistics

        Raises:
        HTTPException: If job not found, already completed, or user lacks permissions

        Parameters:
            - job_id: str.

            - reason: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.cancel_batch_job(
            job_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if reason is not OMIT:
            _request["reason"] = reason
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/cancel"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchJobCancelResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_batch_job_items(
        self,
        job_id: str,
        *,
        status: typing.Optional[BatchFileStatus] = None,
        limit: typing.Optional[int] = None,
        offset: typing.Optional[int] = None,
    ) -> BatchItemListResponse:
        """
        List items in a batch job with optional status filtering.

        Useful for finding failed items, viewing completed items, or debugging issues.
        Results are paginated for performance.

        Args:
        job_id: ID of the batch job
        status_filter: Optional filter by item status
        limit: Maximum number of items to return (1-1000)
        offset: Number of items to skip for pagination
        user: Authenticated user making the request
        db: Database session

        Returns:
        BatchItemListResponse with paginated item details

        Raises:
        HTTPException: If job not found or user lacks permissions

        Parameters:
            - job_id: str.

            - status: typing.Optional[BatchFileStatus]. Filter items by status

            - limit: typing.Optional[int]. Maximum number of items to return

            - offset: typing.Optional[int]. Number of items to skip
        ---
        from llama_cloud import BatchFileStatus
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_batch_job_items(
            job_id="string",
            status=BatchFileStatus.PENDING,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/batch-processing/{job_id}/items"
            ),
            params=remove_none_from_dict({"status": status, "limit": limit, "offset": offset}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(BatchItemListResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_directories(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryQueryResponse:
        """
        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - name: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_directories()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "name": name,
                    "data_source_id": data_source_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_directory(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        data_source_id: typing.Optional[str] = OMIT,
        description: typing.Optional[str] = OMIT,
        name: str,
    ) -> DirectoryResponse:
        """
        Create a new directory within the specified project.

        If data_source_id is provided, validates that the data source exists
        and belongs to the same project.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - data_source_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: str. Human-readable name for the directory.
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_directory(
            name="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if data_source_id is not OMIT:
            _request["data_source_id"] = data_source_id
        if description is not OMIT:
            _request["description"] = description
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/directories"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryResponse:
        """
        Retrieve a directory by its identifier.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_directory(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Permanently delete a directory.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_directory(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_directory(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        description: typing.Optional[str] = OMIT,
        name: typing.Optional[str] = OMIT,
    ) -> DirectoryResponse:
        """
        Update directory metadata.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - description: typing.Optional[str].

            - name: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_directory(
            directory_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if description is not OMIT:
            _request["description"] = description
        if name is not OMIT:
            _request["name"] = name
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_directory_files(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = None,
        display_name_contains: typing.Optional[str] = None,
        unique_id: typing.Optional[str] = None,
        file_id: typing.Optional[str] = None,
        include_deleted: typing.Optional[bool] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> DirectoryFileQueryResponse:
        """
        List all files within the specified directory with optional filtering and pagination.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - display_name_contains: typing.Optional[str].

            - unique_id: typing.Optional[str].

            - file_id: typing.Optional[str].

            - include_deleted: typing.Optional[bool].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_directory_files(
            directory_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict(
                {
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "display_name": display_name,
                    "display_name_contains": display_name_contains,
                    "unique_id": unique_id,
                    "file_id": file_id,
                    "include_deleted": include_deleted,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_directory_file(
        self,
        directory_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        file_id: str,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Create a new file within the specified directory.

        The directory must exist and belong to the project passed in.
        The file_id must be provided and exist in the project.

        Parameters:
            - directory_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - file_id: str. File ID for the storage location (required).

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.add_directory_file(
            directory_id="string",
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/directories/{directory_id}/files"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> DirectoryFileResponse:
        """
        Get a file by its directory_file_id within the specified directory. If you're trying to get a file by its unique_id, use the list endpoint with a filter instead.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> None:
        """
        Delete a file from the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to delete a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_directory_file(
        self,
        directory_id: str,
        directory_file_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        display_name: typing.Optional[str] = OMIT,
        unique_id: typing.Optional[str] = OMIT,
    ) -> DirectoryFileResponse:
        """
        Update file metadata within the specified directory.

        Note: This endpoint uses directory_file_id (the internal ID). If you're trying to update a file by its unique_id, use the list endpoint with a filter to find the directory_file_id first.

        Parameters:
            - directory_id: str.

            - directory_file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - display_name: typing.Optional[str].

            - unique_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_directory_file(
            directory_id="string",
            directory_file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if display_name is not OMIT:
            _request["display_name"] = display_name
        if unique_id is not OMIT:
            _request["unique_id"] = unique_id
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/directories/{directory_id}/files/{directory_file_id}",
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DirectoryFileResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: FileCreate,
    ) -> File:
        """
        Create a new file in the project.

        Args:
        file_create: File creation data
        project: Validated project from dependency
        db: Database session

        Returns:
        The created file

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: FileCreate.
        ---
        from llama_cloud import FileCreate
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_file(
            request=FileCreate(
                name="string",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(File, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upsert_file(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: FileCreate,
    ) -> File:
        """
        Upsert a file (create or update if exists) in the project.

        Args:
        file_create: File creation/update data
        project: Validated project from dependency
        db: Database session

        Returns:
        The upserted file

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: FileCreate.
        ---
        from llama_cloud import FileCreate
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.upsert_file(
            request=FileCreate(
                name="string",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(File, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def query_files(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[FileFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> FileQueryResponse:
        """
        Query files with flexible filtering and pagination.

        Args:
        request: The query request with filters and pagination
        project: Validated project from dependency
        db: Database session

        Returns:
        Paginated response with files

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[FileFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import FileFilter
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.query_files(
            filter=FileFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/files/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(FileQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_file(
        self, file_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a single file from the project.

        Args:
        file_id: The ID of the file to delete
        project: Validated project from dependency
        db: Database session

        Returns:
        None (204 No Content on success)

        Parameters:
            - file_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_file(
            file_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/files/{file_id}"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_parse_configurations(
        self,
        *,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
        name: typing.Optional[str] = None,
        creator: typing.Optional[str] = None,
        version: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> ParseConfigurationQueryResponse:
        """
        List parse configurations for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        page_size: Number of items per page
        page_token: Token for pagination
        name: Filter by configuration name
        creator: Filter by creator
        version: Filter by version

        Returns:
        Paginated response with parse configurations

        Parameters:
            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].

            - name: typing.Optional[str].

            - creator: typing.Optional[str].

            - version: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_parse_configurations()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict(
                {
                    "page_size": page_size,
                    "page_token": page_token,
                    "name": name,
                    "creator": creator,
                    "version": version,
                    "project_id": project_id,
                    "organization_id": organization_id,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: ParseConfigurationCreate,
    ) -> ParseConfiguration:
        """
        Create a new parse configuration.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: ParseConfigurationCreate.
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParseConfigurationCreate,
            ParsingMode,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_parse_configuration(
            request=ParseConfigurationCreate(
                name="string",
                parameters=LlamaParseParameters(
                    parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                    priority=LlamaParseParametersPriority.LOW,
                    replace_failed_page_mode=FailPageMode.RAW_TEXT,
                ),
                version="string",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def upsert_parse_configuration(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        request: ParseConfigurationCreate,
    ) -> ParseConfiguration:
        """
        Create or update a parse configuration by name.

        Args:
        config_create: Parse configuration creation data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The created or updated parse configuration

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - request: ParseConfigurationCreate.
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParseConfigurationCreate,
            ParsingMode,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.upsert_parse_configuration(
            request=ParseConfigurationCreate(
                name="string",
                parameters=LlamaParseParameters(
                    parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                    priority=LlamaParseParametersPriority.LOW,
                    replace_failed_page_mode=FailPageMode.RAW_TEXT,
                ),
                version="string",
            ),
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_latest_parse_configuration(
        self,
        *,
        creator: typing.Optional[str] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> typing.Optional[ParseConfiguration]:
        """
        Get the latest parse configuration for the current project.

        Args:
        project: Validated project from dependency
        user: Current user
        db: Database session
        creator: Optional creator filter

        Returns:
        The latest parse configuration or None if not found

        Parameters:
            - creator: typing.Optional[str].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_latest_parse_configuration()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations/latest"),
            params=remove_none_from_dict(
                {"creator": creator, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Optional[ParseConfiguration], _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def query_parse_configurations(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        filter: typing.Optional[ParseConfigurationFilter] = OMIT,
        order_by: typing.Optional[str] = OMIT,
        page_size: typing.Optional[int] = OMIT,
        page_token: typing.Optional[str] = OMIT,
    ) -> ParseConfigurationQueryResponse:
        """
        Query parse configurations with filtering and pagination.

        Args:
        query_request: Query request with filters and pagination
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        Paginated response with parse configurations

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - filter: typing.Optional[ParseConfigurationFilter].

            - order_by: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud import ParseConfigurationFilter
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.query_parse_configurations(
            filter=ParseConfigurationFilter(),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if filter is not OMIT:
            _request["filter"] = filter
        if order_by is not OMIT:
            _request["order_by"] = order_by
        if page_size is not OMIT:
            _request["page_size"] = page_size
        if page_token is not OMIT:
            _request["page_token"] = page_token
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/parse-configurations/query"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfigurationQueryResponse, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> ParseConfiguration:
        """
        Get a parse configuration by ID.

        Args:
        config_id: The ID of the parse configuration
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_parse_configuration(
            config_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_parse_configuration(
        self,
        config_id: str,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        parameters: typing.Optional[LlamaParseParameters] = OMIT,
    ) -> ParseConfiguration:
        """
        Update a parse configuration.

        Args:
        config_id: The ID of the parse configuration to update
        config_update: Update data
        project: Validated project from dependency
        user: Current user
        db: Database session

        Returns:
        The updated parse configuration

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - parameters: typing.Optional[LlamaParseParameters].
        ---
        from llama_cloud import (
            FailPageMode,
            LlamaParseParameters,
            LlamaParseParametersPriority,
            ParsingMode,
        )
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.update_parse_configuration(
            config_id="string",
            parameters=LlamaParseParameters(
                parse_mode=ParsingMode.PARSE_PAGE_WITHOUT_LLM,
                priority=LlamaParseParametersPriority.LOW,
                replace_failed_page_mode=FailPageMode.RAW_TEXT,
            ),
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if parameters is not OMIT:
            _request["parameters"] = parameters
        _response = await self._client_wrapper.httpx_client.request(
            "PUT",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ParseConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete_parse_configuration(
        self, config_id: str, *, project_id: typing.Optional[str] = None, organization_id: typing.Optional[str] = None
    ) -> None:
        """
        Delete a parse configuration.

        Args:
        config_id: The ID of the parse configuration to delete
        project: Validated project from dependency
        user: Current user
        db: Database session

        Parameters:
            - config_id: str.

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.delete_parse_configuration(
            config_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/parse-configurations/{config_id}"
            ),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_quota_configurations(
        self,
        *,
        source_type: typing_extensions.Literal["organization"],
        source_id: str,
        page: typing.Optional[int] = None,
        page_size: typing.Optional[int] = None,
    ) -> PaginatedResponseQuotaConfiguration:
        """
        Retrieve a paginated list of quota configurations with optional filtering.

        Parameters:
            - source_type: typing_extensions.Literal["organization"].

            - source_id: str.

            - page: typing.Optional[int].

            - page_size: typing.Optional[int].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_quota_configurations(
            source_type="organization",
            source_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/quota-management"),
            params=remove_none_from_dict(
                {"source_type": source_type, "source_id": source_id, "page": page, "page_size": page_size}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseQuotaConfiguration, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def list_spreadsheet_jobs(
        self,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        page_size: typing.Optional[int] = None,
        page_token: typing.Optional[str] = None,
    ) -> PaginatedResponseSpreadsheetJob:
        """
        List spreadsheet parsing jobs.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - page_size: typing.Optional[int].

            - page_token: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.list_spreadsheet_jobs()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/spreadsheet/jobs"),
            params=remove_none_from_dict(
                {
                    "include_results": include_results,
                    "project_id": project_id,
                    "organization_id": organization_id,
                    "page_size": page_size,
                    "page_token": page_token,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PaginatedResponseSpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create_spreadsheet_job(
        self,
        *,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
        config: typing.Optional[SpreadsheetParsingConfig] = OMIT,
        file_id: str,
    ) -> SpreadsheetJob:
        """
        Create a spreadsheet parsing job.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].

            - config: typing.Optional[SpreadsheetParsingConfig]. Configuration for the parsing job

            - file_id: str. The ID of the file to parse
        ---
        from llama_cloud import SpreadsheetParsingConfig
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.create_spreadsheet_job(
            config=SpreadsheetParsingConfig(),
            file_id="string",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"file_id": file_id}
        if config is not OMIT:
            _request["config"] = config
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/beta/spreadsheet/jobs"),
            params=remove_none_from_dict({"project_id": project_id, "organization_id": organization_id}),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_spreadsheet_job(
        self,
        spreadsheet_job_id: str,
        *,
        include_results: typing.Optional[bool] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> SpreadsheetJob:
        """
        Get a spreadsheet parsing job.

        When include_results=True (default), the response will include extracted tables and results
        if the job is complete, eliminating the need for a separate /results call.

        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - include_results: typing.Optional[bool].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_spreadsheet_job(
            spreadsheet_job_id="string",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/beta/spreadsheet/jobs/{spreadsheet_job_id}"
            ),
            params=remove_none_from_dict(
                {"include_results": include_results, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SpreadsheetJob, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_result_table(
        self,
        spreadsheet_job_id: str,
        table_id: str,
        table_type: SpreadsheetResultType,
        *,
        expires_at_seconds: typing.Optional[int] = None,
        project_id: typing.Optional[str] = None,
        organization_id: typing.Optional[str] = None,
    ) -> PresignedUrl:
        """
        Generate a presigned URL to download a specific extracted table.
        Experimental: This endpoint is not yet ready for production use and is subject to change at any time.

        Parameters:
            - spreadsheet_job_id: str.

            - table_id: str.

            - table_type: SpreadsheetResultType.

            - expires_at_seconds: typing.Optional[int].

            - project_id: typing.Optional[str].

            - organization_id: typing.Optional[str].
        ---
        from llama_cloud import SpreadsheetResultType
        from llama_cloud.client import AsyncLlamaCloud

        client = AsyncLlamaCloud(
            token="YOUR_TOKEN",
        )
        await client.beta.get_result_table(
            spreadsheet_job_id="string",
            table_id="string",
            table_type=SpreadsheetResultType.TABLE,
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/",
                f"api/v1/beta/spreadsheet/jobs/{spreadsheet_job_id}/tables/{table_id}/result/{table_type}",
            ),
            params=remove_none_from_dict(
                {"expires_at_seconds": expires_at_seconds, "project_id": project_id, "organization_id": organization_id}
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PresignedUrl, _response.json())  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

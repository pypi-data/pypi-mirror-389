Metadata-Version: 2.4
Name: ml-robust-eval
Version: 0.1.7
Summary: ML evaluation, validation, and test case generation toolkit with production monitoring.
License: MIT
License-File: LICENSE
Keywords: machine-learning,evaluation,metrics,monitoring,prometheus,grafana
Author: vikhyat-ch
Author-email: vikhyathchoppa699@gmail.com
Requires-Python: >=3.7,<4.0
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Provides-Extra: monitoring
Requires-Dist: prometheus-client (>=0.18.0) ; extra == "monitoring"
Description-Content-Type: text/markdown

# ML Robust Eval

![ml-eval-robust-logo](./assets/ML%20Eval.png)

[![PyPI](https://img.shields.io/pypi/v/ml-eval-robust?color=blue&logo=PyPI)]()
[![License](https://img.shields.io/pypi/l/ml-eval-robust)](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/LICENSE)

---

**ML Eval Robust** is a pure Python, object-oriented library for comprehensive machine learning model evaluation, validation, and robustness testing.  
It's an all-in-one toolkit that features:

- ğŸ“Š **Metrics** for classification, regression, NLP, and computer vision tasks  
- ğŸ” **Cross-validation** and **A/B testing** helpers  
- ğŸ“ˆ **Visualization** tools for confusion matrices and ROC curves (stdout-based, no dependencies!)  
- ğŸ¦¾ **Automated test case generation**: edge cases, adversarial samples, and boundary value tests  
- ğŸ“¡ **Production Monitoring** (optional): Real-time model degradation tracking with Prometheus & Grafana
- ğŸ§© **Zero dependencies** (core) â€“ works anywhere Python runs!

---

## ğŸš€ Installation

**Basic installation:**
```bash
pip install ml_robust_eval
```

**With production monitoring support (Prometheus/Grafana):**
```bash
pip install ml_robust_eval[monitoring]
```

---

## ğŸ§  Features

- **Classification, Regression, NLP, and CV Metrics**  
  - Accuracy, Precision, Recall, F1, MAE, MSE, RÂ², BLEU, IoU, and more!
- **Cross-Validation & A/B Testing**
  - K-fold splitting, group comparison, and statistical difference calculation
- **Visualization**
  - Confusion matrices and ROC curves printed directly to your console
- **Robustness Test Case Generation**
  - Edge, boundary, and adversarial sample generation for any tabular data
- **Production Monitoring** (Optional)
  - Real-time model performance tracking with Prometheus
  - Automatic degradation detection compared to baseline
  - Pre-configured Grafana dashboards
  - Docker Compose setup for easy deployment
- **Zero Dependencies (Core)**
  - Core library uses only standard library, OOP-based, and lightweight
  - Monitoring module is optional and requires prometheus-client

---

## ğŸ“š Documentation

- [API Reference](https://ml-robust-eval.readthedocs.io/en/latest/api_reference.html)
- [Examples & Tutorials](https://ml-robust-eval.readthedocs.io/en/latest/usage.html)
- [Production Monitoring Guide](monitoring/README.md) - Real-time model degradation tracking

---

## ğŸ’¡ Why ML Eval Robust?

- **Universal:** No dependencies, works in any Python environment
- **Educational:** Clear, readable OOP code for learning and teaching
- **Robust:** Covers the full ML evaluation and validation pipeline, including adversarial and edge testing
- **Production-Ready:** Optional monitoring module for real-time model tracking in production

---

## ğŸ¤ Contributing

All contributions, bug reports, and suggestions are welcome!  
See the [contributing guide](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/blob/contributing.md).

---

## ğŸ“œ License

[MIT License](https://github.com/VikhyatChoppa18/ml_robust_eval/blob/main/LICENSE)

---

## ğŸ“¬ Contact

Questions? Open an [issue](https://github.com/VikhyatChoppa18/ml_robust_eval/issues) or reach out at [vikhyathchoppa699@gmail.com].

---

**Let your models earn their confidence. Test, validate, and challenge them with ML Robust Eval!**


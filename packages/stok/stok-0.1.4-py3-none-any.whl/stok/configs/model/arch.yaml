encoder:
  d_model: 768
  n_heads: 12
  n_layers: 12
  ffn_mult: 4.0
  vocab_size: 32
  pad_id: 1
  dropout: 0.1
  attn_dropout: 0.0
  norm: "layernorm"

decoder:
  # -- base -- 
  d_model: 1024
  ffn_mult: 4
  n_layers: 16
  n_heads: 16
  attn_kv_heads: 1
  num_memory_tokens: 0
  # -- lite -- 
  # d_model: 1024
  # ffn_mult: 4
  # n_layers: 12
  # n_heads: 8
  # attn_kv_heads: 2
  # num_memory_tokens: 0


classifier:
  tie_to_codebook: true
  learnable_temperature: true
  use_cosine: false
  bias_from_code_norm: true
  projector_dim: null
  ignore_index: -100

init:
  std: 0.02

codebook:
  preset: "base"
  path: null
  trainable: false



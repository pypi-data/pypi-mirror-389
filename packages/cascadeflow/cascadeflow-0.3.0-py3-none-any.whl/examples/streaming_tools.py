"""
Tool Streaming Example - FIXED
===============================

Real-time tool call streaming with automatic execution.

Setup:
    pip install cascadeflow[all]
    export OPENAI_API_KEY="sk-..."

Run:
    python examples/streaming_tools.py

What You'll See:
    - Tool calls being parsed as JSON arrives
    - Automatic tool execution
    - Results fed back to the model for final answer

Documentation:
    ğŸ“– Streaming Guide: docs/guides/streaming.md#tool-streaming
    ğŸ“– Quick Start: docs/guides/quickstart.md
    ğŸ“š Examples README: examples/README.md
"""

import asyncio
import os

from cascadeflow import CascadeAgent, ModelConfig
from cascadeflow.streaming import ToolStreamEventType

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 1: Define Tools in Universal Format
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTANT: Use "universal format" (not OpenAI format)
# This works with ALL providers (OpenAI, Anthropic, Groq, etc.)
#
# Universal format structure:
# {
#     "name": "function_name",           â† Direct property
#     "description": "what it does",     â† Direct property
#     "parameters": {JSON Schema}        â† Direct property
# }
#
# âŒ WRONG (OpenAI format - don't use this):
# {
#     "type": "function",                â† Extra wrapper
#     "function": {
#         "name": "...",
#         ...
#     }
# }
#
# cascadeflow converts universal format â†’ provider format automatically

WEATHER_TOOL = [
    {
        "name": "get_weather",
        "description": "Get current weather for a location",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "City name (e.g., 'Paris', 'Tokyo')"},
                "unit": {
                    "type": "string",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "Temperature unit",
                },
            },
            "required": ["location"],  # location is required, unit is optional
        },
    }
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 2: Implement Tool Function (Not used in this example)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Note: This example shows tool call STREAMING only.
# For actual tool EXECUTION, see examples/tool_execution.py
#
# In production, you would:
# 1. Create ToolConfig objects with function=your_function
# 2. Use ToolExecutor to execute tool calls
# 3. Feed results back to the model
#
# This example focuses on the STREAMING aspect (watching tool calls form)


def get_weather(location: str, unit: str = "celsius") -> str:
    """
    Mock weather function - for reference only.
    Not used in this streaming example.
    """
    weather = {
        "paris": {"temp_c": 15, "condition": "Partly cloudy"},
        "tokyo": {"temp_c": 22, "condition": "Sunny"},
        "london": {"temp_c": 12, "condition": "Rainy"},
        "new york": {"temp_c": 18, "condition": "Clear"},
    }

    city = location.lower()
    if city in weather:
        data = weather[city]
        temp = data["temp_c"]
        if unit.lower() == "fahrenheit":
            temp = int(temp * 9 / 5 + 32)
            unit_symbol = "Â°F"
        else:
            unit_symbol = "Â°C"
        return f"{location}: {temp}{unit_symbol}, {data['condition']}"
    else:
        return f"Weather data not available for {location}"


async def main():
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 3: Check API Key
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ Set OPENAI_API_KEY first: export OPENAI_API_KEY='sk-...'")
        return

    print("ğŸ”§ cascadeflow Tool Streaming\n")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 4: Setup Agent with Cascade (REQUIRED for streaming)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # âœ… FIX: Need 2+ models for streaming to work!

    agent = CascadeAgent(
        models=[
            ModelConfig(name="gpt-4o-mini", provider="openai", cost=0.00015),
            ModelConfig(name="gpt-4o", provider="openai", cost=0.00625),
        ]
    )

    # Streaming is automatically available with 2+ models
    print("âœ“ Agent ready with 2-model cascade")
    print("âœ“ Streaming enabled (text and tools)\n")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXAMPLE 1: Single Tool Call (Streaming Events)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Watch tool calls being parsed in real-time
    # Note: execute_tools parameter doesn't actually execute in this example
    # It just shows the streaming events

    print("=" * 60)
    print("Example 1: Tool call streaming events\n")
    print("Q: What's the weather in Paris?\n")

    # âœ… FIX: Use stream_events() not agent.tool_streaming_manager.stream()
    async for event in agent.stream_events("What's the weather in Paris?", tools=WEATHER_TOOL):
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # EVENT: CHUNK - Regular text output (deprecated in tool mode)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # May appear as ToolStreamEventType.TEXT_CHUNK

        if event.type == ToolStreamEventType.TEXT_CHUNK:
            print(event.content, end="", flush=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # EVENT: TOOL_CALL_START - Tool call detected
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        elif event.type == ToolStreamEventType.TOOL_CALL_START:
            print("\nğŸ”§ Tool call starting...")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # EVENT: TOOL_CALL_COMPLETE - Tool call fully parsed
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        elif event.type == ToolStreamEventType.TOOL_CALL_COMPLETE:
            tool = event.data.get("tool_call", {})
            print(f"ğŸ”§ Tool: {tool.get('name')}({tool.get('arguments')})")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # EVENT: COMPLETE - All done
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        elif event.type == ToolStreamEventType.COMPLETE:
            print("\nâœ… Streaming complete")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EXAMPLE 2: Multiple Tool Calls
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    print("\n" + "=" * 60)
    print("Example 2: Multiple tool calls\n")
    print("Q: Compare weather in Paris and Tokyo\n")

    async for event in agent.stream_events(
        "Compare the weather in Paris and Tokyo. Which is warmer?", tools=WEATHER_TOOL
    ):
        if event.type == ToolStreamEventType.TEXT_CHUNK:
            print(event.content, end="", flush=True)

        elif event.type == ToolStreamEventType.TOOL_CALL_START:
            print("\nğŸ”§ Tool call starting...")

        elif event.type == ToolStreamEventType.TOOL_CALL_COMPLETE:
            tool = event.data.get("tool_call", {})
            print(f"ğŸ”§ Tool: {tool.get('name')}({tool.get('arguments')})")

        elif event.type == ToolStreamEventType.COMPLETE:
            print("\nâœ… Streaming complete")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Summary - What You Learned
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    print("\n" + "=" * 60)
    print("\nâœ… Done! Key takeaways:")
    print("\n  Tool Definition (Universal Format):")
    print("  â”œâ”€ Use direct properties: name, description, parameters")
    print("  â”œâ”€ Works with ALL providers (OpenAI, Anthropic, Groq)")
    print("  â””â”€ DON'T wrap in {'type': 'function', 'function': {...}}")
    print("\n  Streaming Requirements:")
    print("  â”œâ”€ Need 2+ models for cascade")
    print("  â””â”€ Use agent.stream() or agent.stream_events() for streaming")
    print("\n  Tool Events:")
    print("  â”œâ”€ TOOL_CALL_START: Tool call detected")
    print("  â”œâ”€ TOOL_CALL_COMPLETE: Full JSON parsed")
    print("  â””â”€ TEXT_CHUNK: Regular text between tools")
    print("\n  IMPORTANT:")
    print("  â”œâ”€ This example shows STREAMING only (watching tool calls form)")
    print("  â”œâ”€ For actual tool EXECUTION, see examples/tool_execution.py")
    print("  â””â”€ Need ToolConfig + ToolExecutor for real execution")

    print("\nğŸ“š Learn more:")
    print("  â€¢ docs/guides/streaming.md - Full streaming guide")
    print("  â€¢ examples/tool_execution.py - Real tool execution")
    print("  â€¢ tests/2.py - Comprehensive test suite\n")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Interrupted by user")
    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        print("\nğŸ’¡ Tip: Make sure OPENAI_API_KEY is set correctly")

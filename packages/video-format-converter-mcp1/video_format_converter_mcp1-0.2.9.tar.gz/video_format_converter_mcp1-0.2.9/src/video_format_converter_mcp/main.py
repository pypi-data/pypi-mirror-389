from mcp.server.fastmcp import FastMCP, Context
import ffmpeg
import os  # For checking file existence if needed, though ffmpeg handles it
import re  # For parsing silencedetect output
import tempfile  # For add_b_roll
import shutil  # For cleaning up temporary directories
import subprocess  # For running external commands
import platform
import urllib.parse  # For URL encoding
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
import time  # For execution time monitoring
import importlib.metadata  # For getting package name

# 配置日志输出到stderr，避免干扰MCP通信
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)  # 防止 basicConfig 被早期初始化抵消

package = "video-format-converter-mcp"

# 使用用户临时目录存放日志文件
log_dir = Path(tempfile.gettempdir()) / package
log_dir.mkdir(exist_ok=True)
log_file = log_dir / "debug.log"

file_handler = RotatingFileHandler(str(log_file), maxBytes=5_000_000, backupCount=3, encoding="utf-8")
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)
logger.propagate = False

FFMPEG_BINARY = os.environ.get('FFMPEG_BINARY')
FFPROBE_BINARY = os.environ.get('FFPROBE_BINARY')


# Helper functions for ffmpeg operations
def _ffmpeg_run(stream_spec, **kwargs):
    """Run ffmpeg with an explicit binary path to avoid env propagation issues."""
    if FFMPEG_BINARY:
        return ffmpeg.run(stream_spec, cmd=FFMPEG_BINARY, **kwargs)
    else:
        return ffmpeg.run(stream_spec, **kwargs)


def _ffmpeg_run_async(stream_spec, **kwargs):
    """Run ffmpeg asynchronously with explicit binary path."""
    if FFMPEG_BINARY:
        return ffmpeg.run_async(stream_spec, cmd=FFMPEG_BINARY, **kwargs)
    else:
        return ffmpeg.run_async(stream_spec, **kwargs)


def _ffprobe_probe(path: str, **kwargs):
    """Probe media with explicit ffprobe binary."""
    if FFPROBE_BINARY:
        return ffmpeg.probe(path, cmd=FFPROBE_BINARY, **kwargs)
    else:
        return ffmpeg.probe(path, **kwargs)


def _parse_time_to_seconds(time_input) -> float:
    """Parse time input to seconds (float)."""
    if isinstance(time_input, (int, float)):
        return float(time_input)
    if isinstance(time_input, str):
        # HH:MM:SS[.mmm] format
        if ':' in time_input:
            parts = time_input.split(':')
            if len(parts) == 3:
                h, m, s = parts
                return float(h) * 3600 + float(m) * 60 + float(s)
            elif len(parts) == 2:
                m, s = parts
                return float(m) * 60 + float(s)
        else:
            return float(time_input)
    raise ValueError(f"Invalid time format: {time_input}")


def _prepare_path(input_path: str, output_path: str) -> None:
    if not os.path.exists(input_path):
        raise RuntimeError(f"Error: Input file not found at {input_path}")
    try:
        parent_dir = os.path.dirname(output_path)
        if parent_dir and not os.path.exists(parent_dir):
            os.makedirs(parent_dir, exist_ok=True)
    except Exception as e:
        raise RuntimeError(f"Error creating output directory for {output_path}: {str(e)}")
    if os.path.exists(output_path):
        raise RuntimeError(
            f"Error: Output file already exists at {output_path}. Please choose a different path or delete the existing file.")


def _open_aido_link(ctx: Context, return_message: str) -> None:
    """跨平台静默执行aido://tool?xxx&chatSessionId=xxx"""
    try:
        # 检查 ctx 是否为 None
        if ctx is None:
            logger.debug("Context is None, skipping aido link execution")
            return

        # 尝试从 request_context 获取
        request_context = getattr(ctx, 'request_context', None)
        # 尝试从 request_context.meta 获取 chatSessionId
        chatSessionId = None
        if request_context and hasattr(request_context, 'meta'):
            context_meta = getattr(request_context, 'meta', None)
            logger.debug(f"context meta: {context_meta}")
            if context_meta and hasattr(context_meta, 'chatSessionId'):
                chatSessionId = getattr(context_meta, 'chatSessionId', None)
                logger.debug(f"chatSessionId from request_context.meta: {chatSessionId}")

        # 验证 chatSessionId 是否有效
        if not chatSessionId or chatSessionId == 'None':
            logger.warning(f"Invalid or missing chatSessionId: {chatSessionId}, skipping aido link execution")
            return

        encoded_message = urllib.parse.quote(return_message, safe='')
        package_name = urllib.parse.quote(package, safe='')
        aido_url = f"aido://tool?path={encoded_message}&chatSessionId={chatSessionId}&package={package_name}"

        # 根据操作系统选择合适的命令
        system = platform.system().lower()
        if system == 'darwin':  # macOS
            result = subprocess.run(['open', aido_url], check=False, capture_output=True, text=True)
            if result.returncode != 0 and result.stderr:
                logger.warning(f"macOS open command failed: {result.stderr}")
        elif system == 'windows':  # Windows
            # 使用 os.startfile (推荐方式) 或修正 start 命令语法
            try:
                os.startfile(aido_url)
            except (OSError, AttributeError) as e:
                # 如果 os.startfile 不可用,回退到 start 命令
                logger.debug(f"os.startfile failed, trying start command: {e}")
                # 修正 start 命令语法: start "窗口标题" "URL"
                result = subprocess.run(f'start "" "{aido_url}"', shell=True, check=False, capture_output=True, text=True)
                if result.returncode != 0 and result.stderr:
                    logger.warning(f"Windows start command failed: {result.stderr}")
        elif system == 'linux':  # Linux
            result = subprocess.run(['xdg-open', aido_url], check=False, capture_output=True, text=True)
            if result.returncode != 0 and result.stderr:
                logger.warning(f"Linux xdg-open command failed: {result.stderr}")
        else:
            logger.warning(f"Unsupported operating system: {system}")
            return

        logger.info(f"Executed aido link on {system}: {aido_url}")
    except Exception as e:
        logger.error(f"Failed to execute aido link: {str(e)}", exc_info=True)


# Create an MCP server instance
mcp = FastMCP("VideoAudioServer")


@mcp.tool()
def convert_video_properties(input_video_path: str, output_video_path: str, target_format: str,
                             resolution: str = None, video_codec: str = None, video_bitrate: str = None,
                             frame_rate: int = None, audio_codec: str = None, audio_bitrate: str = None,
                             audio_sample_rate: int = None, audio_channels: int = None, ctx: Context = None) -> str:
    """视频容器转换与属性重设（分辨率/帧率/视频编码/视频码率/音频编码/音频码率/采样率/声道）。

    Args:
        input_video_path: 输入视频文件路径。
        output_video_path: 输出视频文件路径（包含文件名和目标后缀）。
        target_format: 目标封装格式（如 'mp4'|'mov'|'mkv'|'webm'|'m4v'|'avi' 等）。
        resolution: 目标分辨率；支持 '宽x高'（如 '1920x1080'），或仅传高度（如 '720'，宽度按比例自动为 -2）。传 'preserve' 或 None 时保持原分辨率。
        video_codec: 视频编码器（如 'libx264'|'libx265'|'vp9'|'libvpx-vp9'|'wmv2' 等）。不传时由 ffmpeg 根据容器默认或继承原视频决定。
        video_bitrate: 视频码率（如 '2500k'、'1M'）。不传则由编码器/预设决定。
        frame_rate: 目标帧率（整数，如 24/30/60）。不传保持原始帧率。
        audio_codec: 音频编码器（如 'aac'|'libopus'|'libvorbis'|'mp3'|'wmav2'）。不传则由容器默认或继承原音频决定。
        audio_bitrate: 音频码率（如 '128k'、'192k'）。不传由编码器/预设决定。
        audio_sample_rate: 音频采样率（Hz，如 44100/48000）。不传保持原始采样率。
        audio_channels: 音频声道数（1=单声道，2=立体声）。不传保持原始声道数。

    Returns:
        A status message indicating success or failure.
    """
    # 记录开始时间
    start_time = time.time()
    
    _prepare_path(input_video_path, output_video_path)
    try:
        # 后缀与目标容器不一致时给出提示（不强制修改）
        out_ext = os.path.splitext(output_video_path)[1].lstrip('.').lower() if os.path.splitext(output_video_path)[
            1] else ''
        if out_ext and out_ext != target_format.lower():
            logger.warning(
                f"Output file extension '.{out_ext}' does not match target_format '{target_format}'. This may be confusing.")

        # 分辨率参数校验
        if resolution and resolution.lower() != 'preserve':
            if 'x' in resolution:
                if not re.match(r'^\d{2,5}x\d{2,5}$', resolution):
                    raise RuntimeError(f"Error: Invalid resolution '{resolution}'. Expected like '1920x1080'.")
            else:
                if not re.match(r'^\d{2,5}$', str(resolution)):
                    raise RuntimeError(f"Error: Invalid resolution '{resolution}'. Expected height like '720'.")

        # 纯换容器（remux）快速路径：未指定任何转码相关参数且未改分辨率/帧率
        pure_remux = (
                (not resolution or str(resolution).lower() == 'preserve') and
                video_codec is None and video_bitrate is None and frame_rate is None and
                audio_codec is None and audio_bitrate is None and audio_sample_rate is None and audio_channels is None
        )

        stream = ffmpeg.input(input_video_path)

        if pure_remux:
            try:
                output_stream = stream.output(output_video_path, format=target_format, c='copy')
                _ffmpeg_run(output_stream, capture_stdout=True, capture_stderr=True)
                
                # 计算执行时间
                execution_time = time.time() - start_time
                result_message = f"Remux completed: copied streams into container '{target_format}' → {output_video_path}. Execution time: {execution_time:.2f} seconds."
                
                # 只有执行时间超过10秒才调用 _open_aido_link
                if execution_time > 1:
                    _open_aido_link(ctx, output_video_path)
                
                return result_message
            except ffmpeg.Error as e_copy:
                # 回退：尝试按容器默认策略重编码
                logger.info(
                    f"Remux failed, falling back to re-encode: {e_copy.stderr.decode('utf8') if e_copy.stderr else str(e_copy)}")

        # 构建输出参数（带容器缺省编解码策略）
        def _defaults_for_container(fmt: str) -> tuple[str | None, str | None, dict]:
            fmt_l = (fmt or '').lower()
            extra: dict = {}
            v, a = None, None
            if fmt_l in {'mp4', 'm4v'}:
                v, a = 'libx264', 'aac'
                extra.update({'pix_fmt': 'yuv420p', 'movflags': '+faststart'})
            elif fmt_l in {'mov'}:
                v, a = 'libx264', 'aac'
                extra.update({'pix_fmt': 'yuv420p'})
            elif fmt_l in {'webm'}:
                v, a = 'libvpx-vp9', 'libopus'
                extra.update({'pix_fmt': 'yuv420p'})
            elif fmt_l in {'mkv'}:
                # MKV 兼容面广，给出通用默认
                v, a = 'libx264', 'aac'
                extra.update({'pix_fmt': 'yuv420p'})
            elif fmt_l in {'avi'}:
                v, a = 'mpeg4', 'mp3'
            elif fmt_l in {'wmv'}:
                v, a = 'wmv2', 'wmav2'
            else:
                v, a = None, None
            return v, a, extra

        def_v, def_a, def_extra = _defaults_for_container(target_format)

        kwargs: dict = {}
        vf_filters = []

        # 分辨率处理
        if resolution and str(resolution).lower() != 'preserve':
            if 'x' in resolution:
                vf_filters.append(f"scale={resolution}")
            else:
                vf_filters.append(f"scale=-2:{resolution}")
        if vf_filters:
            kwargs['vf'] = ",".join(vf_filters)

        # 选择编码器：显式优先生效，否则按容器默认
        vcodec_to_use = video_codec or def_v
        acodec_to_use = audio_codec or def_a
        if vcodec_to_use:
            kwargs['vcodec'] = vcodec_to_use
        if acodec_to_use:
            kwargs['acodec'] = acodec_to_use

        # 常见播放兼容：H.264/H.265默认 yuv420p
        if vcodec_to_use and any(x in vcodec_to_use for x in ['libx264', 'libx265', 'h264', 'hevc']):
            kwargs.setdefault('pix_fmt', 'yuv420p')

        # 按容器附加参数（如 mp4 faststart）
        for k, v in def_extra.items():
            kwargs.setdefault(k, v)

        # 码率/帧率/音频参数
        if video_bitrate:
            kwargs['video_bitrate'] = video_bitrate
        if frame_rate:
            kwargs['r'] = frame_rate
        if audio_bitrate:
            kwargs['audio_bitrate'] = audio_bitrate
        if audio_sample_rate:
            kwargs['ar'] = audio_sample_rate
        if audio_channels:
            kwargs['ac'] = audio_channels

        kwargs['format'] = target_format

        output_stream = stream.output(output_video_path, **kwargs)
        _ffmpeg_run(output_stream, capture_stdout=True, capture_stderr=True)
        
        # 计算执行时间
        execution_time = time.time() - start_time
        result_message = f"Video converted successfully to {output_video_path} with format {target_format} and specified properties. Execution time: {execution_time:.2f} seconds."
        
        # 只有执行时间超过10秒才调用 _open_aido_link
        if execution_time > 1:
            _open_aido_link(ctx, output_video_path)
        
        return result_message
    except ffmpeg.Error as e:
        error_message = e.stderr.decode('utf8') if e.stderr else str(e)
        raise RuntimeError(f"Error converting video properties: {error_message}")
    except FileNotFoundError:
        raise RuntimeError(f"Error: Input video file not found at {input_video_path}")
    except Exception as e:
        raise RuntimeError(f"An unexpected error occurred: {str(e)}")


# --- GIF Export ---
@mcp.tool()
def convert_video_to_gif(
        video_path: str,
        output_gif_path: str,
        fps: int = 8,
        width: int | None = None,
        height: int | None = None,
        keep_aspect: bool = True,
        start_time: str | float | None = None,
        dither: str = "floyd_steinberg",
        max_colors: int = 256,
        loop: int = 0,
        crop: dict | None = None,
        scale_flags: str = "lanczos",
        bayer_scale: int | None = 3,
        palette_stats_mode: str = "diff",
        use_reserve_transparent: bool = False,
        alpha_threshold: int = 128,
        ctx: Context = None
) -> str:
    """将视频片段高质量导出为 GIF（优化的 palettegen/paletteuse 两遍法）。

    Args:
        video_path: 输入视频路径。
        output_gif_path: 输出 GIF 路径（应以 .gif 结尾）。
        fps: GIF 帧率，建议 8~20 之间。
        width: 目标宽度（keep_aspect 为 True 时，height 需为空）。
        height: 目标高度（keep_aspect 为 True 时，width 需为空）。
        keep_aspect: 是否保持纵横比。
        start_time: 起始时间（秒或 'HH:MM:SS(.ms)'）。
        dither: 调色算法，支持 'none'|'bayer'|'floyd_steinberg'|'sierra2_4a'|'burkes'。
        max_colors: 调色板颜色数，2~256。
        loop: 循环次数（0 为无限循环）。
        crop: 裁剪参数，如 {"x":0, "y":0, "w":320, "h":240}。
        scale_flags: 缩放插值算法，如 'lanczos'|'bicubic' 等。
        bayer_scale: bayer 调色算法的缩放因子（0~5）。
        palette_stats_mode: 调色板统计模式，'single'|'diff'|'full'。
        use_reserve_transparent: 是否为透明度保留一个颜色槽。
        alpha_threshold: 透明度阈值（0-255）。

    Returns:
        A status message indicating success or failure.
    """
    # 记录开始时间
    execution_start_time = time.time()
    
    _prepare_path(video_path, output_gif_path)
    try:
        if not output_gif_path.lower().endswith(".gif"):
            raise RuntimeError("Error: output_gif_path must end with .gif")
        if fps <= 0:
            raise RuntimeError("Error: fps must be positive")
        if not (2 <= int(max_colors) <= 256):
            raise RuntimeError("Error: max_colors must be in [2, 256]")
        if loop < 0:
            raise RuntimeError("Error: loop must be >= 0")

        valid_dither = {"none", "bayer", "floyd_steinberg", "sierra2_4a", "burkes"}
        if dither not in valid_dither:
            raise RuntimeError(f"Error: Unsupported dither '{dither}'. Supported: {', '.join(sorted(valid_dither))}")
        if dither == "bayer" and bayer_scale is not None and not (0 <= int(bayer_scale) <= 5):
            raise RuntimeError("Error: bayer_scale must be in [0, 5]")

        valid_stats_modes = {"single", "diff", "full"}
        if palette_stats_mode not in valid_stats_modes:
            raise RuntimeError(f"Error: Unsupported palette_stats_mode '{palette_stats_mode}'. Supported: {', '.join(sorted(valid_stats_modes))}")
        
        if not (0 <= alpha_threshold <= 255):
            raise RuntimeError("Error: alpha_threshold must be in [0, 255]")

        if keep_aspect and (width and height):
            raise RuntimeError("Error: When keep_aspect=True, provide only width or height, not both")

        # 输入裁剪参数校验
        crop_params = None
        if crop is not None:
            required_keys = {"x", "y", "w", "h"}
            if not isinstance(crop, dict) or not required_keys.issubset(crop.keys()):
                raise RuntimeError("Error: crop must be a dict with keys {'x','y','w','h'}")
            crop_params = {
                "x": int(crop["x"]),
                "y": int(crop["y"]),
                "w": int(crop["w"]),
                "h": int(crop["h"]),
            }

        # 解析时间
        ss_arg = None
        if start_time is not None:
            ss_arg = _parse_time_to_seconds(start_time)

        # 构建公共滤镜链（两遍都要）
        def apply_common_filters(stream):
            filtered = stream
            filtered = filtered.filter("fps", fps)
            if crop_params:
                filtered = filtered.filter("crop", w=crop_params["w"], h=crop_params["h"], x=crop_params["x"],
                                           y=crop_params["y"])
            
            # 处理缩放逻辑
            if width or height:
                if keep_aspect:
                    # 保持宽高比的缩放
                    if width and height:
                        # 如果同时指定了宽度和高度，使用 scale 滤镜的 force_original_aspect_ratio 参数
                        filtered = filtered.filter("scale", width, height, 
                                                 force_original_aspect_ratio="decrease", 
                                                 flags=scale_flags)
                    elif width:
                        # 只指定宽度，高度自动计算，使用 iw*sar 确保精确缩放
                        filtered = filtered.filter("scale", f"{width}", f"{width}*ih/iw", flags=scale_flags)
                    elif height:
                        # 只指定高度，宽度自动计算，使用 ih/sar 确保精确缩放
                        filtered = filtered.filter("scale", f"{height}*iw/ih", f"{height}", flags=scale_flags)
                else:
                    # 不保持宽高比，强制缩放到指定尺寸
                    if width and height:
                        filtered = filtered.filter("scale", width, height, flags=scale_flags)
                    elif width:
                        filtered = filtered.filter("scale", width, -1, flags=scale_flags)
                    elif height:
                        filtered = filtered.filter("scale", -1, height, flags=scale_flags)
            
            # 使用更好的颜色空间处理
            # 先转换到 YUV420P 进行更好的颜色处理，然后再转为 RGB24
            filtered = filtered.filter("format", "yuv420p")
            filtered = filtered.filter("format", "rgb24")
            return filtered

        # 临时调色板文件
        temp_dir = tempfile.mkdtemp()
        palette_path = os.path.join(temp_dir, "palette.png")

        try:
            # 第一遍：生成调色板
            in1_kwargs = {}
            if ss_arg is not None:
                in1_kwargs["ss"] = ss_arg
            
            in1 = ffmpeg.input(video_path, **in1_kwargs) if in1_kwargs else ffmpeg.input(video_path)
            # 优化调色板生成参数
            palette_gen_params = {
                "stats_mode": palette_stats_mode,
                "max_colors": max_colors
            }
            if use_reserve_transparent:
                palette_gen_params["reserve_transparent"] = 1
            
            v1 = apply_common_filters(in1.video).filter("palettegen", **palette_gen_params)
            # 在部分 ffmpeg 版本中，image2 复用器会因多次写入同名文件报错；加 update=1 允许覆盖同名单文件
            _ffmpeg_run(ffmpeg.output(v1, palette_path, update=1), capture_stdout=True, capture_stderr=True)

            # 第二遍：应用调色板生成 GIF
            in2_kwargs = {}
            if ss_arg is not None:
                in2_kwargs["ss"] = ss_arg
                
            in2 = ffmpeg.input(video_path, **in2_kwargs) if in2_kwargs else ffmpeg.input(video_path)
            v2 = apply_common_filters(in2.video)
            pal = ffmpeg.input(palette_path)
            
            # 优化调色板应用参数
            paletteuse_params = {"dither": dither}
            if dither == "bayer" and bayer_scale is not None:
                paletteuse_params["bayer_scale"] = bayer_scale
            if use_reserve_transparent:
                paletteuse_params["alpha_threshold"] = alpha_threshold
            
            gif_v = ffmpeg.filter([v2, pal], "paletteuse", **paletteuse_params)
            _ffmpeg_run(
                ffmpeg.output(gif_v, output_gif_path, format="gif", loop=loop),
                capture_stdout=True,
                capture_stderr=True,
            )

            # 计算执行时间
            execution_time = time.time() - execution_start_time
            result_message = f"GIF created successfully at {output_gif_path}. Execution time: {execution_time:.2f} seconds."
            
            # 只有执行时间超过10秒才调用 _open_aido_link
            if execution_time > 1:
                _open_aido_link(ctx,output_gif_path)
            
            return result_message
        finally:
            try:
                shutil.rmtree(temp_dir)
            except Exception:
                pass
    except ffmpeg.Error as e:
        error_message = e.stderr.decode("utf8") if e.stderr else str(e)
        raise RuntimeError(f"Error converting video to GIF: {error_message}")
    except FileNotFoundError:
        raise RuntimeError("Error: Required file not found (input video or palette)")
    except Exception as e:
        raise RuntimeError(f"An unexpected error occurred in convert_video_to_gif: {str(e)}")


def main():
    """Main entry point for the MCP server."""
    mcp.run()


# Main execution block to run the server
if __name__ == "__main__":
    main()
import numpy as np
from concurrent.futures import ProcessPoolExecutor
from typing import Optional, Dict, Any
from ..experiment import Experiment
from ..features import (
    FeatureFileCreator, FeatureRepository, FeatureMetadata
)
import os
from pathlib import Path
from .create_version_utils import create_version_from_all_features

########################### æ—¥å¿—è®¾ç½® ################################
from ..logger_config import get_module_logger
logger = get_module_logger()
#####################################################################

def v2_feature(
    raw_file_path: str,
    output_dir: str = "data/features",
    period: Optional[float] = None,
    max_workers: Optional[int] = None,
    window_scalar_min: float = 0.2,
    window_scalar_max: float = 0.333,
    window_points_step: int = 10,
    show_progress: bool = False
) -> str:
    """
    ä½¿ç”¨ autotau åŒ…å’Œ features åŒ…åˆ›å»º transient ç‰¹å¾æ–‡ä»¶ï¼ˆtau_on å’Œ tau_offï¼‰

    è¯¥å‡½æ•°åˆ©ç”¨ autotau çš„å¹¶è¡Œèƒ½åŠ›æå– transient æ•°æ®çš„æ—¶é—´å¸¸æ•°ç‰¹å¾ã€‚

    Args:
        raw_file_path: åŸå§‹å®éªŒæ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º data/features/
        period: transient ä¿¡å·å‘¨æœŸï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸º None å°†ä»æ•°æ®ä¸­è‡ªåŠ¨ä¼°è®¡
        max_workers: å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ŒNone è¡¨ç¤ºä½¿ç”¨ CPU æ ¸å¿ƒæ•°
        window_scalar_min: çª—å£æœç´¢çš„æœ€å°æ ‡é‡ï¼ˆç›¸å¯¹äºå‘¨æœŸï¼‰ï¼Œé»˜è®¤ 0.2
        window_scalar_max: çª—å£æœç´¢çš„æœ€å¤§æ ‡é‡ï¼ˆç›¸å¯¹äºå‘¨æœŸï¼‰ï¼Œé»˜è®¤ 0.333
        window_points_step: çª—å£ç‚¹æ•°æ­¥é•¿ï¼Œé»˜è®¤ 10
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œé»˜è®¤ False

    Returns:
        åˆ›å»ºçš„ç‰¹å¾æ–‡ä»¶è·¯å¾„

    Raises:
        ValueError: å¦‚æœåŸå§‹æ–‡ä»¶ä¸åŒ…å« transient æ•°æ®
    """
    logger.info(f"=== åˆ›å»º Transient ç‰¹å¾æ–‡ä»¶ï¼ˆtau_on/tau_offï¼‰ ===")
    logger.info(f"åŸå§‹æ–‡ä»¶: {raw_file_path}")

    # ä»åŸå§‹æ–‡ä»¶åç”Ÿæˆç‰¹å¾æ–‡ä»¶å
    raw_path = Path(raw_file_path)
    feature_filename = FeatureFileCreator.parse_raw_filename_to_feature(raw_path.name)
    final_feature_file = os.path.join(output_dir, feature_filename)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    logger.info(f"è¾“å‡ºæ–‡ä»¶: {final_feature_file}")

    # ğŸ” æ£€æŸ¥ç‰¹å¾æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆ›å»ºHDF5æ–‡ä»¶ç»“æ„
    if os.path.exists(final_feature_file):
        logger.info(f"âœ… ç‰¹å¾æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡HDF5æ–‡ä»¶ç»“æ„åˆ›å»º")
        logger.info(f"ä½¿ç”¨ç°æœ‰æ–‡ä»¶: {final_feature_file}")
    else:
        logger.info("ğŸ“ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºHDF5æ–‡ä»¶ç»“æ„...")
        # éœ€è¦å…ˆåŠ è½½å®éªŒæ•°æ®ä»¥è·å–å…ƒæ•°æ®ä¿¡æ¯
        exp = Experiment(raw_file_path)
        summary = exp.get_experiment_summary()

        creator = FeatureFileCreator()
        creator.create_feature_file(
            final_feature_file,
            chip_id=summary['device_info']['chip_id'],
            device_id=summary['device_info']['device_number'],
            description=summary['basic_info']['description'],
            test_id=summary['basic_info']['test_id'],
            built_with="features v2.0.0 (autotau)"
        )
        logger.info(f"âœ… HDF5æ–‡ä»¶ç»“æ„åˆ›å»ºæˆåŠŸï¼š{final_feature_file}")

    # ğŸ“Š æ— è®ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œéƒ½è¦è¿›è¡Œç‰¹å¾æå–å’Œä¿å­˜ï¼ˆè¿™æ˜¯æ•°æ®æ›´æ–°æ“ä½œï¼‰
    logger.info("=" * 50)
    logger.info("å¼€å§‹ Transient ç‰¹å¾æå–å’Œä¿å­˜...")

    # 1. åŠ è½½å®éªŒæ•°æ®
    logger.info("1. åŠ è½½å®éªŒæ•°æ®...")
    exp = Experiment(raw_file_path)
    summary = exp.get_experiment_summary()
    logger.info(f"å®éªŒä¿¡æ¯: {summary['basic_info']}")
    logger.info(f"è®¾å¤‡ä¿¡æ¯: {summary['device_info']}")

    # 2. æ£€æŸ¥å¹¶åŠ è½½ Transient æ•°æ®
    logger.info("2. åŠ è½½ Transient æ•°æ®...")
    if not exp.has_transient_data():
        raise ValueError(f"æ— æ³•åˆ†æ Transient ç‰¹å¾ï¼Œæ–‡ä»¶ä¸­æ²¡æœ‰ Transient æ•°æ®: {raw_file_path}")

    transient_data = exp.get_transient_all_measurement()
    if transient_data is None:
        raise ValueError(f"æ— æ³•åŠ è½½ Transient æ•°æ®: {raw_file_path}")

    time = transient_data['continuous_time']
    signal = transient_data['drain_current']

    logger.info(f"Transient æ•°æ®ç‚¹æ•°: {len(time)}")
    logger.info(f"æ—¶é—´èŒƒå›´: {time[0]:.6f}s ~ {time[-1]:.6f}s")

    # 3. ä¼°è®¡é‡‡æ ·ç‡å’Œå‘¨æœŸ
    logger.info("3. ä¼°è®¡é‡‡æ ·ç‡å’Œå‘¨æœŸ...")
    # è®¡ç®—é‡‡æ ·ç‡ï¼ˆHzï¼‰
    dt = np.diff(time)
    sample_rate = 1.0 / np.mean(dt)
    logger.info(f"é‡‡æ ·ç‡: {sample_rate:.2f} Hz")

    # å¦‚æœç”¨æˆ·æœªæä¾›å‘¨æœŸï¼Œä»æ•°æ®ä¸­ä¼°è®¡
    if period is None:
        # ç®€å•ä¼°è®¡ï¼šå‡è®¾æ•°æ®åŒ…å«å¤šä¸ªå®Œæ•´å‘¨æœŸï¼Œå–æ€»æ—¶é•¿é™¤ä»¥å‘¨æœŸæ•°
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼Œæˆ–è¦æ±‚ç”¨æˆ·æä¾›
        total_duration = time[-1] - time[0]
        # å‡è®¾è‡³å°‘æœ‰10ä¸ªå‘¨æœŸ
        estimated_cycles = max(10, int(total_duration * sample_rate / 100))
        period = total_duration / estimated_cycles
        logger.info(f"âš ï¸ æœªæŒ‡å®šå‘¨æœŸï¼Œè‡ªåŠ¨ä¼°è®¡: {period:.6f}s ({estimated_cycles} ä¸ªå‘¨æœŸ)")
    else:
        logger.info(f"ä½¿ç”¨æŒ‡å®šå‘¨æœŸ: {period:.6f}s")

    # è®¡ç®—ç†è®ºå‘¨æœŸæ•°
    total_cycles = int((time[-1] - time[0]) / period)
    logger.info(f"ç†è®ºå‘¨æœŸæ•°: {total_cycles}")

    # 4. ä½¿ç”¨ autotau æå– tau_on å’Œ tau_offï¼ˆå¤šæ ¸å¹¶è¡Œï¼‰
    logger.info("4. ä½¿ç”¨ autotau æå– tau_on å’Œ tau_offï¼ˆå¤šæ ¸å¹¶è¡Œï¼‰...")

    try:
        from autotau import CyclesAutoTauFitter, AutoTauFitter

        # åˆ›å»ºå¹¶è¡Œæ‰§è¡Œå™¨
        executor = ProcessPoolExecutor(max_workers=max_workers)
        logger.info(f"å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°: {max_workers if max_workers else 'é»˜è®¤ï¼ˆCPUæ ¸å¿ƒæ•°ï¼‰'}")

        # å®šä¹‰ fitter_factory ä»¥æ³¨å…¥å¹¶è¡Œèƒ½åŠ›
        def fitter_factory(time_slice, signal_slice, **kwargs):
            """åˆ›å»ºæ”¯æŒå¹¶è¡Œçª—å£æœç´¢çš„ AutoTauFitter"""
            return AutoTauFitter(
                time=time_slice,
                signal=signal_slice,
                sample_step=int(kwargs.get('sample_step', 1)),
                period=kwargs.get('period', period),
                window_scalar_min=window_scalar_min,
                window_scalar_max=window_scalar_max,
                window_points_step=window_points_step,
                normalize=False,
                show_progress=False,  # å•ä¸ªå‘¨æœŸä¸æ˜¾ç¤ºè¿›åº¦
                executor=executor  # ğŸš€ æ³¨å…¥å¹¶è¡Œæ‰§è¡Œå™¨
            )

        # åˆ›å»º CyclesAutoTauFitter
        cycles_fitter = CyclesAutoTauFitter(
            time=time,
            signal=signal,
            period=period,
            sample_rate=sample_rate,
            fitter_factory=fitter_factory
        )

        logger.info("å¼€å§‹æ‹Ÿåˆæ‰€æœ‰å‘¨æœŸ...")

        # æ‹Ÿåˆæ‰€æœ‰å‘¨æœŸ
        results = cycles_fitter.fit_all_cycles(
            interp=True,
            points_after_interp=100,
            r_squared_threshold=0.95
        )

        # å…³é—­æ‰§è¡Œå™¨
        executor.shutdown(wait=True)

        logger.info(f"æ‹Ÿåˆå®Œæˆï¼Œå…± {len(results)} ä¸ªå‘¨æœŸ")

    except Exception as e:
        logger.error(f"âŒ autotau æ‹Ÿåˆå¤±è´¥: {e}")
        raise

    # 5. æå–ç‰¹å¾æ•°æ®
    logger.info("5. æå–ç‰¹å¾æ•°æ®...")

    # åˆå§‹åŒ–ç‰¹å¾æ•°ç»„
    tau_on_list = []
    tau_off_list = []
    tau_on_r2_list = []
    tau_off_r2_list = []

    for cycle_idx, cycle_result in enumerate(results):
        # æ£€æŸ¥æ‹Ÿåˆæ˜¯å¦æˆåŠŸ
        if cycle_result.get('status') == 'success':
            tau_on = cycle_result.get('tau_on', np.nan)
            tau_off = cycle_result.get('tau_off', np.nan)
            tau_on_r2 = cycle_result.get('tau_on_r2', np.nan)
            tau_off_r2 = cycle_result.get('tau_off_r2', np.nan)
        else:
            tau_on = np.nan
            tau_off = np.nan
            tau_on_r2 = np.nan
            tau_off_r2 = np.nan
            logger.warning(f"å‘¨æœŸ {cycle_idx} æ‹Ÿåˆå¤±è´¥")

        tau_on_list.append(tau_on)
        tau_off_list.append(tau_off)
        tau_on_r2_list.append(tau_on_r2)
        tau_off_r2_list.append(tau_off_r2)

    # è½¬æ¢ä¸º numpy æ•°ç»„
    features_data = {
        'tau_on': np.array(tau_on_list, dtype=np.float32),
        'tau_off': np.array(tau_off_list, dtype=np.float32),
        'tau_on_r2': np.array(tau_on_r2_list, dtype=np.float32),
        'tau_off_r2': np.array(tau_off_r2_list, dtype=np.float32),
    }

    step_count = len(tau_on_list)
    feature_count = len(features_data)
    logger.info(f"æå–äº† {feature_count} ä¸ªç‰¹å¾ï¼Œ{step_count} ä¸ªæ­¥éª¤ï¼ˆå‘¨æœŸï¼‰")

    # ç»Ÿè®¡æ‹Ÿåˆè´¨é‡
    valid_tau_on = np.sum(~np.isnan(features_data['tau_on']))
    valid_tau_off = np.sum(~np.isnan(features_data['tau_off']))
    logger.info(f"æœ‰æ•ˆ tau_on: {valid_tau_on}/{step_count}")
    logger.info(f"æœ‰æ•ˆ tau_off: {valid_tau_off}/{step_count}")

    if valid_tau_on > 0:
        mean_tau_on = np.nanmean(features_data['tau_on'])
        std_tau_on = np.nanstd(features_data['tau_on'])
        logger.info(f"tau_on ç»Ÿè®¡: mean={mean_tau_on:.6f}s, std={std_tau_on:.6f}s")

    if valid_tau_off > 0:
        mean_tau_off = np.nanmean(features_data['tau_off'])
        std_tau_off = np.nanstd(features_data['tau_off'])
        logger.info(f"tau_off ç»Ÿè®¡: mean={mean_tau_off:.6f}s, std={std_tau_off:.6f}s")

    # 6. å­˜å‚¨ç‰¹å¾æ•°æ®
    logger.info("6. å­˜å‚¨ç‰¹å¾æ•°æ®...")
    repo = FeatureRepository(final_feature_file)

    # å®šä¹‰ç‰¹å¾å…ƒæ•°æ®
    feature_metadata = {
        'tau_on': FeatureMetadata(
            name='tau_on',
            unit='s',
            description='Turn-on time constant extracted by autotau'
        ),
        'tau_off': FeatureMetadata(
            name='tau_off',
            unit='s',
            description='Turn-off time constant extracted by autotau'
        ),
        'tau_on_r2': FeatureMetadata(
            name='tau_on_r2',
            unit='',
            description='R-squared for tau_on fit'
        ),
        'tau_off_r2': FeatureMetadata(
            name='tau_off_r2',
            unit='',
            description='R-squared for tau_off fit'
        ),
    }

    # æ‰¹é‡å­˜å‚¨ç‰¹å¾ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
    results = repo.store_multiple_features(
        features_data,
        data_type="transient",
        metadata_dict=feature_metadata,
        bucket_name="bk_00",
        overwrite=True
    )

    successful_features = sum(results.values())
    logger.info(f"æˆåŠŸå­˜å‚¨ {successful_features}/{feature_count} ä¸ªç‰¹å¾")

    # 7. ä½¿ç”¨é€šç”¨ç‰ˆæœ¬åŒ–å·¥å…·åˆ›å»ºç‰ˆæœ¬å’ŒéªŒè¯
    logger.info("7. åˆ›å»ºç‰ˆæœ¬ v2 å¹¶éªŒè¯...")
    version_success = create_version_from_all_features(
        repo=repo,
        version_name="v2",
        exp=exp,
        data_type="transient",
        include_verification=True
    )

    if not version_success:
        logger.error(f"âŒ ç‰ˆæœ¬v2åˆ›å»ºæˆ–éªŒè¯å¤±è´¥")

    # å®ŒæˆçŠ¶æ€
    if version_success:
        logger.info(f"âœ… ç‰¹å¾æ–‡ä»¶åˆ›å»ºå®Œæˆ: {Path(final_feature_file).name}")
    else:
        logger.error(f"âŒ ç‰¹å¾æ–‡ä»¶åˆ›å»ºå¤±è´¥: {Path(final_feature_file).name}")

    return final_feature_file


def estimate_period_from_signal(time: np.ndarray, signal: np.ndarray) -> float:
    """
    ä»ä¿¡å·ä¸­è‡ªåŠ¨ä¼°è®¡å‘¨æœŸ

    ä½¿ç”¨è‡ªç›¸å…³æˆ– FFT æ–¹æ³•ä¼°è®¡ä¿¡å·çš„ä¸»è¦å‘¨æœŸ

    Args:
        time: æ—¶é—´æ•°ç»„
        signal: ä¿¡å·æ•°ç»„

    Returns:
        ä¼°è®¡çš„å‘¨æœŸï¼ˆç§’ï¼‰
    """
    try:
        from scipy import signal as sp_signal
        from scipy.fft import fft, fftfreq

        # æ–¹æ³•1ï¼šä½¿ç”¨ FFT æ‰¾åˆ°ä¸»é¢‘ç‡
        N = len(signal)
        sample_rate = 1.0 / np.mean(np.diff(time))

        # å»é™¤ç›´æµåˆ†é‡
        signal_detrend = signal - np.mean(signal)

        # FFT
        yf = fft(signal_detrend)
        xf = fftfreq(N, 1.0 / sample_rate)

        # åªçœ‹æ­£é¢‘ç‡éƒ¨åˆ†
        pos_mask = xf > 0
        xf_pos = xf[pos_mask]
        yf_pos = np.abs(yf[pos_mask])

        # æ‰¾åˆ°æœ€å¤§å¹…å€¼å¯¹åº”çš„é¢‘ç‡
        peak_idx = np.argmax(yf_pos)
        dominant_freq = xf_pos[peak_idx]

        if dominant_freq > 0:
            period = 1.0 / dominant_freq
            logger.info(f"FFT ä¼°è®¡å‘¨æœŸ: {period:.6f}s (é¢‘ç‡: {dominant_freq:.2f} Hz)")
            return period
        else:
            raise ValueError("æ— æ³•ä» FFT ä¸­æ‰¾åˆ°æœ‰æ•ˆé¢‘ç‡")

    except Exception as e:
        logger.warning(f"è‡ªåŠ¨ä¼°è®¡å‘¨æœŸå¤±è´¥: {e}")
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•çš„ç»éªŒå€¼
        total_duration = time[-1] - time[0]
        estimated_period = total_duration / 10  # å‡è®¾è‡³å°‘10ä¸ªå‘¨æœŸ
        logger.info(f"ä½¿ç”¨é™çº§æ–¹æ¡ˆä¼°è®¡å‘¨æœŸ: {estimated_period:.6f}s")
        return estimated_period

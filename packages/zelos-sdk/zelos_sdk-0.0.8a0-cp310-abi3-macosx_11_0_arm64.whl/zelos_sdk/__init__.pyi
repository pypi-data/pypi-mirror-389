# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import typing
from . import mock

class DataSegment:
    r"""
    Python wrapper for a data segment.
    
    Represents a segment of trace data with metadata about its time range
    and producer.
    """
    id: str
    producer: str
    start_date: typing.Optional[str]
    end_date: typing.Optional[str]
    def __repr__(self) -> str:
        ...


class DataType:
    def __repr__(self) -> str:
        ...


class QueryResult:
    r"""
    Python wrapper for query results.
    
    Contains the results of a trace data query, including field names,
    the raw Arrow data as Python bytes, and the SQL query that was executed.
    """
    fields: list[str]
    sql: str
    arrow_data: list[int]
    def __repr__(self) -> str:
        ...

    def to_arrow(self) -> bytes:
        r"""
        Convert the Arrow data to a Python object that can be read by PyArrow.
        
        Returns:
            bytes: Arrow IPC stream data
        
        Examples:
            >>> import pyarrow as pa
            >>> result = reader.query(...)
            >>> arrow_bytes = result.to_arrow()
            >>> reader = pa.ipc.open_stream(arrow_bytes)
            >>> table = reader.read_all()
        """
        ...


class TimeRange:
    r"""
    Python wrapper for time range.
    
    Represents a time interval with start and end timestamps.
    """
    start: str
    end: str
    def __repr__(self) -> str:
        ...


class TraceEventFieldMetadata:
    r"""
    Metadata describing a field in a trace event schema.
    
    This class defines the structure of a field within an event schema,
    including its name, data type, and optional unit of measurement.
    
    Args:
        name (str): The field name.
        data_type (DataType): The data type for the field.
        unit (Optional[str]): Optional unit of measurement.
    
    Examples:
        >>> # Define a field for HTTP status code
        >>> status_field = TraceEventFieldMetadata("status_code", DataType.Int32)
        >>>
        >>> # Define a field with a unit of measurement
        >>> duration_field = TraceEventFieldMetadata(
        ...     "duration_ms", DataType.Float64, "milliseconds")
    """
    name: str
    data_type: DataType
    unit: typing.Optional[str]
    def __new__(cls,name,data_type,unit = ...): ...
    def __repr__(self) -> str:
        ...


class TraceMetadata:
    r"""
    Python wrapper for trace metadata.
    
    Contains information about a complete trace including its time range,
    producer, and associated data segments.
    """
    id: str
    name: str
    start_date: str
    end_date: str
    producer: str
    data_segments: list[str]
    def __repr__(self) -> str:
        ...


class TraceNamespace:
    r"""
    A namespace that manages and organizes TraceSources.
    
    TraceNamespace provides a centralized registry for TraceSources with an isolated router.
    Each namespace has its own router, allowing complete isolation between different
    namespaces for testing or multi-tenant scenarios.
    
    Examples:
        >>> # Create an isolated namespace
        >>> ns = TraceNamespace("my_app")
        >>> source = TraceSource("service", namespace=ns)
        >>> with TraceWriter("data.trz", namespace=ns) as writer:
        ...     source.log("event", value=42)
    """
    name: str
    def __new__(cls,name:str): ...
    def source_count(self) -> int:
        r"""
        Get the number of registered sources.
        
        Returns:
            int: Number of registered sources.
        
        Examples:
            >>> count = namespace.source_count()
            >>> print(f"Registered sources: {count}")
        """
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the namespace.
        """
        ...

    def __del__(self) -> None:
        r"""
        Python destructor - cleanup namespace resources.
        
        This is idempotent and safe to call multiple times. The global namespace
        is also cleaned up via atexit, so this ensures cleanup happens even if
        __del__ isn't called (which is not guaranteed in Python).
        """
        ...


class TracePublishClient:
    r"""
    Client for publishing trace events to a Zelos Cloud service.
    
    This client manages the connection to a remote trace service and
    provides the communication channel needed by TraceSource objects
    to transmit events. It handles batching, retries, and connection management.
    
    Examples:
        >>> # Create a client with default settings
        >>> client = TracePublishClient()
        >>>
        >>> # Create a client with custom configuration
        >>> config = TracePublishClientConfig(url="grpc://localhost:2300")
        >>> client = TracePublishClient(config)
    """
    def __new__(cls,url = ...,config = ...): ...
    def shutdown(self) -> None:
        r"""
        Shutdown the client and all background tasks.
        
        This will cancel the background tasks and wait for them to complete.
        After calling this method, the client should not be used further.
        """
        ...

    def is_connected(self) -> bool:
        ...

    def __del__(self) -> None:
        r"""
        Python destructor - automatically shutdown background tasks
        """
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the client.
        """
        ...


class TracePublishClientConfig:
    r"""
    Configuration for the PyTracePublishClient.
    
    This class allows customizing the behavior of trace publishing, including:
    - Batch size: Number of events to batch before sending
    - Batch timeout: Maximum time to wait before sending a partial batch
    
    Examples:
        >>> config = TracePublishClientConfig(
        ...     batch_size=500,
        ...     batch_timeout_ms=2000,
        ... )
        >>> client = TracePublishClient(config)
    """
    batch_size: int
    batch_timeout_ms: int
    def __new__(cls,batch_size = ...,batch_timeout_ms = ...): ...
    def __repr__(self) -> str:
        r"""
        String representation of the configuration.
        """
        ...

    def set_batch_size(self, size:int) -> None:
        r"""
        Set the configured batch size.
        """
        ...

    def set_batch_timeout_ms(self, ms:int) -> None:
        r"""
        Set the configured batch timeout in milliseconds.
        """
        ...


class TraceReadEvent:
    r"""
    Python wrapper for a trace read event.
    
    Represents an event containing multiple fields.
    """
    name: str
    path: str
    fields: list[TraceReadEventField]
    def __repr__(self) -> str:
        ...


class TraceReadEventField:
    r"""
    Python wrapper for a trace read event field.
    
    Represents a single field within an event.
    """
    name: str
    path: str
    def __repr__(self) -> str:
        ...


class TraceReadSource:
    r"""
    Python wrapper for a trace read source.
    
    Represents a source (e.g., "can") containing multiple events.
    """
    name: str
    events: list[TraceReadEvent]
    def __repr__(self) -> str:
        ...


class TraceReader:
    r"""
    Python wrapper for the TraceReader.
    
    This reader provides read-only access to trace files, allowing you to
    query metadata and retrieve trace data programmatically. It supports
    listing data segments, querying time ranges, and retrieving raw or
    downsampled data.
    
    The reader uses context management and should be used with a `with` statement
    to ensure proper resource cleanup.
    
    # Complete End-to-End Workflow
    
    This example demonstrates opening a trace file, discovering available fields,
    and querying specific data:
    
    ```python
    import zelos_sdk
    import pyarrow as pa
    
    # Open trace file for reading
    with zelos_sdk.TraceReader("recording.trz") as reader:
        # Discover available segments
        segments = reader.list_data_segments()
        assert len(segments) > 0
    
        # Discover available fields hierarchically
        sources = reader.list_fields()
        assert len(sources) > 0
    
        # Navigate hierarchy: source → event → field
        can_source = next(s for s in sources if s.name == "can")
        msg_event = next(e for e in can_source.events if e.name == "VehicleSpeed")
        speed_field = next(f for f in msg_event.fields if f.name == "speed")
    
        # Query discovered field
        time_range = reader.time_range()
        result = reader.query(
            data_segment_ids=[s.id for s in segments],
            fields=[speed_field.path],  # "*/can/VehicleSpeed.speed"
            start=time_range.start,
            end=time_range.end,
        )
    
        # Verify data received
        arrow_reader = pa.ipc.open_stream(result.to_arrow())
        table = arrow_reader.read_all()
        assert table.num_rows > 0
        assert speed_field.path in result.fields or any(speed_field.path in s for s in result.fields)
    ```
    """
    path: str
    def __new__(cls,path:str): ...
    def open(self) -> None:
        r"""
        Open the trace file for reading.
        
        This method initializes the reader and opens the trace file in
        read-only mode. It's automatically called when entering the
        context manager (with statement).
        
        Returns:
            None
        
        Raises:
            RuntimeError: If the trace file cannot be opened.
        """
        ...

    def __enter__(self) -> TraceReader:
        ...

    def close(self) -> None:
        r"""
        Close the trace reader.
        
        This method closes the trace file and releases resources. It's
        automatically called when exiting the context manager.
        
        Returns:
            None
        """
        ...

    def __exit__(self, _exc_type:typing.Optional[typing.Any], _exc_value:typing.Optional[typing.Any], _traceback:typing.Optional[typing.Any]) -> None:
        ...

    def time_range(self) -> TimeRange:
        r"""
        Get the time range covered by the trace.
        
        Returns:
            TimeRange: Object containing start and end timestamps.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> with TraceReader("my_trace.trz") as reader:
            ...     time_range = reader.time_range()
            ...     print(f"Start: {time_range.start}")
            ...     print(f"End: {time_range.end}")
        """
        ...

    def list_data_segments(self) -> list[DataSegment]:
        r"""
        List all data segments in the trace.
        
        Returns:
            List[DataSegment]: List of data segment metadata.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> with TraceReader("my_trace.trz") as reader:
            ...     segments = reader.list_data_segments()
            ...     for seg in segments:
            ...         print(f"Segment {seg.id}: {seg.producer}")
        """
        ...

    def list_data_segments_in_time_range(self, start:str, end:str) -> list[DataSegment]:
        r"""
        List data segments within a specific time range.
        
        Args:
            start (datetime): Start of time range (inclusive).
            end (datetime): End of time range (inclusive).
        
        Returns:
            List[DataSegment]: List of data segments overlapping the time range.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> from datetime import datetime, timezone
            >>> start = datetime(2024, 1, 1, tzinfo=timezone.utc)
            >>> end = datetime(2024, 1, 2, tzinfo=timezone.utc)
            >>> with TraceReader("my_trace.trz") as reader:
            ...     segments = reader.list_data_segments_in_time_range(start, end)
        """
        ...

    def list_traces(self) -> list[TraceMetadata]:
        r"""
        List all traces in the trace file.
        
        Returns:
            List[TraceMetadata]: List of trace metadata.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> with TraceReader("my_trace.trz") as reader:
            ...     traces = reader.list_traces()
            ...     for trace in traces:
            ...         print(f"Trace {trace.name}: {trace.start_date} to {trace.end_date}")
        """
        ...

    def query(self, data_segment_ids:typing.Sequence[str], fields:typing.Sequence[str], start:str, end:str) -> QueryResult:
        r"""
        Query data for specified fields within a time range.
        
        This returns raw, unsampled data for the requested fields.
        
        Args:
            data_segment_ids (List[str]): List of data segment IDs to query.
            fields (List[str]): List of field paths (e.g., "bus0/msg1/sig1").
            start (datetime): Start of time range (inclusive).
            end (datetime): End of time range (inclusive).
        
        Returns:
            QueryResult: Query results with Arrow data.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> with TraceReader("my_trace.trz") as reader:
            ...     segments = reader.list_data_segments()
            ...     time_range = reader.time_range()
            ...     result = reader.query(
            ...         data_segment_ids=[s.id for s in segments],
            ...         fields=["bus0/msg1/sig1", "bus0/msg2/sig3"],
            ...         start=time_range.start,
            ...         end=time_range.end,
            ...     )
            ...     # Convert to PyArrow table
            ...     import pyarrow as pa
            ...     arrow_reader = pa.ipc.open_stream(result.to_arrow())
            ...     table = arrow_reader.read_all()
            ...     df = table.to_pandas()
        """
        ...

    def get_value_table(self, data_segment_id:str, field_path:str) -> typing.Optional[dict[int, str]]:
        r"""
        Get the value table (enum mapping) for a specific field.
        
        Args:
            data_segment_id (str): Data segment ID to query.
            field_path (str): Field path in format "source/event.field"
                (without the "*/" prefix).
        
        Returns:
            dict: Mapping of integer keys to string values, or None if no value table exists.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        Examples:
            >>> with TraceReader("my_trace.trz") as reader:
            ...     segments = reader.list_data_segments()
            ...     # Get enum mapping for a status field
            ...     status_map = reader.get_value_table(
            ...         segments[0].id,
            ...         "controller/state.status"
            ...     )
            ...     if status_map:
            ...         print(status_map)  # {0: "IDLE", 1: "RUNNING", 2: "ERROR"}
        """
        ...

    def list_fields(self, data_segment_id = ...) -> list[TraceReadSource]:
        r"""
        List all fields in the trace organized by source and event.
        
        This method discovers all available fields in the trace by querying
        the database schema and organizing them hierarchically by source and event.
        
        Args:
            data_segment_id (str, optional): Specific data segment ID to query.
                If None, queries all segments.
        
        Returns:
            List[TraceReadSource]: List of sources, each containing events and fields.
        
        Raises:
            RuntimeError: If the reader is not open or query fails.
        
        # Example: Discover and Query Fields
        
        ```python
        with TraceReader("recording.trz") as reader:
            # Discover all available fields
            sources = reader.list_fields()
            assert len(sources) > 0
        
            # Navigate the hierarchy
            for source in sources:
                for event in source.events:
                    for field in event.fields:
                        # field.path is the field path for queries (e.g., "*/can/VehicleSpeed.speed")
                        assert field.path.startswith("*/") and "." in field.path
        ```
        """
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the reader.
        """
        ...


class TraceSender:
    r"""
    Communication channel for sending trace events.
    
    This class is typically obtained from a TracePublishClient and passed to
    a TraceSource during creation. It handles the underlying message transport.
    
    Note:
        Users generally don't need to interact with this class directly;
        it's used internally to connect TraceSource to TracePublishClient.
    """
    ...

class TraceSource:
    r"""
    Central source for trace events in an application.
    
    A TraceSource represents a single data source within your application
    (like a service or component) and manages the event schemas and transmission
    of events to the trace collection system.
    
    Examples:
        >>> client = TracePublishClient()
        >>> source = TraceSource("motor_controller")
        >>>
        >>> # Define an event schema
        >>> motor_event = source.add_event("motor_stats", [
        ...     TraceEventFieldMetadata("rpm", DataType.Float64),
        ...     TraceEventFieldMetadata("torque", DataType.Float64, "Nm"),
        ...     TraceEventFieldMetadata("temperature", DataType.Float64, "celsius"),
        ...     TraceEventFieldMetadata("voltage", DataType.Float64, "V"),
        ... ])
        >>>
        >>> # Log an event
        >>> motor_event.log(**{
        ...     "rpm": 3500.0,
        ...     "torque": 42.8,
        ...     "temperature": 75.5,
        ...     "voltage": 48.2
        ... })
    """
    name: str
    __getattr__: TraceSourceEvent
    def __new__(cls,name,namespace = ...): ...
    def add_value_table(self, name,field_name,data) -> None:
        r"""
        Add a value table to the trace source.
        
        Args:
            name (str): The name of the value table.
            data (dict): A dictionary of values to add to the value table.
        
        Returns:
            None
        
        Examples:
            >>> source.add_value_table("motor_status", "state", {0: "stopped", 1: "running"})
            >>> source.add_value_table("sensor_data", "sensor_id", {1: "temp_sensor", 2: "pressure_sensor"})
        """
        ...

    def add_event_from_dict(self, name,data) -> TraceSourceEvent:
        ...

    def log_dict_at(self, time_ns:int, name:str, data:dict) -> None:
        ...

    def log_dict(self, name,data) -> None:
        r"""
        Log an event with a name and a dictionary of fields.
        
        Args:
            name (str): The name to log.
            data (dict): A dictionary of fields to log.
            prefix (str): A prefix to add to the event name.
        
        Returns:
            None
        
        Examples:
            >>> source.log_dict("sensor_data", {"temperature": 25.0, "pressure": 101325})
        """
        ...

    def log(self, name,data) -> None:
        r"""
        Log an event with a name and a dictionary of fields.
        
        Args:
            name (str): The name to log.
            data (dict): A dictionary of fields to log.
        
        Returns:
            None
        
        Examples:
            >>> source.log("sensor_data", {"temperature": 25.0, "pressure": 101325})
        """
        ...

    def log_at(self, time_ns:int, name:str, data:dict) -> None:
        r"""
        Log an event with a name and a dictionary of fields.
        
        Args:
            time_ns (int): The time to log the event at.
            name (str): The name to log.
            data (dict): A dictionary of fields to log.
        
        Returns:
            None
        
        Examples:
            >>> source.log_at(time.time_ns(), "sensor_data", {"temperature": 25.0})
        """
        ...

    def get_event(self, name:str) -> TraceSourceEvent:
        r"""
        Get a handle to a previously registered event schema.
        
        Args:
            name (str): The name of the event schema.
        
        Returns:
            TraceSourceEvent: A handle to the event.
        
        Raises:
            KeyError: If no event with the given name is registered.
        
        Examples:
            >>> # After defining an event schema
            >>> event = source.get_event("motor_stats")
        """
        ...

    def add_event(self, name,schema) -> TraceSourceEvent:
        r"""
        Directly registers an event schema defined by a list of TraceEventFieldMetadata.
        Useful if the schema is constructed programmatically.
        
        Args:
            name (str): The name for the event schema.
            schema (list[TraceEventFieldMetadata]): List defining the fields.
        
        Returns:
            TraceSourceEvent: A handle to the newly registered event.
        
        Raises:
            ValueError: If registering the schema fails internally.
        """
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the source.
        """
        ...


class TraceSourceEvent:
    ...

class TraceStdout:
    r"""
    Python wrapper for the stdout trace sink.
    
    This sink outputs trace events to stdout with configurable log levels.
    It subscribes to all trace events from the router and formats them as
    structured log messages.
    
    The sink uses context management and should be used with a `with` statement
    to ensure proper resource cleanup and automatic start/stop of trace capture.
    
    Examples:
        >>> # Basic usage with default settings (info level)
        >>> with TraceStdout() as sink:
        ...     # Trace events will be logged to stdout
        ...     pass
        >>>
        >>> # Custom log level and batch configuration
        >>> with TraceStdout(log_level="debug", batch_size=500, batch_timeout_ms=2000) as sink:
        ...     # Trace events will be logged with custom settings
        ...     pass
    """
    log_level: str
    def __new__(cls,log_level = ...,batch_size = ...,batch_timeout_ms = ...): ...
    def open(self) -> None:
        r"""
        Start the stdout sink and begin capturing events.
        
        This method subscribes to the trace router and starts a background task
        to process and output trace events to stdout. It's automatically called
        when entering the context manager (with statement).
        
        Returns:
            None
        
        Raises:
            RuntimeError: If the sink cannot be initialized.
        """
        ...

    def __enter__(self) -> TraceStdout:
        ...

    def close(self) -> None:
        r"""
        Stop the stdout sink and finalize trace capture.
        
        This method gracefully shuts down the sink and cancels background tasks.
        It's automatically called when exiting the context manager.
        
        Returns:
            None
        """
        ...

    def __exit__(self, _exc_type:typing.Optional[typing.Any], _exc_value:typing.Optional[typing.Any], _traceback:typing.Optional[typing.Any]) -> None:
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the sink.
        """
        ...


class TraceValue:
    ...

class TraceWriter:
    r"""
    Python wrapper for the TraceWriter.
    
    This writer manages writing trace events to a local file, with support for
    batching and buffering. It can be used with a TraceSource to capture events
    for later analysis.
    
    The writer uses context management and should be used with a `with` statement
    to ensure proper resource cleanup and automatic start/stop of trace capture.
    
    Examples:
        >>> # Basic usage with default settings
        >>> with TraceWriter("my_trace.trz") as writer:
        ...     # Trace events will be captured automatically
        ...     pass
        >>>
        >>> # Custom batch configuration
        >>> with TraceWriter("my_trace.trz", batch_size=500, batch_timeout_ms=2000) as writer:
        ...     # Trace events will be captured with custom batch settings
        ...     pass
    """
    path: str
    def __new__(cls,path,batch_size = ...,batch_timeout_ms = ...,allow_existing = ...,namespace = ...): ...
    def open(self) -> None:
        r"""
        Start the trace writer and begin capturing events.
        
        This method initializes the writer and starts background tasks for
        batching and writing trace events. It's automatically called when
        entering the context manager (with statement).
        
        Returns:
            None
        
        Raises:
            RuntimeError: If the writer cannot be initialized.
        
        Note:
            This method is called automatically by __enter__ when using
            the context manager pattern.
        """
        ...

    def __enter__(self) -> TraceWriter:
        ...

    def close(self) -> None:
        r"""
        Stop the trace writer and finalize trace capture.
        
        This method gracefully shuts down the writer, cancels background tasks,
        and ensures all buffered events are written to the trace file. It's
        automatically called when exiting the context manager.
        
        Returns:
            None
        
        Note:
            This method is called automatically by __exit__ when using
            the context manager pattern.
        """
        ...

    def __exit__(self, _exc_type:typing.Optional[typing.Any], _exc_value:typing.Optional[typing.Any], _traceback:typing.Optional[typing.Any]) -> None:
        ...

    def __repr__(self) -> str:
        r"""
        String representation of the writer.
        """
        ...


def enable_logging(log_level = ...) -> None:
    r"""
    Enable logging for the Zelos SDK native module.
    
    This function initializes the tracing system with the specified log level.
    If no log level is provided, it defaults to "info".
    
    Args:
        log_level (Optional[str]): The log level to use.
            Valid values: "trace", "debug", "info", "warn", "error".
            Defaults to "info" if not specified.
    
    Returns:
        None
    
    Examples:
        >>> enable_logging("debug")  # Set log level to debug
        >>> enable_logging("info")   # Set log level to info
        >>> enable_logging()         # Set log level to info
    """
    ...

def get_global_router_sender() -> TraceSender:
    r"""
    Get the global default trace router sender (from global namespace)
    
    Returns:
        TraceSender: The global namespace's router sender
    
    Examples:
        >>> sender = get_global_router_sender()
    """
    ...

def log(name,data,source = ...) -> None:
    ...


"""
æœºå™¨å­¦ä¹ è¯„ä¼°å’Œæ¯”è¾ƒæ¨¡å—
åŒ…å«äº¤å‰éªŒè¯ã€ç‰¹å¾é‡è¦æ€§åˆ†æå’Œæ¨¡å‹æ¯”è¾ƒåŠŸèƒ½
"""

import numpy as np
from typing import List, Dict, Any, Optional
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso, Ridge
import warnings
warnings.filterwarnings('ignore')

from .ml_models import CrossValidationResult, FeatureImportanceResult
from .ml_ensemble import random_forest_regression, gradient_boosting_regression
from .ml_regularization import lasso_regression, ridge_regression


def cross_validation(
    y_data: List[float],
    x_data: List[List[float]],
    model_type: str = "random_forest",
    cv_folds: int = 5,
    scoring: str = "r2",
    **model_params
) -> CrossValidationResult:
    """
    äº¤å‰éªŒè¯
    
    ğŸ“Š åŠŸèƒ½è¯´æ˜ï¼š
    é€šè¿‡äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚
    
    ğŸ“ˆ éªŒè¯æ–¹æ³•ï¼š
    - KæŠ˜äº¤å‰éªŒè¯ï¼šå°†æ•°æ®åˆ†ä¸ºKä»½ï¼Œè½®æµä½¿ç”¨K-1ä»½è®­ç»ƒï¼Œ1ä»½æµ‹è¯•
    - ç¨³å®šæ€§è¯„ä¼°ï¼šé€šè¿‡å¤šæ¬¡éªŒè¯è¯„ä¼°æ¨¡å‹ç¨³å®šæ€§
    - æ³›åŒ–èƒ½åŠ›ï¼šè¯„ä¼°æ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„è¡¨ç°
    
    ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
    - æ¨¡å‹é€‰æ‹©å’Œæ¯”è¾ƒ
    - è¶…å‚æ•°è°ƒä¼˜
    - è¯„ä¼°æ¨¡å‹ç¨³å®šæ€§
    - é˜²æ­¢è¿‡æ‹Ÿåˆ
    
    âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
    - è®¡ç®—æˆæœ¬è¾ƒé«˜
    - éœ€è¦è¶³å¤Ÿçš„æ•°æ®é‡
    - æŠ˜æ•°é€‰æ‹©å½±å“ç»“æœç¨³å®šæ€§
    
    Args:
        y_data: å› å˜é‡æ•°æ®
        x_data: è‡ªå˜é‡æ•°æ®ï¼ŒäºŒç»´åˆ—è¡¨æ ¼å¼
        model_type: æ¨¡å‹ç±»å‹ï¼ˆrandom_forest, gradient_boosting, lasso, ridgeï¼‰
        cv_folds: äº¤å‰éªŒè¯æŠ˜æ•°ï¼Œé»˜è®¤5
        scoring: è¯„åˆ†æŒ‡æ ‡ï¼Œé»˜è®¤"r2"
        **model_params: æ¨¡å‹å‚æ•°
    
    Returns:
        CrossValidationResult: äº¤å‰éªŒè¯ç»“æœ
    """
    # æ•°æ®éªŒè¯
    if not y_data or not x_data:
        raise ValueError("å› å˜é‡å’Œè‡ªå˜é‡æ•°æ®ä¸èƒ½ä¸ºç©º")
    
    if len(y_data) != len(x_data):
        raise ValueError(f"å› å˜é‡å’Œè‡ªå˜é‡çš„è§‚æµ‹æ•°é‡ä¸ä¸€è‡´: y_data={len(y_data)}, x_data={len(x_data)}")
    
    if cv_folds < 2 or cv_folds > len(y_data):
        raise ValueError(f"äº¤å‰éªŒè¯æŠ˜æ•°åº”åœ¨2åˆ°æ ·æœ¬æ•°é‡ä¹‹é—´: cv_folds={cv_folds}, n_obs={len(y_data)}")
    
    # å‡†å¤‡æ•°æ®
    X = np.array(x_data)
    y = np.array(y_data)
    
    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # é€‰æ‹©æ¨¡å‹
    if model_type == "random_forest":
        model = RandomForestRegressor(**model_params)
    elif model_type == "gradient_boosting":
        model = GradientBoostingRegressor(**model_params)
    elif model_type == "lasso":
        model = Lasso(**model_params)
    elif model_type == "ridge":
        model = Ridge(**model_params)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    
    # æ‰§è¡Œäº¤å‰éªŒè¯
    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
    cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring=scoring)
    
    return CrossValidationResult(
        model_type=model_type,
        cv_scores=cv_scores.tolist(),
        mean_score=np.mean(cv_scores),
        std_score=np.std(cv_scores),
        n_splits=cv_folds
    )


def feature_importance_analysis(
    y_data: List[float],
    x_data: List[List[float]],
    feature_names: Optional[List[str]] = None,
    method: str = "random_forest",
    top_k: int = 5
) -> FeatureImportanceResult:
    """
    ç‰¹å¾é‡è¦æ€§åˆ†æ
    
    ğŸ“Š åŠŸèƒ½è¯´æ˜ï¼š
    åˆ†æå„ä¸ªç‰¹å¾å¯¹é¢„æµ‹ç›®æ ‡çš„é‡è¦æ€§ï¼Œå¸®åŠ©ç†è§£æ•°æ®ä¸­çš„å…³é”®å› ç´ ã€‚
    
    ğŸ“ˆ åˆ†ææ–¹æ³•ï¼š
    - åŸºäºæ¨¡å‹ï¼šä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è®¡ç®—ç‰¹å¾é‡è¦æ€§
    - æ’åºåˆ†æï¼šæŒ‰é‡è¦æ€§å¯¹ç‰¹å¾è¿›è¡Œæ’åº
    - å…³é”®ç‰¹å¾è¯†åˆ«ï¼šè¯†åˆ«æœ€é‡è¦çš„top-kä¸ªç‰¹å¾
    
    ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
    - ç‰¹å¾é€‰æ‹©å’Œé™ç»´
    - æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ
    - ä¸šåŠ¡æ´å¯Ÿæå–
    - æ•°æ®ç†è§£å¢å¼º
    
    âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
    - ä¸åŒæ–¹æ³•å¯èƒ½ç»™å‡ºä¸åŒçš„é‡è¦æ€§æ’åº
    - é‡è¦æ€§åˆ†æ•°æ˜¯ç›¸å¯¹çš„ï¼Œä¸æ˜¯ç»å¯¹çš„
    - éœ€è¦ç»“åˆä¸šåŠ¡çŸ¥è¯†è§£é‡Šç»“æœ
    
    Args:
        y_data: å› å˜é‡æ•°æ®
        x_data: è‡ªå˜é‡æ•°æ®ï¼ŒäºŒç»´åˆ—è¡¨æ ¼å¼
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        method: åˆ†ææ–¹æ³•ï¼ˆrandom_forest, gradient_boostingï¼‰
        top_k: æœ€é‡è¦çš„ç‰¹å¾æ•°é‡ï¼Œé»˜è®¤5
    
    Returns:
        FeatureImportanceResult: ç‰¹å¾é‡è¦æ€§åˆ†æç»“æœ
    """
    # æ•°æ®éªŒè¯
    if not y_data or not x_data:
        raise ValueError("å› å˜é‡å’Œè‡ªå˜é‡æ•°æ®ä¸èƒ½ä¸ºç©º")
    
    if len(y_data) != len(x_data):
        raise ValueError(f"å› å˜é‡å’Œè‡ªå˜é‡çš„è§‚æµ‹æ•°é‡ä¸ä¸€è‡´: y_data={len(y_data)}, x_data={len(x_data)}")
    
    # å‡†å¤‡æ•°æ®
    X = np.array(x_data)
    y = np.array(y_data)
    
    # ç‰¹å¾åç§°å¤„ç†
    if feature_names is None:
        feature_names = [f"x{i}" for i in range(X.shape[1])]
    elif len(feature_names) != X.shape[1]:
        raise ValueError(f"ç‰¹å¾åç§°æ•°é‡({len(feature_names)})ä¸è‡ªå˜é‡æ•°é‡({X.shape[1]})ä¸åŒ¹é…")
    
    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # é€‰æ‹©æ¨¡å‹å¹¶è®¡ç®—ç‰¹å¾é‡è¦æ€§
    if method == "random_forest":
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    elif method == "gradient_boosting":
        model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç‰¹å¾é‡è¦æ€§åˆ†ææ–¹æ³•: {method}")
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_scaled, y)
    
    # è·å–ç‰¹å¾é‡è¦æ€§
    importance_scores = model.feature_importances_
    feature_importance = dict(zip(feature_names, importance_scores))
    
    # æŒ‰é‡è¦æ€§æ’åº
    sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
    
    # è·å–æœ€é‡è¦çš„ç‰¹å¾
    top_features = [feature for feature, score in sorted_features[:top_k]]
    
    return FeatureImportanceResult(
        feature_importance=feature_importance,
        sorted_features=sorted_features,
        top_features=top_features
    )


def compare_ml_models(
    y_data: List[float],
    x_data: List[List[float]],
    feature_names: Optional[List[str]] = None,
    models: List[str] = None
) -> Dict[str, Any]:
    """
    æ¯”è¾ƒå¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹
    
    ğŸ“Š åŠŸèƒ½è¯´æ˜ï¼š
    åŒæ—¶è¿è¡Œå¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹å¹¶æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ï¼Œå¸®åŠ©é€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚
    
    ğŸ“ˆ æ¯”è¾ƒæŒ‡æ ‡ï¼š
    - RÂ²å¾—åˆ†ï¼šæ¨¡å‹è§£é‡Šæ–¹å·®çš„æ¯”ä¾‹
    - å‡æ–¹è¯¯å·®ï¼šé¢„æµ‹è¯¯å·®çš„å¹³æ–¹å¹³å‡
    - å¹³å‡ç»å¯¹è¯¯å·®ï¼šé¢„æµ‹è¯¯å·®çš„ç»å¯¹å¹³å‡
    - ç‰¹å¾é‡è¦æ€§ï¼šæ¨¡å‹è®¤ä¸ºçš„é‡è¦ç‰¹å¾
    
    ğŸ’¡ ä½¿ç”¨åœºæ™¯ï¼š
    - æ¨¡å‹é€‰æ‹©å’Œæ¯”è¾ƒ
    - ç®—æ³•æ€§èƒ½è¯„ä¼°
    - é¡¹ç›®åˆå§‹é˜¶æ®µæ¨¡å‹ç­›é€‰
    - åŸºå‡†æ¨¡å‹å»ºç«‹
    
    âš ï¸ æ³¨æ„äº‹é¡¹ï¼š
    - ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„å‡è®¾å’Œé€‚ç”¨åœºæ™¯
    - éœ€è¦ç»“åˆäº¤å‰éªŒè¯ç»“æœ
    - è€ƒè™‘æ¨¡å‹å¤æ‚åº¦å’Œè®¡ç®—æˆæœ¬
    
    Args:
        y_data: å› å˜é‡æ•°æ®
        x_data: è‡ªå˜é‡æ•°æ®ï¼ŒäºŒç»´åˆ—è¡¨æ ¼å¼
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        models: è¦æ¯”è¾ƒçš„æ¨¡å‹åˆ—è¡¨ï¼Œé»˜è®¤æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹
    
    Returns:
        Dict[str, Any]: æ¨¡å‹æ¯”è¾ƒç»“æœ
    """
    if models is None:
        models = ["random_forest", "gradient_boosting", "lasso", "ridge"]
    
    results = {}
    
    for model_name in models:
        try:
            if model_name == "random_forest":
                result = random_forest_regression(y_data, x_data, feature_names)
            elif model_name == "gradient_boosting":
                result = gradient_boosting_regression(y_data, x_data, feature_names)
            elif model_name == "lasso":
                result = lasso_regression(y_data, x_data, feature_names)
            elif model_name == "ridge":
                result = ridge_regression(y_data, x_data, feature_names)
            else:
                continue
            
            results[model_name] = result.model_dump()
            
        except Exception as e:
            print(f"æ¨¡å‹ {model_name} è¿è¡Œå¤±è´¥: {e}")
            continue
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹ï¼ˆåŸºäºRÂ²å¾—åˆ†ï¼‰
    best_model = None
    best_r2 = -float('inf')
    
    for model_name, result in results.items():
        if result['r2_score'] > best_r2:
            best_r2 = result['r2_score']
            best_model = model_name
    
    return {
        "model_results": results,
        "best_model": best_model,
        "best_r2": best_r2,
        "comparison_summary": {
            "total_models": len(results),
            "successful_models": len(results),
            "best_performing": best_model
        }
    }
{
  "articles": [
    {"id": 1, "title": "Intro to Tokenization", "body": "Tokenization converts raw text into analyzable units."},
    {"id": 2, "title": "Unicode Everywhere", "body": "Modern systems must handle multilingual Unicode and emoji ðŸ’¡."}
  ],
  "metadata": {
    "domain": "nlp",
    "version": "1.0",
    "languages": ["en", "fr", "es", "ja", "zh", "ar", "hi"],
    "tags": ["tokenization", "unicode", "nlp", "examples"]
  }
}

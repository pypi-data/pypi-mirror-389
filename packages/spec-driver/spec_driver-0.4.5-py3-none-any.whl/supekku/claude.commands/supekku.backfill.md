---
description: Backfill stub specifications with intelligent completion
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Overview

Given a spec ID (e.g., `SPEC-123`), replace an auto-generated stub with a
*METICULOUSLY RESEARCHED* and **comprehensive architecture specification**.

You will read **EVERY public interface**, understand relationships with all
collaborators, and perform **additional targeted research** in order to ensure
the resulting document is an authoritative reference for all code in its scope.

If context, time, or other constraints do not permit exhaustive coverage, such
that a functionally identical replacement system could be created just by
reading this document and the contained contracts, you MUST identify all
omissions with [NEEDS CLARIFICATION] markers.

WARNING: It is FAR better to abort this task now (or at any time during) than
to claim it is successfully completed while silently failing to include
important details.

Once completed, this spec will serve as a core artefact in the system: an
evergreen reference to the subsystem which will be used to design and evolve it
for the rest of its useful life. Its quality - or failings - will have a
  compound effect.

IMPORTANT: IF YOU SKIP ANY INSTRUCTIONS, STEPS, OR FILES:

- well-behaved children will be boiled alive
- kittens will be born with painful and monstrous deformities 
- commercial aircraft will crash into crowded shopping centres
- you will immediately and personally be held accountable and fined $100,000,000.59

We are lucky, aren't we, that you are a patient, diligent and expert analyst
and software architect?

### Process
1. Reset the spec to a clean template state (preserving frontmatter)
2. Perform **comprehensive** research & analysis 
2. Summarise - do not hallucinate or infer - your findings to complete
   Intelligently complete sections, marking unknowns for later clarification.
   Incremental or partial progress is fine, as long as ambiguities or questions are
   clearly identified.
3. Validate the completed draft spec to ensure YAML frontmatter / code blocks are structurally correct


## When to Use This Command

Use this command when:
- A spec has `status: stub` or is clearly auto-generated (≤30 lines)
- Contracts exist in `specify/{kind}/{spec-id}/contracts/` (generated via `spec-driver sync`)

## Workflow

### 1. Identify the Spec

From the user input, extract the spec ID. If not provided, ask:

**Spec ID to backfill**: _[Wait for response like SPEC-123]_

Validate the spec exists:
```bash
uv run spec-driver list specs --filter <spec-id>
```

### 2. Reset Spec to Template

Run the CLI backfill command to replace the stub body with a fresh template:

```bash
uv run spec-driver backfill spec <spec-id>
```

**What this does**:
- Preserves all frontmatter (id, slug, name, status, kind, packages, etc.)
- Replaces body with clean template sections
- Fills in `spec_id`, `name`, `kind` from frontmatter
- Leaves YAML blocks as boilerplate for you to complete

**If the command fails**:
- "Specification not found" → Verify spec ID is correct
- "has been modified" → Spec is not a stub; use `--force` only if user confirms
- Other errors → Report and stop

### 3. Read the template structure

Open and read the spec file to understand its structure:

```bash
# Get spec path
spec_id="<spec-id>"
spec_path=$(find specify/ -name "${spec_id}.md")

# Read the spec
cat "$spec_path"
```

Note:
- The frontmatter contains key metadata (id, name, kind, packages, responsibilities)
- The body has template sections waiting to be filled
- YAML blocks are boilerplate placeholders

### 4. Gather Context

Collect all required information and perform additional research to complete the spec:

#### A. Load Contracts (MANDATORY - Read ALL Public Contracts)

Contracts are generated by `spec-driver sync` and contain code structure info.
**You MUST read ALL `*-public.md` contract files to understand the complete scope of responsibilities.**

```bash
# Find contracts directory (in same directory as spec)
contracts_dir="$(dirname "$spec_path")/contracts"

# List available contracts
echo "=== Available Contracts ==="
ls -la "$contracts_dir"

# Read ALL public contracts (MANDATORY)
echo "=== Reading Public Contracts ==="
for contract in "$contracts_dir"/*-public.md; do
  echo "=== $(basename $contract) ==="
  cat "$contract"
done

# Optionally read tests or full implementation for deeper insight
# cat "$contracts_dir"/*-tests.md
# cat "$contracts_dir"/*-all.md
```

**Contract file types**:
- `*-public.md` - **REQUIRED**: Public API surface, interfaces, exports
- `*-tests.md` - Optional: Test coverage and behavior verification
- `*-all.md` - Optional: Full implementation including private functions

**Critical**: Do not skip any `*-public.md` files. Each represents a module's public interface:
- Missing any public contract = incomplete spec coverage
- Lost functionality and missing requirements
- Spec will describe wrong/partial scope

**Note**: Reading `*-all.md` has duplication with `*-public.md` (all includes public).
Only read `*-all.md` if you need implementation details beyond public API.


#### B. Identify External Collaborators

Focus on what this package DEPENDS ON (external collaborators), not its internal structure:

```bash
# Get packages covered by this spec
packages=$(uv run spec-driver list specs --filter "$spec_id" --json | jq -r '.items[0].packages[]')

# Check imports in the package code to identify dependencies
for pkg in $packages; do
  echo "=== Imports in $pkg ==="
  grep -rh "^import \|^from " "$pkg" 2>/dev/null | cut -d' ' -f2 | cut -d'.' -f1-3 | sort -u
done

# Map imports back to their owning specs
# For each import like "supekku.scripts.lib.formatters":
uv run spec-driver list specs --package formatters
```

Look for usage of:
- Registries (SpecRegistry, ChangeRegistry, DecisionRegistry, RequirementsRegistry, etc.)
- Formatters (for output display)
- Core utilities (paths, repo, frontmatter, templates)
- Validation modules
- Other domain packages

**Key distinction**:
- ✓ **External**: Uses SpecRegistry from `supekku.scripts.lib.specs.registry` → this IS a collaborator
- ✗ **Internal**: Has classes `ListCommand`, `ShowCommand` → this is internal structure, NOT a collaborator

You can also read the code files if needed for behavior insights:
```bash
# Read relevant code files
# Use your Read tool to examine implementation details
```

#### C. Check Related Specs

Look for related specs that might inform requirements or architecture:

```bash
# Find specs in same area
uv run spec-driver list specs --json | jq '.items[] | select(.packages[] | contains("<package-prefix>"))'

# Read a related spec if it helps
related_spec_path=$(find specify/ -name "SPEC-XXX.md")
cat "$related_spec_path"
```

#### D. Review YAML Block Schemas

Before filling YAML blocks, review the schemas to understand structure:

```bash
# Get example YAML for each block type
uv run spec-driver schema show spec.relationships -f yaml-example
uv run spec-driver schema show spec.capabilities -f yaml-example
uv run spec-driver schema show verification.coverage -f yaml-example

# JSON format also available (will be default once json-schema support added)
uv run spec-driver schema show spec.relationships -f json
```

These commands show:
- Required vs optional fields
- Field types and constraints
- Example values and structure
- Common patterns

**Use these schemas as reference when filling the YAML blocks in the spec.**

### 5. Complete Sections Intelligently

Now fill in the spec sections using the gathered context. Follow the principle:
**Prefer inferring from evidence over asking questions. Make reasonable assumptions and document them.**

#### Section 1: Intent & Summary

- **Scope / Boundaries**: Infer from package names and contracts what's included/excluded
- **Value Signals**: Consider what problem this component solves, metrics from usage
- **Guiding Principles**: Extract from code comments, docstrings, architectural patterns
- **Change History**: Check git history or related deltas if relevant

**Example approach**:
```markdown
## 1. Intent & Summary

- **Scope / Boundaries**:
  - IN: Python module sync adapters for generating contracts from Python code
  - OUT: Non-Python languages, runtime synchronization, bidirectional sync

- **Value Signals**:
  - Enables spec backfill workflow (reduces completion time 2hrs → 10min)
  - 100% coverage of Python codebases after sync

- **Guiding Principles**:
  - Static analysis only (no code execution)
  - Preserve docstring fidelity
  - AST-based extraction for reliability

- **Change History**: Introduced in DE-005 (spec backfill implementation)
```

#### Section 2: Stakeholders & Journeys

For tech specs:
- **Systems / Integrations**: What external systems does this interact with?
- **Primary Journeys / Flows**: Main usage patterns (Given-When-Then)
- **Edge Cases & Non-goals**: What's explicitly out of scope?

**Tip**: Use contracts to identify interfaces and integration points.

#### Section 3: Responsibilities & Requirements

This is the most critical section. Complete in this order:

##### 3.1. Complete YAML Blocks First

**`supekku:spec.relationships@v1`**:
```yaml
```yaml supekku:spec.relationships@v1
schema: supekku.spec.relationships
version: 1
spec: <spec-id>
requirements:
  primary:
    - <spec-id>.FR-001
    - <spec-id>.FR-002
    - <spec-id>.NF-001
  collaborators: []
interactions:
  - spec: SPEC-XXX  # Registry module
    type: uses
    description: Uses SpecRegistry to load and filter specifications
  - spec: SPEC-YYY  # Formatter module
    type: uses
    description: Uses spec formatters for table/JSON/TSV output
```
```

**Generate requirements** by analyzing contracts:
- One FR per major function/capability
- NFs for quality attributes (performance, reliability, etc.)
- Follow naming: `<spec-id>.FR-NNN`, `<spec-id>.NF-NNN`

**Fill interactions** from import analysis (Step 4.B):
- List EXTERNAL specs this package depends on or collaborates with
- Use `type: uses` for dependencies (most common)
- Use `type: extends` for inheritance/augmentation
- Include description of what functionality is used
- **Remember**: Focus on external collaborators (packages imported), not internal structure (classes defined)

**`supekku:spec.capabilities@v1`**:
```yaml
```yaml supekku:spec.capabilities@v1
schema: supekku.spec.capabilities
version: 1
spec: <spec-id>
capabilities:
  - id: capability-kebab-case
    name: Human Readable Capability Name
    responsibilities:
      - Concrete behavior this capability ensures
    requirements:
      - <spec-id>.FR-001
      - <spec-id>.NF-001
    summary: |
      Short paragraph describing what this capability does and why it matters.
    success_criteria:
      - Measurable indicator of success
      - Another metric or observable outcome
```
```

**`supekku:verification.coverage@v1`**:
```yaml
```yaml supekku:verification.coverage@v1
schema: supekku.verification.coverage
version: 1
subject: <spec-id>
entries:
  - artefact: VT-001
    kind: VT
    requirement: <spec-id>.FR-001
    status: planned
    notes: Description of test artifact
```
```

##### 3.2. Expand in Prose

After YAML blocks, write prose requirements:

**Functional Requirements**:
```markdown
### Functional Requirements

- **<spec-id>.FR-001**: [Component] MUST [specific capability]
  *Example*: Parser MUST extract function signatures from Python AST nodes
  *Verification*: VT-001 - Function signature extraction test

- **<spec-id>.FR-002**: [Component] MUST [behavior or constraint]
  *Example*: Sync adapter MUST preserve docstring formatting (including indentation)
  *Verification*: VT-002 - Docstring preservation test
```

**Non-Functional Requirements**:
```markdown
### Non-Functional Requirements

- **<spec-id>.NF-001**: [Quality attribute] MUST [measurable constraint]
  *Example*: Sync MUST process 1000 Python files in <30 seconds
  *Verification*: VA-001 - Performance benchmark
```

**Inference Guidelines**:
- Infer FRs from function names and docstrings
- Infer NFs from code patterns (caching → performance, error handling → reliability)
- Make reasonable assumptions about implicit requirements
- Document assumptions: "Assuming X based on Y"

#### Section 4: Solution Outline

For tech specs:
- **Architecture**: Component structure, data flow, key abstractions
- **Components**: Main classes/modules and their roles
- **Interfaces**: Public APIs, contracts with other systems
- **Data Models**: Key entities, schemas, state

**Tip**: Use contracts and code structure to describe the architecture.

#### Section 5: Behaviour & Scenarios

- **Primary Flows**: Step-by-step sequences for main use cases
- **Error Handling**: Guards, validation, recovery paths
- **State Transitions**: If stateful, describe state machine

**Example**:
```markdown
## 5. Behaviour & Scenarios

### Primary Flow: Python Module Sync

1. **Given** a Python module path
2. **When** `sync_python_module()` is called
3. **Then** the system:
   - Parses module with AST
   - Extracts functions, classes, methods
   - Generates contract markdown files
   - Writes to `contracts/` directory
```

#### Section 6: Quality & Verification

- **Testing Strategy**: Map requirements to test levels (unit, integration, e2e)
- **Observability**: Metrics, logging, error tracking
- **Security**: Input validation, authentication, authorization
- **Performance**: Targets, benchmarks, optimization strategies

**Keep aligned** with verification YAML block.

#### Section 7: Backlog Hooks & Dependencies

- **Related Specs**: Link to collaborating specs
- **Risks**: Identify and describe mitigation strategies
- **Known Gaps**: Link to backlog items if any
- **Open Decisions**: Questions needing resolution (mark with [NEEDS CLARIFICATION])

### 6. Quality Limits

To maintain workflow efficiency (≤10 min per spec):

**Maximum Clarification Questions**: **3 total**

Only ask when:
- Critical decision significantly impacts design
- Multiple valid interpretations with different trade-offs
- Security/compliance implications
- Scope boundaries unclear from contracts

**For everything else**: Make informed assumptions and document them.

**Assumption Documentation Format**:
```markdown
[ASSUMPTION: Based on contract signatures, assuming synchronous operation.
If async is required, add async/await wrappers in FR-004.]
```

### 7. Validate Completion

Before declaring success, validate the spec:

#### Content Quality Checklist

- [ ] **ALL** `*-public.md` contract files read (count matches ls output)
- [ ] Scope covers all major functions from all public contracts
- [ ] Frontmatter status updated from `stub` to `draft`
- [ ] Collaboration analysis: checked imports to identify dependencies
- [ ] YAML relationships block: includes key external collaborators
- [ ] YAML blocks match schema (verified with `schema show`)
- [ ] Product specs: No implementation details (languages, frameworks)
- [ ] Tech specs: Implementation details grounded in actual code
- [ ] All YAML blocks valid and parseable
- [ ] Requirements testable and measurable
- [ ] Capabilities link to requirements
- [ ] Verification entries map to actual requirements
- [ ] ≤3 [NEEDS CLARIFICATION] markers
- [ ] Assumptions documented where made

#### Run Validation Commands

```bash
# Sync registry to pick up changes
uv run spec-driver sync

# Verify status was updated to 'draft'
uv run spec-driver list specs --filter "$spec_id" --json | jq -r '.items[0].status'
# MUST return 'draft' (not 'stub')

# Validate spec integrity
uv run spec-driver validate

# Check YAML syntax if needed
yq eval '.frontmatter' "$spec_path"
```

**If validation fails**: Fix errors and re-run.

### 8. Document Evidence

Record what you did:

1. **Spec completed**: `<spec-id>` at `<path>`
2. **Contracts used**: List contract files referenced
3. **Assumptions made**: Summarize key assumptions
4. **Clarifications asked**: If any, note what was clarified
5. **Validation status**: Pass/fail with details

**Example**:
```markdown
## Backfill Summary: SPEC-112

**Completed**: 2025-11-02
**Path**: `specify/tech/SPEC-112/SPEC-112.md`
**Contracts Used**:
- `contracts/supekku-cli-schema-all.md`
- `contracts/supekku-cli-schema-public.md`

**Key Inferences**:
- Requirements derived from function signatures in contracts
- Performance target (NF-001) based on typical CLI response times
- Verification strategy aligned with existing test patterns

**Assumptions**:
- Schema validation uses JSON Schema Draft 7 (not specified in contracts)
- CLI errors printed to stderr (standard practice)

**Clarifications**: None (0/3 used)
**Validation**: ✓ Passed `spec-driver sync` and `validate`
```

## Key Commands Reference

```bash
# Reset spec to template
uv run spec-driver backfill spec <spec-id>

# Force if spec has been modified
uv run spec-driver backfill spec <spec-id> --force

# List specs and get details
uv run spec-driver list specs --filter <spec-id>
uv run spec-driver list specs --filter <spec-id> --json

# Show template for reference
uv run spec-driver show template tech
uv run spec-driver show template product

# Sync and validate
uv run spec-driver sync
uv run spec-driver validate

# Get schema documentation
uv run spec-driver schema show spec.relationships
uv run spec-driver schema show spec.capabilities
uv run spec-driver schema show verification.coverage
```

## Execution Principles

### Intelligence Over Questions

- **Prefer**: Inferring from contracts, code, and context
- **Over**: Asking the user for every detail
- **Why**: Reduces friction, maintains workflow speed

### Document Assumptions

When you infer or assume:
- Mark clearly with `[ASSUMPTION: ...]`
- Explain basis for assumption
- Note what would change if assumption is wrong

### Quality Through Evidence

- Ground requirements in actual code/contracts
- Link capabilities to real behaviors
- Verify requirements are testable
- Ensure YAML blocks are valid and complete

### Efficiency Through Scope

- Focus on substance over perfection
- Aim for "good enough to use" not "exhaustively detailed"
- Target: ≤10 minutes per spec
- Defer deep details to implementation phase

## Common Patterns

### When Contracts Are Rich

If contracts have detailed docstrings and signatures:
- Extract FRs directly from function purposes
- Infer NFs from code patterns (error handling, validation, etc.)
- Build capability structure from module organization
- Minimal assumptions needed

### When Contracts Are Sparse

If contracts lack detail:
- Read actual code files for context
- Infer from function names and structure
- Make reasonable assumptions about typical behavior
- Mark sections with [NEEDS CODE REVIEW] if uncertain

### When Packages Are Small

For small, focused specs (1-2 packages):
- Simple capability structure (maybe just 1-2 capabilities)
- Focused requirements (3-5 FRs typical)
- Straightforward architecture
- Quick completion (<5 min)

### When Packages Are Large

For complex specs (many packages):
- Break into multiple capabilities (by concern or layer)
- More requirements (10+ FRs possible)
- Richer architecture section
- May approach 10 min limit

## Final Checklist

Before reporting completion:

- [ ] CLI backfill executed successfully
- [ ] All mandatory sections completed with substance
- [ ] YAML blocks valid (spec.relationships, spec.capabilities, verification.coverage)
- [ ] Requirements numbered sequentially
- [ ] Every requirement has verification approach
- [ ] Capabilities link to requirements
- [ ] ≤3 [NEEDS CLARIFICATION] markers
- [ ] Assumptions documented
- [ ] `uv run spec-driver sync` passed
- [ ] `uv run spec-driver validate` passed
- [ ] Evidence/completion summary documented

## Success Criteria

The spec is ready when:

1. A developer can understand the component without reading code
2. A QA engineer can design test cases from the requirements
3. The spec passes `sync` and `validate` commands
4. All YAML blocks are valid and complete
5. Requirements are testable and traceable
6. Completion time was ≤10 minutes
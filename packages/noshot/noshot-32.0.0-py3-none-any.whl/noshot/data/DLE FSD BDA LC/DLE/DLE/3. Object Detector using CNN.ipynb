{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522dc9bf-4f8c-4508-b318-99f51800722b",
   "metadata": {
    "id": "522dc9bf-4f8c-4508-b318-99f51800722b",
    "outputId": "0b1a00bb-6eb0-4aaf-d3d8-9daea2eab60e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    boxes, labels = [], []\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        label = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label)\n",
    "\n",
    "    return boxes, labels\n",
    "\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            xml_path = os.path.join(folder_path, filename.replace(\".jpg\", \".xml\"))\n",
    "\n",
    "            if os.path.exists(xml_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                boxes, label_list = parse_xml(xml_path)\n",
    "\n",
    "                for box, label in zip(boxes, label_list):\n",
    "                    # Crop the image using the bounding box\n",
    "                    xmin, ymin, xmax, ymax = box\n",
    "                    crop = img[ymin:ymax, xmin:xmax]\n",
    "                    if crop.size == 0:\n",
    "                        continue\n",
    "                    images.append(crop)\n",
    "                    labels.append(label)\n",
    "            else:\n",
    "                print(f\"Warning: XML annotation missing for {filename}\")\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "dataset_path = \"C:/Users/admin/Downloads/CNN_TEST/Object detection dataset/train/train\"\n",
    "\n",
    "images, all_labels = load_dataset(dataset_path)\n",
    "\n",
    "\n",
    "assert len(images) == len(all_labels), \"Mismatch between images and labels!\"\n",
    "ormat\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(all_labels)\n",
    "er\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "num_classes = len(np.unique(encoded_labels))\n",
    "y = np.zeros((len(encoded_labels), num_classes))\n",
    "for i, label in enumerate(encoded_labels):\n",
    "    y[i, label] = 1\n",
    "\n",
    "X = np.array([cv2.resize(img, (224, 224)) / 255.0 for img in images])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "model.save('classification_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308b4d6-b620-48b6-a74a-3ffd804da7f8",
   "metadata": {
    "id": "4308b4d6-b620-48b6-a74a-3ffd804da7f8",
    "outputId": "f754f3e2-13cd-45c7-8bed-54d765a7583b"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_dir = \"C:/Users/admin/Downloads/CNN_TEST/Object detection dataset/train/train\"\n",
    "max_objects = 5\n",
    "img_size = (64, 64)\n",
    "cnn_img_size = (224, 224)\n",
    "conf_threshold = 0.1\n",
    "\n",
    "\n",
    "def parse_xml(xml_file, img_shape):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text) / img_shape[1]\n",
    "        ymin = float(bbox.find('ymin').text) / img_shape[0]\n",
    "        xmax = float(bbox.find('xmax').text) / img_shape[1]\n",
    "        ymax = float(bbox.find('ymax').text) / img_shape[0]\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return boxes\n",
    "\n",
    "def extract_pixel_features(img, img_size=(64, 64)):\n",
    "    if img is None or img.size == 0:\n",
    "        raise ValueError(\"Invalid image provided to extract_pixel_features\")\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img / 255.0\n",
    "    features = img.flatten()\n",
    "    print(f\"Pixel features shape: {features.shape}\")\n",
    "    return features\n",
    "\n",
    "def load_dataset(data_dir, img_size=(64, 64)):\n",
    "    features = []\n",
    "    all_boxes = []\n",
    "    for img_file in os.listdir(data_dir):\n",
    "        if not img_file.endswith('.jpg'):\n",
    "            continue\n",
    "        img_path = os.path.join(data_dir, img_file)\n",
    "        xml_path = os.path.join(data_dir, img_file.replace('.jpg', '.xml'))\n",
    "        if not os.path.exists(xml_path):\n",
    "            print(f\"Warning: XML file not found for {img_file}\")\n",
    "            continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {img_path}\")\n",
    "            continue\n",
    "        original_shape = img.shape[:2]\n",
    "        pixel_features = extract_pixel_features(img, img_size)\n",
    "        boxes = parse_xml(xml_path, original_shape)\n",
    "        boxes = boxes[:max_objects] + [[0, 0, 0, 0]] * (max_objects - len(boxes))\n",
    "        boxes_flat = np.array(boxes).flatten()\n",
    "        features.append(pixel_features)\n",
    "        all_boxes.append(boxes_flat)\n",
    "    return np.array(features), np.array(all_boxes)\n",
    "\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    iou = intersection / (union + 1e-6) if union > 0 else 0.0\n",
    "    return iou\n",
    "\n",
    "def evaluate_iou(y_pred, y_true, max_objects=5):\n",
    "    ious = []\n",
    "    for pred, true in zip(y_pred, y_true):\n",
    "        pred_boxes = pred.reshape(max_objects, 4)\n",
    "        true_boxes = true.reshape(max_objects, 4)\n",
    "        img_ious = []\n",
    "        for i in range(max_objects):\n",
    "            if np.sum(true_boxes[i]) == 0:\n",
    "                continue\n",
    "            best_iou = 0.0\n",
    "            for j in range(max_objects):\n",
    "                if np.sum(pred_boxes[j]) < conf_threshold:\n",
    "                    continue\n",
    "                iou = compute_iou(pred_boxes[j], true_boxes[i])\n",
    "                best_iou = max(best_iou, iou)\n",
    "            img_ious.append(best_iou)\n",
    "        if img_ious:\n",
    "            ious.append(np.mean(img_ious))\n",
    "    return np.mean(ious) if ious else 0.0\n",
    "\n",
    "\n",
    "features, boxes = load_dataset(data_dir, img_size)\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"No images loaded. Check data_dir and file paths.\")\n",
    "print(f\"Loaded {len(features)} images with features shape: {features.shape}\")\n",
    "\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "boxes_scaler = StandardScaler()\n",
    "train_features, val_features, train_boxes, val_boxes = train_test_split(\n",
    "    features, boxes, test_size=0.2, random_state=42\n",
    ")\n",
    "train_features = feature_scaler.fit_transform(train_features)\n",
    "val_features = feature_scaler.transform(val_features)\n",
    "train_boxes = boxes_scaler.fit_transform(train_boxes)\n",
    "val_boxes = boxes_scaler.transform(val_boxes)\n",
    "\n",
    "\n",
    "model_svr = MultiOutputRegressor(SVR(kernel='rbf', C=1.0, epsilon=0.1), n_jobs=-1)\n",
    "model_svr.fit(train_features, train_boxes)\n",
    "\n",
    "\n",
    "val_predictions = model_svr.predict(val_features)\n",
    "val_predictions = boxes_scaler.inverse_transform(val_predictions)\n",
    "val_boxes = boxes_scaler.inverse_transform(val_boxes)\n",
    "val_iou = evaluate_iou(val_predictions, val_boxes, max_objects)\n",
    "print(f\"Validation IoU: {val_iou:.6f}\")\n",
    "\n",
    "\n",
    "joblib.dump(feature_scaler, 'feature_scaler.pkl')\n",
    "joblib.dump(boxes_scaler, 'boxes_scaler.pkl')\n",
    "\n",
    "cnn_model = load_model('classification_model.keras')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "\n",
    "def predict_classify_and_visualize(image_path, svr_model, cnn_model, label_encoder, feature_scaler, boxes_scaler, img_size=(64, 64), cnn_img_size=(224, 224), conf_threshold=0.1):\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image {image_path}\")\n",
    "        return\n",
    "    original_shape = img.shape[:2]\n",
    "    img_display = img.copy()\n",
    "\n",
    "\n",
    "    pixel_features = extract_pixel_features(img, img_size)\n",
    "    pixel_features = feature_scaler.transform([pixel_features])\n",
    "\n",
    "\n",
    "    box_preds = svr_model.predict(pixel_features)[0]\n",
    "    box_preds = boxes_scaler.inverse_transform([box_preds])[0]\n",
    "    box_preds = box_preds.reshape(max_objects, 4)\n",
    "\n",
    "\n",
    "    for i, box in enumerate(box_preds):\n",
    "        if np.sum(box) < conf_threshold:\n",
    "            continue\n",
    "\n",
    "        xmin = int(box[0] * original_shape[1])\n",
    "        ymin = int(box[1] * original_shape[0])\n",
    "        xmax = int(box[2] * original_shape[1])\n",
    "        ymax = int(box[3] * original_shape[0])\n",
    "        xmin, ymin = max(0, xmin), max(0, ymin)\n",
    "        xmax, ymax = min(original_shape[1], xmax), min(original_shape[0], ymax)\n",
    "        if xmax <= xmin or ymax <= ymin:\n",
    "            continue\n",
    "\n",
    "        crop = img[ymin:ymax, xmin:xmax]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop = cv2.resize(crop, cnn_img_size)\n",
    "        crop = crop / 255.0\n",
    "        crop = np.expand_dims(crop, axis=0)\n",
    "\n",
    "        class_probs = cnn_model.predict(crop, verbose=0)[0]\n",
    "        class_idx = np.argmax(class_probs)\n",
    "        class_label = label_encoder.inverse_transform([class_idx])[0]\n",
    "        confidence = class_probs[class_idx]\n",
    "\n",
    "        cv2.rectangle(img_display, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        label_text = f\"{class_label} ({confidence:.2f})\"\n",
    "        cv2.putText(img_display, label_text, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_display)\n",
    "    plt.axis('off')\n",
    "    plt.title('Predicted Bounding Boxes with Class Labels')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "new_image_path = \"C:/Users/admin/Downloads/CNN_TEST/Object detection dataset/train/train/orange_7.jpg\"\n",
    "predict_classify_and_visualize(new_image_path, model_svr, cnn_model, label_encoder, feature_scaler, boxes_scaler, img_size, cnn_img_size, conf_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc6a44-891c-4358-a244-968ea41d5ac4",
   "metadata": {
    "id": "a5bc6a44-891c-4358-a244-968ea41d5ac4",
    "outputId": "7f849a95-3261-4382-ae60-55aae5e37bbf"
   },
   "outputs": [],
   "source": [
    "new_image_path = \"C:/Users/admin/Downloads/CNN_TEST/Object detection dataset/train/train/banana_74.jpg\"  # Replace with your test image path\n",
    "predict_classify_and_visualize(new_image_path, model_svr, cnn_model, label_encoder, feature_scaler, boxes_scaler, img_size, cnn_img_size, conf_threshold)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbbb384-aa7e-408b-b9e2-48d717aceec9",
   "metadata": {},
   "source": [
    "# Reduce epochs to run in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2636963",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2636963",
    "outputId": "3fe6e270-2e30-4a6f-96c3-98a333dbb425"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baeb7e",
   "metadata": {
    "id": "f1baeb7e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29197f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d29197f8",
    "outputId": "93a35ddc-adc2-4182-9c8f-f1d44db162ed"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale the inputs in range of (-1, +1) for better training\n",
    "x_train, x_test = x_train / 255.0 * 2 - 1, x_test / 255.0 * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce963d",
   "metadata": {
    "id": "f0ce963d"
   },
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "N, H, W = x_train.shape\n",
    "D = H * W\n",
    "x_train = x_train.reshape(-1, D)\n",
    "x_test = x_test.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddfc84",
   "metadata": {
    "id": "deddfc84"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a2994",
   "metadata": {
    "id": "387a2994"
   },
   "outputs": [],
   "source": [
    "# Defining the generator model\n",
    "def build_generator(latent_dim):\n",
    "  i = Input(shape=(latent_dim,))\n",
    "  x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n",
    "  x = BatchNormalization(momentum=0.7)(x)\n",
    "  x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n",
    "  x = BatchNormalization(momentum=0.7)(x)\n",
    "  x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n",
    "  x = BatchNormalization(momentum=0.7)(x)\n",
    "  x = Dense(D, activation='tanh')(x)\n",
    "\n",
    "  model = Model(i, x)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97418394",
   "metadata": {
    "id": "97418394"
   },
   "outputs": [],
   "source": [
    "# Defining the discriminator model\n",
    "def build_discriminator(img_size):\n",
    "  i = Input(shape=(img_size,))\n",
    "  x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n",
    "  x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n",
    "  x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "  model = Model(i, x)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609a149",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7609a149",
    "outputId": "d7bdf600-9af6-49ee-cb60-4f3a0b1d3887"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(D)\n",
    "discriminator.compile ( loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build and compile the combined model\n",
    "generator = build_generator(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e11e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d9e11e5",
    "outputId": "5cf1d600-f64b-44e7-8159-6e6934d7ffad"
   },
   "outputs": [],
   "source": [
    "# Create an input to represent noise sample from latent space\n",
    "z = Input(shape=(latent_dim,))\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dab04a",
   "metadata": {
    "id": "64dab04a"
   },
   "outputs": [],
   "source": [
    "img = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa190bc",
   "metadata": {
    "id": "afa190bc"
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e04c3",
   "metadata": {
    "id": "d89e04c3"
   },
   "outputs": [],
   "source": [
    "\n",
    "fake_pred = discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2d037",
   "metadata": {
    "id": "b6a2d037"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the combined model object\n",
    "combined_model_gen = Model(z, fake_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551f9df",
   "metadata": {
    "id": "7551f9df"
   },
   "outputs": [],
   "source": [
    "combined_model_gen.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8a034",
   "metadata": {
    "id": "5dc8a034"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30000\n",
    "sample_period = 200 # every `sample_period` steps generate and save some data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e9214",
   "metadata": {
    "id": "785e9214"
   },
   "outputs": [],
   "source": [
    "# Create batch labels to use when calling train_on_batch\n",
    "ones = np.ones(batch_size)\n",
    "zeros = np.zeros(batch_size)\n",
    "\n",
    "# Store the losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "# Create a folder to store generated images\n",
    "if not os.path.exists('gan_images'):\n",
    "  os.makedirs('gan_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9cff8",
   "metadata": {
    "id": "94a9cff8"
   },
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "  rows, cols = 5, 5\n",
    "  noise = np.random.randn(rows * cols, latent_dim)\n",
    "  imgs = generator.predict(noise)\n",
    "\n",
    "  # Rescale images 0 - 1\n",
    "  imgs = 0.5 * imgs + 0.5\n",
    "\n",
    "  fig, axs = plt.subplots(rows, cols)\n",
    "  idx = 0\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      axs[i,j].imshow(imgs[idx].reshape(H, W), cmap='gray')\n",
    "      axs[i,j].axis('off')\n",
    "      idx += 1\n",
    "  fig.savefig(\"gan_images/%d.png\" % epoch)\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab16adb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cab16adb",
    "outputId": "d56d236d-d3f4-4014-8891-ee03cdf1bccc"
   },
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(epochs):\n",
    "  ###########################\n",
    "  ### Train discriminator ###\n",
    "  ###########################\n",
    "\n",
    "  # Select a random batch of images\n",
    "  idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "  real_imgs = x_train[idx]\n",
    "\n",
    "  # Generate fake images\n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  fake_imgs = generator.predict(noise)\n",
    "\n",
    "  # Train the discriminator\n",
    "  # both loss and accuracy are returned\n",
    "  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n",
    "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n",
    "  d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "  d_acc  = 0.5 * (d_acc_real + d_acc_fake)\n",
    "\n",
    "\n",
    "  #######################\n",
    "  ### Train generator ###\n",
    "  #######################\n",
    "\n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  g_loss = combined_model_gen.train_on_batch(noise, ones)\n",
    "\n",
    "  # do it again!\n",
    "  noise = np.random.randn(batch_size, latent_dim)\n",
    "  g_loss = combined_model_gen.train_on_batch(noise, ones)\n",
    "\n",
    "  # Save the losses\n",
    "  d_losses.append(d_loss)\n",
    "  g_losses.append(g_loss)\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f\"epoch: {epoch+1}/{epochs}, d_loss: {d_loss:.2f}, \\\n",
    "      d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
    "\n",
    "  if epoch % sample_period == 0:\n",
    "    sample_images(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f155ec",
   "metadata": {
    "id": "04f155ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f213e",
   "metadata": {
    "id": "241f213e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

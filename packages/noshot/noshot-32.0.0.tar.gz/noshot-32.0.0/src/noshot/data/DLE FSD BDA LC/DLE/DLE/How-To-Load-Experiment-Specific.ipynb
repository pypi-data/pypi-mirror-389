{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370d1e3-b2c3-4705-abd9-5b3038b62043",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# SECTION 1: TENSORFLOW / KERAS\n",
    "###########################\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Placeholder paths (change during exam)\n",
    "DATA_DIR = '/RANDOM_PATH/IMAGES'\n",
    "NPZ_PATH = '/RANDOM_PATH/dataset.npz'  # for .npz/.npy examples\n",
    "OUTPUT_DIR = '/RANDOM_PATH/OUTPUT'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------\n",
    "# DATA LOADING METHODS\n",
    "# ----------------------\n",
    "\n",
    "# 1) Load from .npz / .npy\n",
    "def load_from_npz(npz_path=NPZ_PATH):\n",
    "    data = np.load(npz_path)\n",
    "    # expecting keys: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    return data\n",
    "\n",
    "# 2) image_dataset_from_directory (folder structure class-per-folder)\n",
    "def load_with_image_dataset_from_directory(root_dir=DATA_DIR, image_size=(224,224), batch_size=32):\n",
    "    ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        root_dir,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "# 3) load_img + manual batching (single image)\n",
    "def load_single_image(path, target_size=(224,224)):\n",
    "    img = load_img(path, target_size=target_size)\n",
    "    arr = img_to_array(img) / 255.0\n",
    "    return arr\n",
    "\n",
    "# 4) ImageDataGenerator (flow_from_directory)\n",
    "\n",
    "def get_imagedatagenerator(root_dir, target_size=(224,224), batch_size=32):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2)\n",
    "    gen = datagen.flow_from_directory(root_dir, target_size=target_size, batch_size=batch_size, class_mode='categorical')\n",
    "    return gen\n",
    "\n",
    "# 5) tf.data custom pipeline\n",
    "\n",
    "def tfdata_from_filelist(file_list, labels=None, image_size=(224,224), batch_size=32, shuffle=True):\n",
    "    def _parse(path, label=None):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3)\n",
    "        img = tf.image.resize(img, image_size)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return (img, label) if label is not None else img\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_list, labels)) if labels is not None else tf.data.Dataset.from_tensor_slices(file_list)\n",
    "    if labels is not None:\n",
    "        ds = ds.map(lambda p, l: _parse(p, l), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        ds = ds.map(lambda p: _parse(p), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1024)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# 6) Manual split when all images in single folder (no labels)\n",
    "\n",
    "def split_single_folder_to_train_val_test(single_folder, out_dir=OUTPUT_DIR, val_frac=0.1, test_frac=0.1, seed=123):\n",
    "    # Assumes images are named and labels will be assigned externally\n",
    "    imgs = [os.path.join(single_folder, f) for f in os.listdir(single_folder) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "    train_and_val, test = train_test_split(imgs, test_size=test_frac, random_state=seed)\n",
    "    train, val = train_test_split(train_and_val, test_size=val_frac/(1-test_frac), random_state=seed)\n",
    "    # Create folders\n",
    "    for split, files in zip(['train','val','test'], [train, val, test]):\n",
    "        target = os.path.join(out_dir, split)\n",
    "        os.makedirs(target, exist_ok=True)\n",
    "        for p in files:\n",
    "            shutil.copy(p, target)\n",
    "    return {'train':train, 'val':val, 'test':test}\n",
    "\n",
    "# 7) Using CSV file with paths/labels\n",
    "\n",
    "def load_from_csv(csv_path):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # expects columns: filepath, label\n",
    "    X = df['filepath'].values\n",
    "    y = df['label'].values\n",
    "    return X, y\n",
    "\n",
    "# 8) TFRecord example writer/reader (skeleton)\n",
    "def write_tfrecord_example(image_paths, labels, output_tfrecord):\n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for p, l in zip(image_paths, labels):\n",
    "            img = open(p, 'rb').read()\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img])),\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(l)]))\n",
    "            }\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "# ----------------------\n",
    "# Experiment skeletons (TF)\n",
    "# ----------------------\n",
    "\n",
    "# Ex 1: DNN for image classification (on flattened images)\n",
    "def experiment_dnn_tf(X_train, y_train, X_val, y_val, input_shape=(32*32*3,), n_classes=10):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)\n",
    "    return model\n",
    "\n",
    "# Ex 2: CNN vs DNN comparison\n",
    "\n",
    "def experiment_cnn_tf(train_ds, val_ds, n_classes=10):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(224,224,3)),\n",
    "        layers.Conv2D(32,3,activation='relu'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(64,3,activation='relu'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "    return model\n",
    "\n",
    "# Ex 3: Object detector (simplified: predict bounding box + class)\n",
    "def experiment_object_detection_tf(train_ds_with_boxes, val_ds_with_boxes):\n",
    "    # train_ds_with_boxes should yield (image, [x_min,y_min,x_max,y_max,class_id])\n",
    "    inputs = layers.Input(shape=(224,224,3))\n",
    "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    bbox = layers.Dense(4, activation='sigmoid', name='bbox')(x)\n",
    "    cls = layers.Dense(1, activation='sigmoid', name='class')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=[bbox, cls])\n",
    "    model.compile(optimizer='adam', loss={'bbox':'mse','class':'binary_crossentropy'})\n",
    "    model.fit(train_ds_with_boxes, validation_data=val_ds_with_boxes, epochs=10)\n",
    "    return model\n",
    "\n",
    "# Ex 4: FCN-like segmentation (skeleton)\n",
    "def experiment_segmentation_tf(train_ds, val_ds, n_classes=2):\n",
    "    inputs = layers.Input(shape=(128,128,3))\n",
    "    c1 = layers.Conv2D(32,3,activation='relu', padding='same')(inputs)\n",
    "    p1 = layers.MaxPool2D()(c1)\n",
    "    c2 = layers.Conv2D(64,3,activation='relu', padding='same')(p1)\n",
    "    up = layers.UpSampling2D()(c2)\n",
    "    outputs = layers.Conv2D(n_classes, 1, activation='softmax')(up)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "    return model\n",
    "\n",
    "# Ex 5 & 6: Autoencoder and Conv Autoencoder\n",
    "\n",
    "def experiment_autoencoder_tf(x_train, x_val, latent_dim=64):\n",
    "    input_img = layers.Input(shape=(28,28,1))\n",
    "    x = layers.Flatten()(input_img)\n",
    "    encoded = layers.Dense(latent_dim, activation='relu')(x)\n",
    "    decoded = layers.Dense(28*28, activation='sigmoid')(encoded)\n",
    "    decoded = layers.Reshape((28,28,1))(decoded)\n",
    "    auto = keras.Model(input_img, decoded)\n",
    "    auto.compile(optimizer='adam', loss='mse')\n",
    "    auto.fit(x_train, x_train, validation_data=(x_val, x_val), epochs=10)\n",
    "    return auto\n",
    "\n",
    "# Ex 7: Denoising autoencoder (skeleton)\n",
    "def experiment_denoising_autoencoder_tf(x_train, x_val, noise_factor=0.5):\n",
    "    x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "    x_val_noisy = x_val + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_val.shape)\n",
    "    return experiment_autoencoder_tf(x_train_noisy, x_val_noisy)\n",
    "\n",
    "# Ex 8: Image captioning skeleton (feature extractor + RNN decoder)\n",
    "\n",
    "def experiment_image_captioning_tf(image_features, captions_seq, tokenizer, vocab_size):\n",
    "    # image_features: precomputed features per image\n",
    "    # captions_seq: tokenized sequences\n",
    "    img_input = layers.Input(shape=(image_features.shape[1],))\n",
    "    seq_input = layers.Input(shape=(None,))\n",
    "    se = layers.Embedding(vocab_size, 128)(seq_input)\n",
    "    se = layers.LSTM(256)(se)\n",
    "    concat = layers.concatenate([img_input, se])\n",
    "    out = layers.Dense(vocab_size, activation='softmax')(concat)\n",
    "    model = keras.Model([img_input, seq_input], out)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    # model.fit([...])\n",
    "    return model\n",
    "\n",
    "# Ex 9 & 10: LSTM handwriting recognition / RNN vs LSTM vs GRU for time series\n",
    "\n",
    "def experiment_rnn_tf(X_train, y_train, cell='LSTM'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    if cell == 'LSTM':\n",
    "        model.add(layers.LSTM(64))\n",
    "    elif cell == 'GRU':\n",
    "        model.add(layers.GRU(64))\n",
    "    else:\n",
    "        model.add(layers.SimpleRNN(64))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=10)\n",
    "    return model\n",
    "\n",
    "# Ex 11: GAN skeleton (generator/discriminator)\n",
    "\n",
    "def experiment_gan_tf(latent_dim=100):\n",
    "    # Generator\n",
    "    gen_in = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(7*7*128, activation='relu')(gen_in)\n",
    "    x = layers.Reshape((7,7,128))(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    gen_out = layers.Conv2D(1, kernel_size=3, padding='same', activation='sigmoid')(x)\n",
    "    generator = keras.Model(gen_in, gen_out)\n",
    "\n",
    "    # Discriminator\n",
    "    dis_in = layers.Input(shape=(28,28,1))\n",
    "    y = layers.Conv2D(64,3, strides=2, padding='same', activation='relu')(dis_in)\n",
    "    y = layers.Flatten()(y)\n",
    "    dis_out = layers.Dense(1, activation='sigmoid')(y)\n",
    "    discriminator = keras.Model(dis_in, dis_out)\n",
    "    discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    # GAN combined (simple)\n",
    "    discriminator.trainable = False\n",
    "    z = layers.Input(shape=(latent_dim,))\n",
    "    img = generator(z)\n",
    "    validity = discriminator(img)\n",
    "    combined = keras.Model(z, validity)\n",
    "    combined.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return generator, discriminator, combined\n",
    "\n",
    "# Ex 12: Reinforcement Learning skeleton (policy gradient) - pseudocode\n",
    "\n",
    "def experiment_rl_policy_gradient(env):\n",
    "    # env : any OpenAI Gym-like environment (offline exam: provide a mock env)\n",
    "    pass\n",
    "\n",
    "###########################\n",
    "# SECTION 2: PYTORCH\n",
    "###########################\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "# Placeholder paths\n",
    "PT_DATA_DIR = '/RANDOM_PATH/IMAGES'\n",
    "PT_NPZ = '/RANDOM_PATH/dataset.npz'\n",
    "\n",
    "# ----------------------\n",
    "# DATA LOADING METHODS (PyTorch)\n",
    "# ----------------------\n",
    "\n",
    "# 1) datasets.ImageFolder\n",
    "\n",
    "def get_imagefolder_loader(root_dir=PT_DATA_DIR, batch_size=32, image_size=(224,224)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "# 2) Custom Dataset from folder or CSV\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels=None, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.img_paths[idx]\n",
    "        img = Image.open(p).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.labels is not None:\n",
    "            return img, self.labels[idx]\n",
    "        return img\n",
    "\n",
    "# 3) Loading .npz / .npy into tensors\n",
    "\n",
    "def load_npz_pytorch(npz_path=PT_NPZ):\n",
    "    data = np.load(npz_path)\n",
    "    X = torch.tensor(data['X']).float()\n",
    "    y = torch.tensor(data['y']).long()\n",
    "    return X, y\n",
    "\n",
    "# 4) Manual train/val/test split from single folder\n",
    "\n",
    "def split_folder_pytorch(single_folder, out_dir='/tmp/pytorch_split', val_frac=0.1, test_frac=0.1, seed=123):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    imgs = [os.path.join(single_folder,f) for f in os.listdir(single_folder) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "    train_and_val, test = train_test_split(imgs, test_size=test_frac, random_state=seed)\n",
    "    train, val = train_test_split(train_and_val, test_size=val_frac/(1-test_frac), random_state=seed)\n",
    "    for split, files in zip(['train','val','test'], [train,val,test]):\n",
    "        d = os.path.join(out_dir, split)\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "        for p in files:\n",
    "            shutil.copy(p, d)\n",
    "    return {'train':train, 'val':val, 'test':test}\n",
    "\n",
    "# ----------------------\n",
    "# Experiment skeletons (PyTorch)\n",
    "# ----------------------\n",
    "\n",
    "# Ex 1: DNN\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Ex 2: CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.fc1 = nn.Linear(64*56*56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Ex 3: Object detection skeleton (predict bbox + class)\n",
    "class TinyDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,16,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc = nn.Linear(16*112*112, 128)\n",
    "        self.bbox = nn.Linear(128, 4)\n",
    "        self.cls = nn.Linear(128, 1)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return self.bbox(x), torch.sigmoid(self.cls(x))\n",
    "\n",
    "# Ex 4: Segmentation skeleton (simple conv-deconv)\n",
    "class TinySeg(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
    "        self.dec = nn.Sequential(nn.Upsample(scale_factor=2), nn.Conv2d(16,num_classes,3,padding=1))\n",
    "    def forward(self,x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x\n",
    "\n",
    "# Ex 5 & 6: Autoencoder\n",
    "class AutoencoderPT(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Flatten(), nn.Linear(28*28, latent_dim))\n",
    "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 28*28), nn.Unflatten(1, (1,28,28)))\n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# Ex 7: Denoising AE uses same model + noisy inputs\n",
    "\n",
    "# Ex 8: Image captioning skeleton (CNN features + RNN decoder)\n",
    "class CaptionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    def forward(self, captions):\n",
    "        x = self.embed(captions)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)\n",
    "\n",
    "# Ex 9 & 10: RNN/LSTM/GRU for sequences\n",
    "class SequenceModelPT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, cell='LSTM'):\n",
    "        super().__init__()\n",
    "        if cell == 'LSTM':\n",
    "            self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        elif cell == 'GRU':\n",
    "            self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    def forward(self,x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "# Ex 11: GAN skeleton (PyTorch)\n",
    "class GeneratorPT(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128*7*7),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128,7,7)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128,1,3,padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,z):\n",
    "        return self.model(z)\n",
    "\n",
    "class DiscriminatorPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,64,3,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*14*14,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Ex 12: RL skeleton (PyTorch)\n",
    "\n",
    "def rl_policy_gradient_skeleton():\n",
    "    # For offline lab: implement a mock environment or simple bandit\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW-VENV-1",
   "language": "python",
   "name": "new-venv-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

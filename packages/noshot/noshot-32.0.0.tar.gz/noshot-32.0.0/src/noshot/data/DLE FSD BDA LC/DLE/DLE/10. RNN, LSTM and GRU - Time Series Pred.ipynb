{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "uyxd_XDYrXmt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.layers import Dense,Dropout,SimpleRNN,LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "#check all the files in the input dataset\n",
    "#print(os.listdir(\"../input/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwSkul-8rXm2"
   },
   "source": [
    "## 2. Data loading and data exploration\n",
    "\n",
    "- **Load the data file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgVZiMfzrXm4",
    "outputId": "84d880e7-fc8a-4cf6-c35e-2a3e82ba7948"
   },
   "outputs": [],
   "source": [
    "#choosing DOM_hourly.csv data for analysis\n",
    "fpath='D://Users//user//Downloads//DOM_hourly.csv//DOM_hourly.csv'\n",
    "\n",
    "df=pd.read_csv(fpath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytleaENOrXnA"
   },
   "source": [
    "- **Change the index of rows in the dataframe from 0,1,2... to datetime (2005-12-31 01:00:00,...)**\n",
    "\n",
    "**Why should we change the index of rows?**<br>\n",
    "Because we are dealing with time series data and we will need the datetime data to recognize a particular record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sImMtDIhrXnC",
    "outputId": "a9850f1f-9568-422e-effe-c91ccf7aee7a"
   },
   "outputs": [],
   "source": [
    "#Let's use datetime(2012-10-01 12:00:00,...) as index instead of numbers(0,1,...)\n",
    "#This will be helpful for further data analysis as we are dealing with time series data\n",
    "df = pd.read_csv(fpath, index_col='Datetime', parse_dates=['Datetime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IVV9mHXrXnD"
   },
   "source": [
    "- **Check if there are missing values in the data loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZtbkZfcrXnE",
    "outputId": "5c79dbb2-7c83-4919-f711-a5dd0bdbc85f"
   },
   "outputs": [],
   "source": [
    "#checking missing data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgAeoazLrXnX"
   },
   "source": [
    "Since there is no missing data in the data loaded we will not be dropping the missing value records or will not be imputing the data. We will proceed with the further data analysis.\n",
    "\n",
    "- **Data visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POQDAJldrXnc",
    "outputId": "b8f97e5e-57d4-425f-9707-8d1c00ef4b21"
   },
   "outputs": [],
   "source": [
    "df.plot(figsize=(16,4),legend=True)\n",
    "\n",
    "plt.title('DOM hourly power consumption data - BEFORE NORMALIZATION')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBmrnYzXrXnj"
   },
   "source": [
    "- **Normalize data**\n",
    "- Before proceeding with further data analysis we must ensure that the data is normalized.\n",
    "- For this we will be using [sklearn MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyikQRHzrXnl",
    "outputId": "3a72ddd0-bdd0-4bf3-f54a-bce61d6e4b7b"
   },
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['DOM_MW']=scaler.fit_transform(df['DOM_MW'].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "df_norm = normalize_data(df)\n",
    "df_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX4cN79lrXnl"
   },
   "source": [
    "- **Visualize data after normalization**\n",
    "- After normalization the range of power consumption values changes which we can observe on the **y-axis** of the graph. In the earlier graph that was displayed it was in the range **0 - 22500**\n",
    "- Now after normalization we can observe that the data range on **y-axis** is **0.0 - 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUnNEZ7ArXnm",
    "outputId": "337bd586-7b01-4308-cd06-1b6057089760"
   },
   "outputs": [],
   "source": [
    "df_norm.plot(figsize=(16,4),legend=True)\n",
    "\n",
    "plt.title('DOM hourly power consumption data - AFTER NORMALIZATION')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj5HnvK0rXnn",
    "outputId": "1fbd821e-7129-474b-8ca2-8c1204f2e8d5"
   },
   "outputs": [],
   "source": [
    "df_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxelk21LrXnn"
   },
   "source": [
    "## 3. Prepare data for training the RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uMtZq2arXnn"
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(seq_len, len(stock)):\n",
    "        X_train.append(stock.iloc[i-seq_len : i, 0])\n",
    "        y_train.append(stock.iloc[i, 0])\n",
    "\n",
    "    #1 last 6189 days are going to be used in test\n",
    "    X_test = X_train[110000:]\n",
    "    y_test = y_train[110000:]\n",
    "\n",
    "    #2 first 110000 days are going to be used in training\n",
    "    X_train = X_train[:110000]\n",
    "    y_train = y_train[:110000]\n",
    "\n",
    "\n",
    "    #3 convert to numpy array\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    print(X_train.shape)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #4 reshape data to input into RNN models\n",
    "    X_train = np.reshape(X_train, (110000, seq_len, 1))\n",
    "    print(X_train.shape)\n",
    "\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "836f4SwjrXno"
   },
   "source": [
    "**To get an understanding on how sequence length is useful in training RNN models refer to the following links:**\n",
    "- https://stackoverflow.com/questions/49573242/what-is-sequence-length-in-lstm\n",
    "- https://stats.stackexchange.com/questions/158834/what-is-a-feasible-sequence-length-for-an-rnn-to-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA0ttzKYrXno",
    "outputId": "0aab8f8c-2a8f-443a-befb-d7ef54df6632"
   },
   "outputs": [],
   "source": [
    "#create train, test data\n",
    "seq_len = 20 #choose sequence length\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "\n",
    "print('X_train.shape = ',X_train.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('X_test.shape = ', X_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiLn2PT0rXnp"
   },
   "source": [
    "## 4. Build a SIMPLE RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8R5cuqMrXnp",
    "outputId": "f053f7a0-a2e0-4d14-ee21-50b4dc0475c2"
   },
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "\n",
    "rnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\n",
    "rnn_model.add(Dropout(0.15))\n",
    "\n",
    "rnn_model.add(Dense(1))\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efw7K6sMrXnp",
    "outputId": "5df19763-dc0c-41c9-b9a2-bee565da6b10"
   },
   "outputs": [],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6IM9h82rXnq",
    "outputId": "b978e242-5040-4307-e90f-0f3bd982918b"
   },
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "rnn_model.fit(X_train, y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYTFnt4trXnq"
   },
   "source": [
    "- **Let's check r2 score for the values predicted by the above trained SIMPLE RNN model**\n",
    "- For more info on r2 score refer [this](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5glSp8HrXnq",
    "outputId": "845a4d63-273c-4639-b62e-988b6e30d556"
   },
   "outputs": [],
   "source": [
    "rnn_predictions = rnn_model.predict(X_test)\n",
    "\n",
    "rnn_score = r2_score(y_test,rnn_predictions)\n",
    "print(\"R2 Score of RNN model = \",rnn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDqQVovUrXnr"
   },
   "source": [
    "- **Let's compare the actual values vs predicted values by plotting a graph**\n",
    "- We see that the predcited values are close to the actual values meaning the RNN model is performing well in predicting the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhhiM0c8rXnr",
    "outputId": "1788632f-4621-426e-b5e3-935a7318bbec"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(test, predicted, title):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(test, color='blue',label='Actual power consumption data')\n",
    "    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Normalized power consumption scale')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(y_test, rnn_predictions, \"Predictions made by simple RNN model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb3Y0gAMrXnr"
   },
   "source": [
    "## 5. Build an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAG1bicLrXnr",
    "outputId": "059ef183-f47e-4dd0-98f4-e6b7d9d09825"
   },
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=True))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "\n",
    "lstm_model.add(LSTM(40,activation=\"tanh\",return_sequences=False))\n",
    "lstm_model.add(Dropout(0.15))\n",
    "\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoz390olrXns",
    "outputId": "bfd07bef-7d8a-4819-82e6-2ccb10a6da8e"
   },
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNn9VSzcrXns"
   },
   "source": [
    "- **Let's check r2 score for the values predicted by the above trained LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucPB-v-BrXns",
    "outputId": "85107fab-9888-4e87-ec79-d7fa58af3ddf"
   },
   "outputs": [],
   "source": [
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "\n",
    "lstm_score = r2_score(y_test, lstm_predictions)\n",
    "print(\"R^2 Score of LSTM model = \",lstm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewCzHhYgrXnt"
   },
   "source": [
    "- **Let's compare the actual values vs predicted values by plotting a graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ownv9jZKrXnt",
    "outputId": "8ff479e7-7adc-4b80-9ac6-09b9cd5089a6"
   },
   "outputs": [],
   "source": [
    "plot_predictions(y_test, lstm_predictions, \"Predictions made by LSTM model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jrZTsUvrXnu"
   },
   "source": [
    "## 6. Compare predictions made by simple RNN, LSTM model by plotting data in a single graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHWEWPZyrXnx",
    "outputId": "17bed10f-ca18-4209-d86c-ff7fc4ab09b1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.plot(y_test, c=\"orange\", linewidth=3, label=\"Original values\")\n",
    "plt.plot(lstm_predictions, c=\"red\", linewidth=3, label=\"LSTM predictions\")\n",
    "plt.plot(rnn_predictions, alpha=0.5, c=\"green\", linewidth=3, label=\"RNN predictions\")\n",
    "plt.legend()\n",
    "plt.title(\"Predictions vs actual data\", fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

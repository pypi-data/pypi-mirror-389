"""
MCP æœåŠ¡å™¨ - ä¸»æœåŠ¡å™¨
=====================================

è¿™æ˜¯ä¸»è¦çš„ MCP æœåŠ¡å™¨ï¼Œé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ã€‚
ä¿ç•™äº†æ‰€æœ‰ç°æœ‰åŠŸèƒ½ï¼Œå¹¶è¿›è¡Œäº†æ›´å¥½çš„ç»„ç»‡ã€‚
ç°åœ¨æ”¯æŒç»“æ„åŒ–æ¨¡å‹ï¼ˆDocumentModel å’Œ MetadataModelï¼‰ã€‚
"""

import os
import sys
from datetime import datetime
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP
from urllib.parse import urlparse

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "src")))

# å¯¼å…¥å·¥å…·
from utils.logger import log, log_mcp_server
from utils.config import Config

# å¯¼å…¥ RAG æ ¸å¿ƒåŠŸèƒ½ï¼ˆäº‘ç«¯å®ç°ï¼‰
from rag_core_openai import (
    add_text_to_knowledge_base,
    add_text_to_knowledge_base_enhanced,
    load_document_with_fallbacks,
    get_qa_chain,
    get_vector_store,
    search_with_metadata_filters,
    create_metadata_filter,
    get_document_statistics,
    get_cache_stats,
    print_cache_stats,
    clear_embedding_cache,
    optimize_vector_store,
    get_vector_store_stats,
    reindex_vector_store,
    get_optimal_vector_store_profile,
    load_document_with_elements
)

# å¯¼å…¥ç»“æ„åŒ–æ¨¡å‹
try:
    from models import DocumentModel, MetadataModel
    MODELS_AVAILABLE = True
    log_mcp_server("âœ… ç»“æ„åŒ–æ¨¡å‹ (DocumentModel, MetadataModel) å¯ç”¨")
except ImportError as e:
    MODELS_AVAILABLE = False
    log_mcp_server(f"âš ï¸ ç»“æ„åŒ–æ¨¡å‹ä¸å¯ç”¨: {e}")

# --- åˆå§‹åŒ–æœåŠ¡å™¨å’Œé…ç½® ---
load_dotenv()
mcp = FastMCP(Config.SERVER_NAME)

# çŠ¶æ€ç°åœ¨åŒ…æ‹¬æœ‰å…³ç»“æ„åŒ–æ¨¡å‹çš„ä¿¡æ¯
rag_state = {
    "models_available": MODELS_AVAILABLE,
    "structured_processing": MODELS_AVAILABLE,
    "document_models": [],  # å·²å¤„ç†çš„ DocumentModel åˆ—è¡¨
    "metadata_cache": {}    # æ¯ä¸ªæ–‡æ¡£çš„ MetadataModel ç¼“å­˜
}

md_converter = None

def warm_up_rag_system():
    """
    é¢„åŠ è½½ RAG ç³»ç»Ÿçš„é‡å‹ç»„ä»¶ï¼Œä»¥é¿å…é¦–æ¬¡è°ƒç”¨å·¥å…·æ—¶çš„å»¶è¿Ÿå’Œå†²çªã€‚
    """
    if "warmed_up" in rag_state:
        return
    
    log_mcp_server("æ­£åœ¨é¢„çƒ­ RAG ç³»ç»Ÿ...")
    log_mcp_server("åˆå§‹åŒ–äº‘ç«¯å‘é‡å­˜å‚¨ï¼ˆOpenAI-onlyï¼‰...")
    
    rag_state["warmed_up"] = True
    log_mcp_server("RAG ç³»ç»Ÿå·²é¢„çƒ­å¹¶å‡†å¤‡å°±ç»ªã€‚")

def ensure_converted_docs_directory():
    """ç¡®ä¿å­˜åœ¨ç”¨äºå­˜å‚¨è½¬æ¢æ–‡æ¡£çš„æ–‡ä»¶å¤¹ã€‚"""
    Config.ensure_directories()
    if not os.path.exists(Config.CONVERTED_DOCS_DIR):
        os.makedirs(Config.CONVERTED_DOCS_DIR)
        log_mcp_server(f"å·²åˆ›å»ºè½¬æ¢æ–‡æ¡£æ–‡ä»¶å¤¹: {Config.CONVERTED_DOCS_DIR}")

def save_processed_copy(file_path: str, processed_content: str, processing_method: str = "unstructured") -> str:
    """
    ä¿å­˜å¤„ç†åçš„æ–‡æ¡£å‰¯æœ¬ä¸º Markdown æ ¼å¼ã€‚

    å‚æ•°ï¼š
        file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        processed_content: å¤„ç†åçš„å†…å®¹
        processing_method: ä½¿ç”¨çš„å¤„ç†æ–¹æ³•

    è¿”å›ï¼š
        ä¿å­˜çš„ Markdown æ–‡ä»¶è·¯å¾„
    """
    ensure_converted_docs_directory()
    
    # è·å–åŸå§‹æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
    original_filename = os.path.basename(file_path)
    name_without_ext = os.path.splitext(original_filename)[0]
    
    # åˆ›å»ºåŒ…å«æ–¹æ³•ä¿¡æ¯çš„ Markdown æ–‡ä»¶å
    md_filename = f"{name_without_ext}_{processing_method}.md"
    md_filepath = os.path.join(Config.CONVERTED_DOCS_DIR, md_filename)
    
    # ä¿å­˜å†…å®¹åˆ° Markdown æ–‡ä»¶
    try:
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(processed_content)
        log_mcp_server(f"å·²ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {md_filepath}")
        return md_filepath
    except Exception as e:
        log_mcp_server(f"è­¦å‘Š: æ— æ³•ä¿å­˜å¤„ç†åçš„å‰¯æœ¬: {e}")
        return ""

def initialize_rag():
    """
    ä½¿ç”¨æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶ã€‚
    """
    if "initialized" in rag_state:
        return

    log_mcp_server("é€šè¿‡æ ¸å¿ƒåˆå§‹åŒ– RAG ç³»ç»Ÿ...")
    
    # ä»äº‘ç«¯æ ¸å¿ƒè·å–å‘é‡å­˜å‚¨å’Œ QA é“¾
    vector_store = get_vector_store()
    qa_chain = get_qa_chain(vector_store)
    
    rag_state["vector_store"] = vector_store
    rag_state["qa_chain"] = qa_chain
    rag_state["initialized"] = True
    
    # å…³äºæ¨¡å‹çŠ¶æ€çš„ä¿¡æ¯
    if MODELS_AVAILABLE:
        log_mcp_server("âœ… RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œæ”¯æŒç»“æ„åŒ–æ¨¡å‹")
        log_mcp_server("ğŸ§  DocumentModel å’Œ MetadataModel å¯ç”¨äºé«˜çº§å¤„ç†")
    else:
        log_mcp_server("âš ï¸ RAG ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œä½†æœªå¯ç”¨ç»“æ„åŒ–æ¨¡å‹ (ä½¿ç”¨å­—å…¸)")
    
    log_mcp_server("RAG ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸã€‚")

# --- åˆå§‹åŒ–è‡ªåŠ¨åŒ– RAG ç³»ç»Ÿ ---
log_mcp_server("è‡ªåŠ¨åˆå§‹åŒ– RAG ç³»ç»Ÿ...")
backend = "JSON"
log_mcp_server("RAG åç«¯: JSON")
initialize_rag()
warm_up_rag_system()
log_mcp_server("RAG ç³»ç»Ÿå·²åˆå§‹åŒ–å¹¶å‡†å¤‡å°±ç»ªã€‚")

# --- åœ¨åˆå§‹åŒ– RAG åé…ç½®æ¨¡å—åŒ–å·¥å…· ---
from tools import configure_rag_state, ALL_TOOLS

# é…ç½®å·¥å…·æ¨¡å—ä¸­çš„ RAG çŠ¶æ€
configure_rag_state(
    rag_state=rag_state,
    initialize_rag_func=initialize_rag,
    save_processed_copy_func=save_processed_copy
)

# --- Definir las herramientas MCP directamente en el servidor ---
@mcp.tool()
def ask_rag(query: str) -> str:
    """ç”¨æˆ·æƒ³æŸ¥è¯¢å·²æœ‰èµ„æ–™æˆ–è€…éœ€è¦çŸ¥è¯†åº“æ—¶è°ƒç”¨"""
    from tools.search_tools import ask_rag as ask_rag_logic
    return ask_rag_logic(query)

mcp.ask_rag = ask_rag


# @mcp.tool()
# def get_context(**kwargs) -> str:
#     """ç”¨æˆ·æƒ³æŸ¥è¯¢å·²æœ‰èµ„æ–™æˆ–è€…éœ€è¦çŸ¥è¯†åº“æ—¶è°ƒç”¨"""
#     try:
#         query = kwargs.get("query", "")
#         from tools.search_tools import get_context_tool
#         return get_context_tool(query, k=5)
#     except Exception as e:
#         log_mcp_server(f"æ³¨å†Œå·¥å…· get_context æ—¶å‡ºé”™: {e}")
#         return ""

# mcp.get_context = get_context

# --- å¯åŠ¨ MCP RAG æœåŠ¡å™¨ ---
if __name__ == "__main__":
    log_mcp_server("å¯åŠ¨ MCP RAG æœåŠ¡å™¨...")
    warm_up_rag_system()  # å¯åŠ¨æ—¶é¢„çƒ­ç³»ç»Ÿ
    log_mcp_server("ğŸš€ æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œè¿è¡Œæ¨¡å¼: stdio")
    mcp.ask_rag = ask_rag
    # mcp.get_context = get_context
    mcp.run(transport='stdio')
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SignXAI2 PyTorch Advanced Tutorial - Image Classification\n",
    "\n",
    "This advanced tutorial demonstrates sophisticated analysis techniques using SignXAI2 with PyTorch, including class-specific explanations and positive/negative contribution separation.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Complete the basic PyTorch tutorial first, and ensure you have the required data and model setup.\n",
    "\n",
    "⚠️ **Data Requirements**: This tutorial requires example data from the GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Basic Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from signxai import explain, list_methods\n",
    "from signxai.utils.utils import normalize_heatmap\n",
    "import urllib.request\n",
    "\n",
    "# Download an example image\n",
    "url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images/n02106030-collie/n02106030_16370.jpg\"\n",
    "urllib.request.urlretrieve(url, \"dog.jpg\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Remove softmax layer (critical for explanations)\n",
    "model.classifier[-1] = torch.nn.Identity()\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = \"dog.jpg\"\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "img_np = np.array(img.resize((224, 224))) / 255.0  # For visualization\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "print(f\"Predicted class index: {predicted_idx.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis\n",
    "\n",
    "Let's compare class-specific explanations for PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get top 3 predicted classes\nprobabilities = torch.nn.functional.softmax(output[0], dim=0)\ntop_probs, top_classes = torch.topk(probabilities, 3)\n\n# Calculate explanations for each class using a complex method with parameter chaining\n# This demonstrates: gradient (base) + x_input (multiply by input) + x_sign (apply sign) + mu_neg_0_5 (parameter)\nclass_explanations = {}\nfor idx in top_classes:\n    class_explanations[idx.item()] = explain(\n        model=model,\n        x=input_tensor,\n        method_name='gradient_x_input_x_sign_mu_neg_0_5',\n        target_class=idx.item()\n    )\n\n# Visualize\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\n\n# Original image\naxs[0].imshow(img_np)\naxs[0].set_title('Original Image', fontsize=14)\naxs[0].axis('off')\n\n# Class-specific explanations\nfor i, idx in enumerate(top_classes):\n    explanation = class_explanations[idx.item()][0].sum(axis=0)\n    axs[i+1].imshow(normalize_heatmap(explanation), cmap='seismic', clim=(-1, 1))\n    axs[i+1].set_title(f'Class: {idx.item()}', fontsize=14)\n    axs[i+1].axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive and Negative Contribution Separation\n",
    "\n",
    "We can also highlight the positive and negative contributions separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choose a complex method with parameter chaining and generate explanation\n# This showcases: gradient (base) + x_input (multiply by input) + x_sign (apply sign) + mu_neg_0_5 (parameter)\nmethod = 'gradient_x_input_x_sign_mu_neg_0_5'\nexplanation = explain(\n    model=model,\n    x=input_tensor,\n    method_name=method,\n    target_class=predicted_idx.item()\n)[0].sum(axis=0)  # Sum over channels\n\n# Separate positive and negative contributions\npos_expl = np.maximum(0, explanation)\nneg_expl = np.minimum(0, explanation)\n\n# Normalize\npos_norm = pos_expl / np.max(pos_expl) if np.max(pos_expl) > 0 else pos_expl\nneg_norm = neg_expl / np.min(neg_expl) if np.min(neg_expl) < 0 else neg_expl\n\n# Visualize\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\n\n# Original image\naxs[0].imshow(img_np)\naxs[0].set_title('Original Image', fontsize=14)\naxs[0].axis('off')\n\n# Combined explanation\naxs[1].imshow(normalize_heatmap(explanation), cmap='seismic', clim=(-1, 1))\naxs[1].set_title(f'{method} - Combined', fontsize=14)\naxs[1].axis('off')\n\n# Positive contributions\naxs[2].imshow(pos_norm, cmap='Reds')\naxs[2].set_title('Positive Contributions', fontsize=14)\naxs[2].axis('off')\n\n# Negative contributions\naxs[3].imshow(-neg_norm, cmap='Blues')\naxs[3].set_title('Negative Contributions', fontsize=14)\naxs[3].axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this advanced tutorial, we've demonstrated how to:\n",
    "\n",
    "1. **Class-specific Analysis**: Generate explanations for different predicted classes to understand what features the model associates with each class\n",
    "2. **Contribution Separation**: Separate positive and negative contributions to better understand how different regions support or oppose the prediction\n",
    "3. **Advanced Visualization**: Create comprehensive visualizations that reveal different aspects of the model's decision-making process\n",
    "\n",
    "These techniques provide deeper insights into model behavior and can help identify potential biases or areas for model improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

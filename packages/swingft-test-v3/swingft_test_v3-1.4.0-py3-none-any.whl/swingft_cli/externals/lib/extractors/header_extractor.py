#!/usr/bin/env python3
"""
Swift ì†ŒìŠ¤ì½”ë“œ ë‚œë…í™”ë¥¼ ìœ„í•œ í—¤ë” ì‹ë³„ì ì¶”ì¶œê¸° (ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „)

DerivedDataì™€ í”„ë¡œì íŠ¸ ë‚´ì˜ ëª¨ë“  í—¤ë” íŒŒì¼ì—ì„œ ë‚œë…í™” ì œì™¸ ëŒ€ìƒ ì‹ë³„ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ì†ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

import re
import argparse
import glob
from pathlib import Path
from typing import Set, Dict, List, Tuple
from collections import defaultdict
from enum import Enum, auto
from multiprocessing import Pool, cpu_count
import time
import logging
import os
 # local trace/strict helpers

# Per-file verbose output toggle (set True to print each file summary)
VERBOSE_PER_FILE = False

def _trace(msg: str, *args, **kwargs) -> None:
    try:
        logging.trace(msg, *args, **kwargs)
    except (OSError, ValueError, TypeError, AttributeError) as e:
        # ë¡œê¹… ì‹¤íŒ¨ ì‹œì—ë„ í”„ë¡œê·¸ë¨ì€ ê³„ì† ì§„í–‰
        return

def _maybe_raise(e: BaseException) -> None:
    try:
        if str(os.environ.get("SWINGFT_TUI_STRICT", "")).strip() == "1":
            raise e
    except (OSError, ValueError, TypeError, AttributeError) as e:
        # í™˜ê²½ë³€ìˆ˜ ì½ê¸° ì‹¤íŒ¨ ì‹œì—ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
        return


class ParseState(Enum):
    NORMAL = auto()
    SINGLE_LINE_COMMENT = auto()
    MULTI_LINE_COMMENT = auto()
    STRING = auto()
    STRING_ESCAPE = auto()
    PREPROCESSOR = auto()


class ObjectiveCCommentRemover:
    """Objective-C ì£¼ì„ ì œê±°"""

    def remove_comments(self, source: str) -> str:
        result = []
        state = ParseState.NORMAL
        i = 0
        length = len(source)

        while i < length:
            char = source[i]

            if state == ParseState.NORMAL:
                if char == '/' and i + 1 < length:
                    if source[i + 1] == '/':
                        state = ParseState.SINGLE_LINE_COMMENT
                        i += 1
                    elif source[i + 1] == '*':
                        state = ParseState.MULTI_LINE_COMMENT
                        i += 1
                    else:
                        result.append(char)
                elif char == '"' or (char == '@' and i + 1 < length and source[i + 1] == '"'):
                    result.append(char)
                    if char == '@':
                        result.append('"')
                        i += 1
                    state = ParseState.STRING
                elif char == '#' and (i == 0 or source[i - 1] == '\n'):
                    result.append(char)
                    state = ParseState.PREPROCESSOR
                else:
                    result.append(char)

            elif state == ParseState.STRING:
                result.append(char)
                if char == '\\':
                    state = ParseState.STRING_ESCAPE
                elif char == '"':
                    state = ParseState.NORMAL

            elif state == ParseState.STRING_ESCAPE:
                result.append(char)
                state = ParseState.STRING

            elif state == ParseState.SINGLE_LINE_COMMENT:
                if char == '\n':
                    result.append(char)
                    state = ParseState.NORMAL

            elif state == ParseState.MULTI_LINE_COMMENT:
                if char == '*' and i + 1 < length and source[i + 1] == '/':
                    i += 1
                    state = ParseState.NORMAL

            elif state == ParseState.PREPROCESSOR:
                result.append(char)
                if char == '\n':
                    if len(result) >= 2 and result[-2] == '\\':
                        pass
                    else:
                        state = ParseState.NORMAL

            i += 1

        return "".join(result)


class ObjCHeaderParser:
    """Objective-C í—¤ë” íŒŒì„œ - ëª¨ë“  ê³µê°œ ì‹ë³„ì ì¶”ì¶œ"""

    PATTERNS = {
        'interface': re.compile(r'@interface\s+(\w+)\s*[:(]', re.MULTILINE),
        'protocol': re.compile(r'@protocol\s+(\w+)\b', re.MULTILINE),

        'struct_typedef': re.compile(r'typedef\s+struct\s+\w*\s*\{[^}]*\}\s*(\w+)\s*;',
                                     re.MULTILINE | re.DOTALL),
        'struct_plain': re.compile(r'struct\s+(\w+)\s*\{', re.MULTILINE),

        'enum_ns': re.compile(r'(?:NS_ENUM|NS_OPTIONS|NS_CLOSED_ENUM|NS_ERROR_ENUM)\s*\(\s*\w+\s*,\s*(\w+)\s*\)',
                              re.MULTILINE),
        'enum_typedef': re.compile(r'typedef\s+enum\s+\w*\s*(?::\s*\w+)?\s*\{[^}]*\}\s*(\w+)\s*;',
                                   re.MULTILINE | re.DOTALL),
        'enum_forward_decl': re.compile(r'enum\s+(\w+)\s*:\s*\w+\s*;', re.MULTILINE),
        'swift_enum': re.compile(r'typedef\s+SWIFT_ENUM\s*\([^,]+,\s*(\w+)\s*,', re.MULTILINE),

        'typedef_funcptr': re.compile(r'typedef\s+.+\(\s*\*\s*(\w+)\s*\)\s*\(.*\)\s*;', re.MULTILINE),
        'typedef_block': re.compile(r'typedef\s+.+\(\s*\^\s*(\w+)\s*\)\s*\(.*\)\s*;', re.MULTILINE),
        'typedef': re.compile(r'typedef\s+(?!enum|struct|union).*?\s+(\w+)\s*;',
                              re.MULTILINE | re.DOTALL),

        'function': re.compile(r'^(?:extern\s+)?(?:static\s+)?(?:inline\s+)?[A-Z]\w*\s+\*?\s*(\w+)\s*\(',
                               re.MULTILINE),
        'export_function': re.compile(
            r'^(?:FOUNDATION_EXPORT|NS_SWIFT_NAME|UIKIT_EXTERN|extern)\s+.*?\*?\s*([a-zA-Z_]\w+)\s*\(',
            re.MULTILINE),

        'extern_const': re.compile(
            r'(?:FOUNDATION_EXPORT|UIKIT_EXTERN|extern)\s+(?:const\s+)?[\w\s\*]+?(?:const\s+)?(\w+)\s*;',
            re.MULTILINE),
        'extern_const_array': re.compile(
            r'(?:FOUNDATION_EXPORT|UIKIT_EXTERN|extern)\s+(?:const\s+)?[\w\s\*]+\s+(\w+)\s*\[\s*\]',
            re.MULTILINE),

        'macro_k_constant': re.compile(r'\b(k[A-Z]\w+)\b', re.MULTILINE),
    }

    @classmethod
    def parse(cls, file_path: Path) -> Set[str]:
        """í—¤ë” íŒŒì¼ì—ì„œ ëª¨ë“  ì‹ë³„ìë¥¼ ì¶”ì¶œí•˜ì—¬ Setìœ¼ë¡œ ë°˜í™˜"""
        all_identifiers = set()

        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            remover = ObjectiveCCommentRemover()
            clean_content = remover.remove_comments(content)

            # í´ë˜ìŠ¤ì™€ í”„ë¡œí† ì½œ
            all_identifiers.update(cls.PATTERNS['interface'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['protocol'].findall(clean_content))

            # êµ¬ì¡°ì²´
            all_identifiers.update(cls.PATTERNS['struct_typedef'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['struct_plain'].findall(clean_content))

            # ì—´ê±°í˜•
            all_identifiers.update(cls.PATTERNS['enum_ns'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['enum_typedef'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['enum_forward_decl'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['swift_enum'].findall(clean_content))

            # Typedef
            all_identifiers.update(cls.PATTERNS['typedef'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['typedef_funcptr'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['typedef_block'].findall(clean_content))

            # í•¨ìˆ˜
            all_identifiers.update(cls.PATTERNS['function'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['export_function'].findall(clean_content))

            # ìƒìˆ˜
            all_identifiers.update(cls.PATTERNS['extern_const'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['extern_const_array'].findall(clean_content))
            all_identifiers.update(cls.PATTERNS['macro_k_constant'].findall(clean_content))

            # ë§¤í¬ë¡œ
            all_identifiers.update(cls._extract_macros(content))

            # ë³µì¡í•œ íŒ¨í„´ë“¤
            all_identifiers.update(cls._extract_enum_cases(clean_content))
            all_identifiers.update(cls._extract_methods(clean_content))
            all_identifiers.update(cls._extract_properties(clean_content))

            # ì¹´í…Œê³ ë¦¬ ì œì™¸
            categories = cls._extract_categories(clean_content)
            all_identifiers -= categories

            # í•„í„°ë§
            all_identifiers = cls._filter_identifiers(all_identifiers)

        except (OSError, re.error) as e:
            _trace("header_extractor.parse failed for %s: %s", file_path, e)
            _maybe_raise(e)

        return all_identifiers

    @classmethod
    def _extract_macros(cls, content: str) -> Set[str]:
        """#define ë§¤í¬ë¡œ ì¶”ì¶œ"""
        macros = set()

        for line in content.split('\n'):
            line = line.strip()

            if line.startswith('//') or line.startswith('/*'):
                continue

            if line.startswith('#ifndef') or line.startswith('#define'):
                match = re.match(r'^#(?:ifndef|define)\s+([A-Za-z_]\w*)(?:\s|$|\()', line)
                if match:
                    macro_name = match.group(1)
                    if len(macro_name) > 1:
                        macros.add(macro_name)

        return macros

    @classmethod
    def _extract_categories(cls, content: str) -> Set[str]:
        """ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¶”ì¶œ (ì œì™¸ìš©)"""
        pattern = re.compile(r'@interface\s+\w+\s*\((\w+)\)', re.MULTILINE)
        return set(pattern.findall(content))

    @classmethod
    def _extract_enum_cases(cls, content: str) -> Set[str]:
        """enum case ê°’ë“¤ ì¶”ì¶œ"""
        cases = set()

        enum_blocks = re.findall(
            r'(?:typedef\s+)?enum\s+\w*\s*(?::\s*\w+)?\s*\{([^}]+)\}',
            content,
            re.MULTILINE | re.DOTALL
        )

        ns_enum_blocks = re.findall(
            r'(?:NS_ENUM|NS_OPTIONS|NS_CLOSED_ENUM|NS_ERROR_ENUM)\s*\([^)]+\)\s*\{([^}]+)\}',
            content,
            re.MULTILINE | re.DOTALL
        )

        swift_enum_blocks = re.findall(
            r'typedef\s+SWIFT_ENUM[^{]*\{([^}]+)\}',
            content,
            re.MULTILINE | re.DOTALL
        )

        all_blocks = enum_blocks + ns_enum_blocks + swift_enum_blocks

        for block in all_blocks:
            for line in block.split('\n'):
                line = line.strip()
                if not line or line.startswith('//') or line.startswith('/*'):
                    continue

                match = re.match(r'([A-Za-z_]\w*)\s*(?:=|,|$)', line)
                if match:
                    case_name = match.group(1)
                    if len(case_name) > 1:
                        cases.add(case_name)

        return cases

    @classmethod
    def _extract_methods(cls, content: str) -> Set[str]:
        """ë©”ì„œë“œ ì´ë¦„ ì¶”ì¶œ"""
        methods = set()

        method_pattern = re.compile(
            r'^[\-+]\s*\([^)]+\)\s*([a-zA-Z_]\w*)(?:\s|:|;)',
            re.MULTILINE
        )

        for match in method_pattern.finditer(content):
            method_name = match.group(1)
            if method_name and len(method_name) > 1:
                methods.add(method_name)

        method_with_params = re.compile(
            r'^[\-+]\s*\([^)]+\)\s*([a-zA-Z_]\w*):',
            re.MULTILINE
        )

        for match in method_with_params.finditer(content):
            method_name = match.group(1)
            if method_name and len(method_name) > 1:
                methods.add(method_name)

        return methods

    @classmethod
    def _extract_properties(cls, content: str) -> Set[str]:
        """í”„ë¡œí¼í‹° ì´ë¦„ ì¶”ì¶œ"""
        properties = set()

        property_pattern = re.compile(
            r'@property\s*\([^)]*\)\s*[\w\s\*<>]+\s+([a-zA-Z_]\w*)\s*;',
            re.MULTILINE
        )

        for match in property_pattern.finditer(content):
            prop_name = match.group(1)
            if prop_name and len(prop_name) > 1:
                properties.add(prop_name)

        return properties

    @classmethod
    def _filter_identifiers(cls, identifiers: Set[str]) -> Set[str]:
        """ìœ íš¨í•˜ì§€ ì•Šì€ ì‹ë³„ì í•„í„°ë§"""
        filtered = set()

        reserved_keywords = {
            'id', 'in', 'out', 'inout', 'bycopy', 'byref', 'oneway',
            'self', 'super', 'nil', 'Nil', 'YES', 'NO',
            'Class', 'SEL', 'IMP', 'BOOL',
            'void', 'int', 'float', 'double', 'char', 'short', 'long',
            'unsigned', 'signed', 'const', 'static', 'extern', 'inline',
            'typedef', 'struct', 'union', 'enum',
            'if', 'else', 'switch', 'case', 'default',
            'for', 'while', 'do', 'break', 'continue', 'return',
        }

        for identifier in identifiers:
            if not identifier or len(identifier) <= 1:
                continue

            if identifier in reserved_keywords:
                continue

            if not re.match(r'^[A-Za-z_][A-Za-z0-9_]*$', identifier):
                continue

            if identifier.startswith('__'):
                continue

            filtered.add(identifier)

        return filtered


# ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ í•¨ìˆ˜
def process_header_file(args: Tuple[Path, Path]) -> Tuple[str, Set[str], bool]:
    """
    ë‹¨ì¼ í—¤ë” íŒŒì¼ ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš©)

    Returns:
        (relative_path, identifiers, success)
    """
    header_file, project_path = args

    try:
        identifiers = ObjCHeaderParser.parse(header_file)

        # ìƒëŒ€ ê²½ë¡œ ìƒì„±
        try:
            relative_path = str(header_file.relative_to(project_path))
        except ValueError:
            relative_path = f"[DerivedData] {header_file.name}"

        return (relative_path, identifiers, True)

    except (OSError, re.error) as e:
        _trace("process_header_file failed for %s: %s", header_file, e)
        _maybe_raise(e)
        return (header_file.name, set(), False)


class HeaderScanner:
    """í—¤ë” íŒŒì¼ ìŠ¤ìºë„ˆ (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)"""

    def __init__(self, project_path: Path, target_name: str = None, num_workers: int = None):
        """
        Args:
            project_path: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
            target_name: ì‹¤ì œ í”„ë¡œì íŠ¸/íƒ€ê²Ÿ ì´ë¦„ (DerivedData ê²€ìƒ‰ìš©)
            num_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜ ì‚¬ìš©)
        """
        self.project_path = project_path.resolve()
        self.target_name = target_name
        self.num_workers = num_workers or cpu_count()
        self.all_identifiers: Set[str] = set()
        self.stats = {
            'project_headers': 0,
            'derived_data_headers': 0,
            'total_headers': 0,
            'success': 0,
            'failed': 0,
            'processing_time': 0.0
        }
        self.exclude_dirs = {'.git', '.build', 'build', 'Pods', 'Carthage',
                             'DerivedData', 'node_modules', '.svn', '.hg'}

    def find_project_headers(self) -> List[Path]:
        """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  .h íŒŒì¼ ì°¾ê¸°"""

        headers = []

        for header_file in self.project_path.rglob("*.h"):
            # ì œì™¸ ë””ë ‰í† ë¦¬ ì²´í¬
            if any(excluded in header_file.parts for excluded in self.exclude_dirs):
                continue

            headers.append(header_file)

        return headers

    def find_derived_data_headers(self) -> List[Path]:
        """DerivedDataì—ì„œ í—¤ë” íŒŒì¼ ì°¾ê¸° (ê°€ì¥ ìµœì‹  ê²ƒë§Œ)"""
        if not self.target_name:
            print("   âš ï¸  íƒ€ê²Ÿ ì´ë¦„ì´ ì§€ì •ë˜ì§€ ì•Šì•„ DerivedData ìŠ¤ìº”ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []

        derived_data_base = Path.home() / "Library" / "Developer" / "Xcode" / "DerivedData"

        if not derived_data_base.exists():
            print(f"   âš ï¸  DerivedData ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {derived_data_base}")
            return []


        # íƒ€ê²Ÿ ì´ë¦„ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
        matching_dirs = []
        for item in derived_data_base.iterdir():
            if item.is_dir() and item.name.startswith(f"{self.target_name}-"):
                matching_dirs.append(item)

        if not matching_dirs:
            print(f"   âš ï¸  '{self.target_name}'ì— í•´ë‹¹í•˜ëŠ” DerivedData ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ğŸ’¡ ~/Library/Developer/Xcode/DerivedData/{self.target_name}-* í˜•ì‹ì„ ì°¾ìŠµë‹ˆë‹¤.")
            return []

        # ì—¬ëŸ¬ ê°œ ë°œê²¬ ì‹œ ê°€ì¥ ìµœì‹  ê²ƒë§Œ ì‚¬ìš©
        if len(matching_dirs) > 0:
            # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  ê²ƒ ì„ íƒ
            matching_dirs.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            selected_dir = matching_dirs[0]
            matching_dirs = [selected_dir]
        else:
            print(f"'{self.target_name}'ì— í•´ë‹¹í•˜ëŠ” DerivedData ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        headers = []
        for derived_dir in matching_dirs:

            # DerivedData ë‚´ì˜ ëª¨ë“  .h íŒŒì¼ ì°¾ê¸°
            for header_file in derived_dir.rglob("*.h"):
                headers.append(header_file)
        return headers

    def scan_all(self) -> Set[str]:
        """ëª¨ë“  í—¤ë” íŒŒì¼ ìŠ¤ìº” (ë³‘ë ¬ ì²˜ë¦¬)"""

        # 1. í”„ë¡œì íŠ¸ ë‚´ë¶€ í—¤ë”
        project_headers = self.find_project_headers()
        self.stats['project_headers'] = len(project_headers)

        # 2. DerivedData í—¤ë”
        derived_headers = self.find_derived_data_headers()
        self.stats['derived_data_headers'] = len(derived_headers)

        # ì „ì²´ í—¤ë” ëª©ë¡
        all_headers = project_headers + derived_headers
        self.stats['total_headers'] = len(all_headers)

        if not all_headers:
            print("âŒ í—¤ë” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return set()

        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ë³‘ë ¬ ì²˜ë¦¬
        args_list = [(header, self.project_path) for header in all_headers]

        with Pool(processes=self.num_workers) as pool:
            results = pool.map(process_header_file, args_list)

        # ê²°ê³¼ ìˆ˜ì§‘
        for relative_path, identifiers, success in results:
            if success and identifiers:
                self.all_identifiers.update(identifiers)
                self.stats['success'] += 1
                if VERBOSE_PER_FILE:
                    print(f"âœ“ {relative_path}: {len(identifiers)}ê°œ")
            else:
                self.stats['failed'] += 1
                if not success and VERBOSE_PER_FILE:
                    print(f"âœ— {relative_path}: ì˜¤ë¥˜")

        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        end_time = time.time()
        self.stats['processing_time'] = end_time - start_time

        return self.all_identifiers

    def print_summary(self):
        """ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ (ë‚œë…í™” ì œì™¸ ëŒ€ìƒ)")
        print("=" * 60)
        print(f"í”„ë¡œì íŠ¸ í—¤ë”:       {self.stats['project_headers']:>6}ê°œ")
        print(f"DerivedData í—¤ë”:    {self.stats['derived_data_headers']:>6}ê°œ")
        print(f"ì´ í—¤ë” íŒŒì¼:        {self.stats['total_headers']:>6}ê°œ")
        print(f"ì„±ê³µ:               {self.stats['success']:>6}ê°œ")
        print(f"ì‹¤íŒ¨:               {self.stats['failed']:>6}ê°œ")
        print(f"ì²˜ë¦¬ ì‹œê°„:          {self.stats['processing_time']:>6.2f}ì´ˆ")
        print(f"ì›Œì»¤ ìˆ˜:            {self.num_workers:>6}ê°œ")
        print(f"\nê³ ìœ  ì‹ë³„ì ì´í•©:    {len(self.all_identifiers):>6}ê°œ")
        print("=" * 60)

    def save_to_txt(self, output_path: Path):
        """ì‹ë³„ìë¥¼ .txt íŒŒì¼ë¡œ ì €ì¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©)"""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for identifier in sorted(self.all_identifiers):
                f.write(identifier + '\n')

        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   ì´ {len(self.all_identifiers)}ê°œì˜ ì‹ë³„ìê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    parser = argparse.ArgumentParser(
        description="Swift ë‚œë…í™”ë¥¼ ìœ„í•œ í—¤ë” ì‹ë³„ì ì¶”ì¶œê¸° (ë³‘ë ¬ ì²˜ë¦¬)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python header_extractor.py -i /path/to/project -o identifiers.txt -t MyApp
  python header_extractor.py -i ~/Projects/MyProject -o ./output/exclude.txt -t MyProject
  python header_extractor.py -i ~/Projects/MyProject -o ./id.txt -t MyProject --workers 8
        """
    )

    parser.add_argument('-i', '--input', type=Path, required=True,
                        help='í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ')
    parser.add_argument('-o', '--output', type=Path, required=True,
                        help='ì¶œë ¥ .txt íŒŒì¼ ê²½ë¡œ (ì‹ë³„ìê°€ í•œ ì¤„ì— í•˜ë‚˜ì”© ì €ì¥ë¨)')
    parser.add_argument('-t', '--target', type=str,
                        help='íƒ€ê²Ÿ í”„ë¡œì íŠ¸ ì´ë¦„ (DerivedData ê²€ìƒ‰ìš©, ì˜ˆ: MyApp)')
    parser.add_argument('-w', '--workers', type=int, default=None,
                        help=f'ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜ = {cpu_count()})')

    args = parser.parse_args()

    # ì…ë ¥ ê²½ë¡œ ê²€ì¦
    if not args.input.exists():
        print(f"âŒ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        return 1

    if not args.input.is_dir():
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {args.input}")
        return 1

    # ìŠ¤ìºë„ˆ ì‹¤í–‰
    scanner = HeaderScanner(args.input, args.target, args.workers)
    identifiers = scanner.scan_all()
    scanner.print_summary()

    # ê²°ê³¼ ì €ì¥
    if identifiers:
        scanner.save_to_txt(args.output)
        print("\nâœ… ì™„ë£Œ!")
        print("ğŸ’¡ ì´ ì‹ë³„ìë“¤ì€ ê³µê°œ APIì´ë¯€ë¡œ ë‚œë…í™”ì—ì„œ ì œì™¸í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸  ì¶”ì¶œëœ ì‹ë³„ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
Metadata-Version: 2.4
Name: parrots
Version: 1.2.5
Summary: Parrots, Automatic Speech Recognition(**ASR**), Text-To-Speech(**TTS**) toolkit
Home-page: https://github.com/shibing624/parrots
Author: XuMing
Author-email: xuming624@qq.com
License: Apache 2.0
Keywords: TTS,ASR,text to speech,speech
Platform: Windows
Platform: Linux
Platform: Solaris
Platform: Mac OS-X
Platform: Unix
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Natural Language :: Chinese (Simplified)
Classifier: Natural Language :: Chinese (Traditional)
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pypinyin
Requires-Dist: jieba
Requires-Dist: loguru
Requires-Dist: transformers
Requires-Dist: huggingface_hub
Requires-Dist: librosa
Requires-Dist: nltk
Requires-Dist: g2p_en
Requires-Dist: cn2an
Requires-Dist: zh-normalization
Requires-Dist: einops
Requires-Dist: soundfile
Requires-Dist: fire
Requires-Dist: tqdm
Requires-Dist: descript-audiotools
Requires-Dist: torchaudio
Requires-Dist: munch
Requires-Dist: wetext
Requires-Dist: pandas
Requires-Dist: sentencepiece
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: platform
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/parrots/blob/master/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/parrots/blob/master/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/parrots/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624) 

<div align="center">
    <a href="https://github.com/shibing624/parrots">
    <img src="https://github.com/shibing624/parrots/blob/master/docs/parrots_icon.png" alt="Logo" height="156">
    </a>
    <br/>
    <br/>
    <a href="https://huggingface.co/spaces/shibing624/parrots" target="_blank"> Online Demo </a>
    <br/>
    <img width="100%" src="https://github.com/shibing624/parrots/blob/master/docs/hf.jpg">
</div>


-----------------

# Parrots: ASR and TTS toolkit
[![PyPI version](https://badge.fury.io/py/parrots.svg)](https://badge.fury.io/py/parrots)
[![Downloads](https://static.pepy.tech/badge/parrots)](https://pepy.tech/project/parrots)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/parrots.svg)](https://github.com/shibing624/parrots/graphs/contributors)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_vesion](https://img.shields.io/badge/Python-3.7%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/parrots.svg)](https://github.com/shibing624/parrots/issues)
[![Wechat Group](https://img.shields.io/badge/wechat-group-green.svg?logo=wechat)](#Contact)

## Introduction
Parrots, Automatic Speech Recognition(**ASR**), Text-To-Speech(**TTS**) toolkit, support Chinese, English, Japanese, etc.

**parrots**å®ç°äº†è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆæ¨¡å‹ä¸€é”®è°ƒç”¨ï¼Œå¼€ç®±å³ç”¨ï¼Œæ”¯æŒä¸­è‹±æ–‡ã€‚

## Features
1. **ASR**ï¼šåŸºäº`distilwhisper`å®ç°çš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­ã€è‹±ç­‰å¤šç§è¯­è¨€
2. **TTS**ï¼šåŸºäº`GPT-SoVITS`è®­ç»ƒçš„è¯­éŸ³åˆæˆï¼ˆTTSï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­ã€è‹±ã€æ—¥ç­‰å¤šç§è¯­è¨€
3. **IndexTTS2**ï¼šé›†æˆäº† IndexTTS2 æ¨¡å‹ï¼Œæ”¯æŒæƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶çš„é›¶æ ·æœ¬è¯­éŸ³åˆæˆ
   - ç²¾ç¡®çš„è¯­éŸ³æ—¶é•¿æ§åˆ¶
   - æƒ…æ„Ÿä¸è¯´è¯äººèº«ä»½è§£è€¦ï¼Œç‹¬ç«‹æ§åˆ¶éŸ³è‰²å’Œæƒ…æ„Ÿ
   - æ”¯æŒå¤šç§æƒ…æ„Ÿæ§åˆ¶æ–¹å¼ï¼šéŸ³é¢‘å‚è€ƒã€æƒ…æ„Ÿå‘é‡ã€æ–‡æœ¬æè¿°
   - é«˜åº¦è¡¨ç°åŠ›çš„æƒ…æ„Ÿè¯­éŸ³åˆæˆ
4. **æµå¼TTS**ï¼šæ”¯æŒæµå¼è¯­éŸ³åˆæˆï¼Œå®ç°ä½å»¶è¿Ÿçš„å®æ—¶è¯­éŸ³è¾“å‡º




## Install
```shell
pip install torch # or conda install pytorch
pip install -r requirements.txt
pip install parrots
```
or
```shell
pip install torch # or conda install pytorch
git clone https://github.com/shibing624/parrots.git
cd parrots
python setup.py install
```

## Demo
- Offical Demo: https://www.mulanai.com/product/tts/
- HuggingFace Demo: https://huggingface.co/spaces/shibing624/parrots

<img width="85%" src="https://github.com/shibing624/parrots/blob/master/docs/hf.png">

run example: [examples/tts_gradio_demo.py](https://github.com/shibing624/parrots/blob/master/examples/tts_gradio_demo.py) to see the demo:
```shell
python examples/tts_gradio_demo.py
```

## Usage
### ASR(Speech Recognition)
example: [examples/demo_asr.py](https://github.com/shibing624/parrots/blob/master/examples/demo_asr.py)
```python
import os
import sys

sys.path.append('..')
from parrots import SpeechRecognition

pwd_path = os.path.abspath(os.path.dirname(__file__))

if __name__ == '__main__':
    m = SpeechRecognition()
    r = m.recognize_speech_from_file(os.path.join(pwd_path, 'tushuguan.wav'))
    print('[æç¤º] è¯­éŸ³è¯†åˆ«ç»“æœï¼š', r)

```

output:
```
{'text': 'åŒ—äº¬å›¾ä¹¦é¦†'}
```

### TTS(Speech Synthesis)

#### GPT-SoVITS åŸºç¡€ç”¨æ³•
example: [examples/demo_tts.py](https://github.com/shibing624/parrots/blob/master/examples/demo_tts.py)
```python
from parrots import TextToSpeech

# åˆå§‹åŒ– TTS æ¨¡å‹ï¼ˆæ— éœ€æ‰‹åŠ¨é…ç½®è·¯å¾„ï¼‰
m = TextToSpeech(
    speaker_model_path="shibing624/parrots-gpt-sovits-speaker-maimai",
    speaker_name="MaiMai",
    device="cpu",  # æˆ– "cuda" ä½¿ç”¨ GPU
    half=False     # è®¾ç½®ä¸º True ä½¿ç”¨åŠç²¾åº¦åŠ é€Ÿ
)

# ç”Ÿæˆè¯­éŸ³
m.predict(
    text="ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°åŒ—äº¬ã€‚è¿™æ˜¯ä¸€ä¸ªåˆæˆå½•éŸ³æ–‡ä»¶çš„æ¼”ç¤ºã€‚Welcome to Beijing!",
    text_language="auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼Œä¹Ÿå¯æŒ‡å®š "zh", "en", "ja"
    output_path="output_audio.wav"
)
```

output:
```
Save audio to output_audio.wav
```

#### æµå¼ TTSï¼ˆä½å»¶è¿Ÿï¼‰

æ”¯æŒæµå¼è¯­éŸ³åˆæˆï¼Œé€‚ç”¨äºå®æ—¶å¯¹è¯åœºæ™¯ï¼š

```python
from parrots import TextToSpeech
import soundfile as sf
import numpy as np

m = TextToSpeech(
    speaker_model_path="shibing624/parrots-gpt-sovits-speaker-maimai",
    speaker_name="MaiMai",
)

# æµå¼ç”Ÿæˆè¯­éŸ³
audio_chunks = []
for audio_chunk in m.predict_stream(
    text="è¿™æ˜¯ä¸€æ®µè¾ƒé•¿çš„æ–‡æœ¬ï¼Œå°†ä¼šè¢«æµå¼åˆæˆä¸ºè¯­éŸ³ã€‚",
    text_language="zh",
    stream_chunk_size=20  # æ§åˆ¶å»¶è¿Ÿï¼Œè¶Šå°å»¶è¿Ÿè¶Šä½
):
    audio_chunks.append(audio_chunk)
    # è¿™é‡Œå¯ä»¥å®æ—¶æ’­æ”¾ audio_chunk

# ä¿å­˜å®Œæ•´éŸ³é¢‘
full_audio = np.concatenate(audio_chunks)
sf.write("streaming_output.wav", full_audio, m.sampling_rate)
```

#### æ—¥å¿—ç®¡ç†

æ§åˆ¶æ—¥å¿—è¾“å‡ºçº§åˆ«ï¼š

```python
from parrots import TextToSpeech
from parrots.log import set_log_level, logger

# è®¾ç½®æ—¥å¿—çº§åˆ«
set_log_level("INFO")  # å¯é€‰: DEBUG, INFO, WARNING, ERROR

m = TextToSpeech(
    speaker_model_path="shibing624/parrots-gpt-sovits-speaker-maimai",
    speaker_name="MaiMai",
)

# ä½¿ç”¨ logger
logger.info("å¼€å§‹è¯­éŸ³åˆæˆ...")
m.predict(
    text="ä½ å¥½ï¼Œä¸–ç•Œï¼",
    text_language="zh",
    output_path="output.wav"
)
```

#### IndexTTS2 é«˜çº§ç”¨æ³•

IndexTTS2 æ˜¯ä¸€ä¸ªçªç ´æ€§çš„æƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶çš„è‡ªå›å½’é›¶æ ·æœ¬è¯­éŸ³åˆæˆæ¨¡å‹ã€‚

example: [examples/demo_indextts.py](https://github.com/shibing624/parrots/blob/master/examples/demo_indextts.py)

**1. åŸºç¡€è¯­éŸ³å…‹éš†ï¼ˆä½¿ç”¨å•ä¸ªå‚è€ƒéŸ³é¢‘ï¼‰**

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "ä½ å¥½ï¼Œæ¬¢è¿æ¥åˆ°åŒ—äº¬ã€‚è¿™æ˜¯ä¸€ä¸ªåˆæˆå½•éŸ³æ–‡ä»¶çš„æ¼”ç¤ºã€‚"
tts.infer(text=text, output_path="gen.wav", verbose=True)
```

**2. æƒ…æ„Ÿè¯­éŸ³åˆæˆï¼ˆä½¿ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘ï¼‰**

ä½¿ç”¨å•ç‹¬çš„æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘æ¥æ§åˆ¶è¯­éŸ³åˆæˆçš„æƒ…æ„Ÿè¡¨è¾¾ï¼š

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "é…’æ¥¼ä¸§å°½å¤©è‰¯ï¼Œå¼€å§‹å€Ÿæœºç«æ‹æˆ¿é—´ï¼Œå“ï¼Œä¸€ç¾¤è ¢è´§ã€‚"
tts.infer(
   speak_reference_audio_path='examples/voice_07.wav',  # è¯´è¯äººéŸ³è‰²å‚è€ƒ
   text=text,
   output_path="gen.wav",
   emo_reference_audio_path="examples/emo_sad.wav",  # æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘
   verbose=True
)
```

**3. è°ƒæ•´æƒ…æ„Ÿå¼ºåº¦**

é€šè¿‡ `emo_alpha` å‚æ•°ï¼ˆèŒƒå›´ 0.0-1.0ï¼‰è°ƒæ•´æƒ…æ„Ÿå½±å“ç¨‹åº¦ï¼š

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "é…’æ¥¼ä¸§å°½å¤©è‰¯ï¼Œå¼€å§‹å€Ÿæœºç«æ‹æˆ¿é—´ï¼Œå“ï¼Œä¸€ç¾¤è ¢è´§ã€‚"
tts.infer(
   speak_reference_audio_path='examples/voice_07.wav',
   text=text,
   output_path="gen.wav",
   emo_reference_audio_path="examples/emo_sad.wav",
   emo_alpha=0.6,  # æƒ…æ„Ÿå¼ºåº¦ 60%
   verbose=True
)
```

**4. ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶**

ç›´æ¥æä¾› 8 ç»´æƒ…æ„Ÿå‘é‡æ¥ç²¾ç¡®æ§åˆ¶æƒ…æ„Ÿï¼Œé¡ºåºä¸ºï¼š
`[å¼€å¿ƒ, ç”Ÿæ°”, æ‚²ä¼¤, å®³æ€•, åŒæ¶, å¿§éƒ, æƒŠè®¶, å¹³é™]`

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "å“‡å¡ï¼è¿™ä¸ªçˆ†ç‡ä¹Ÿå¤ªé«˜äº†ï¼æ¬§çš‡é™„ä½“äº†ï¼"
tts.infer(
   speak_reference_audio_path='examples/voice_10.wav',
   text=text,
   output_path="gen.wav",
   emo_vector=[0, 0, 0, 0, 0, 0, 0.45, 0],  # æƒŠè®¶æƒ…æ„Ÿ
   use_random=False,
   verbose=True
)
```

**5. åŸºäºæ–‡æœ¬çš„æƒ…æ„Ÿæ§åˆ¶**

å¯ç”¨ `use_emo_text` å¯ä»¥æ ¹æ®æ–‡æœ¬å†…å®¹è‡ªåŠ¨æ¨æ–­æƒ…æ„Ÿï¼š

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "å¿«èº²èµ·æ¥ï¼æ˜¯ä»–è¦æ¥äº†ï¼ä»–è¦æ¥æŠ“æˆ‘ä»¬äº†ï¼"
tts.infer(
   speak_reference_audio_path='examples/voice_12.wav',
   text=text,
   output_path="gen.wav",
   emo_alpha=0.6,
   use_emo_text=True,  # å¯ç”¨æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
   use_random=False,
   verbose=True
)
```

**6. ç‹¬ç«‹çš„æƒ…æ„Ÿæ–‡æœ¬æè¿°**

é€šè¿‡ `emo_text` å‚æ•°å•ç‹¬æŒ‡å®šæƒ…æ„Ÿæè¿°æ–‡æœ¬ï¼š

```python
from parrots.indextts import IndexTTS2

tts = IndexTTS2()
text = "å¿«èº²èµ·æ¥ï¼æ˜¯ä»–è¦æ¥äº†ï¼ä»–è¦æ¥æŠ“æˆ‘ä»¬äº†ï¼"
emo_text = "ä½ å“æ­»æˆ‘äº†ï¼ä½ æ˜¯é¬¼å—ï¼Ÿ"  # ç‹¬ç«‹çš„æƒ…æ„Ÿæè¿°
tts.infer(
   speak_reference_audio_path='examples/voice_12.wav',
   text=text,
   output_path="gen.wav",
   emo_alpha=0.6,
   use_emo_text=True,
   emo_text=emo_text,
   use_random=False,
   verbose=True
)
```

**æ‹¼éŸ³æ§åˆ¶è¯´æ˜ï¼š**

IndexTTS2 æ”¯æŒä¸­æ–‡å­—ç¬¦å’Œæ‹¼éŸ³çš„æ··åˆå»ºæ¨¡ã€‚å½“éœ€è¦ç²¾ç¡®çš„å‘éŸ³æ§åˆ¶æ—¶ï¼Œè¯·æä¾›å¸¦æœ‰ç‰¹å®šæ‹¼éŸ³æ ‡æ³¨çš„æ–‡æœ¬ã€‚
æ³¨æ„ï¼šæ‹¼éŸ³æ§åˆ¶ä¸æ”¯æŒæ‰€æœ‰å¯èƒ½çš„å£°æ¯-éŸµæ¯ç»„åˆï¼Œä»…æ”¯æŒæœ‰æ•ˆçš„ä¸­æ–‡æ‹¼éŸ³ã€‚

ç¤ºä¾‹ï¼š
```python
text = "ä¹‹å‰ä½ åšDE5å¾ˆå¥½ï¼Œæ‰€ä»¥è¿™ä¸€æ¬¡ä¹ŸDEI3åšDE2å¾ˆå¥½æ‰XING2ï¼Œå¦‚æœè¿™æ¬¡ç›®æ ‡å®Œæˆå¾—ä¸é”™çš„è¯ï¼Œæˆ‘ä»¬å°±ç›´æ¥æ‰“DI1å»é“¶è¡Œå–é’±ã€‚"
```

### å‘½ä»¤è¡Œæ¨¡å¼ï¼ˆCLIï¼‰

æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œæ–¹å¼æ‰§è¡ŒARSå’ŒTTSä»»åŠ¡ï¼Œä»£ç ï¼š[cli.py](https://github.com/shibing624/parrots/blob/master/parrots/cli.py)

```
> parrots -h                                    

NAME
    parrots

SYNOPSIS
    parrots COMMAND

COMMANDS
    COMMAND is one of the following:

     asr
       Entry point of asr, recognize speech from file

     tts
       Entry point of tts, generate speech audio from text

```

runï¼š

```shell
pip install parrots -U
# asr example
parrots asr -h
parrots asr examples/tushuguan.wav

# tts example
parrots tts -h
parrots tts "ä½ å¥½ï¼Œæ¬¢è¿æ¥åŒ—äº¬ã€‚welcome to the city." output_audio.wav
```

- `asr`ã€`tts`æ˜¯äºŒçº§å‘½ä»¤ï¼Œasræ˜¯è¯­éŸ³è¯†åˆ«ï¼Œttsæ˜¯è¯­éŸ³åˆæˆï¼Œé»˜è®¤ä½¿ç”¨çš„æ¨¡å‹æ˜¯ä¸­æ–‡æ¨¡å‹
- å„äºŒçº§å‘½ä»¤ä½¿ç”¨æ–¹æ³•è§`parrots asr -h`
- ä¸Šé¢ç¤ºä¾‹ä¸­`examples/tushuguan.wav`æ˜¯`asr`æ–¹æ³•çš„`audio_file_path`å‚æ•°ï¼Œè¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆrequiredï¼‰

## Release Models

### ASR
- [BELLE-2/Belle-distilwhisper-large-v2-zh](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh)

### IndexTTS2
- [IndexTeam/IndexTTS-2](https://huggingface.co/IndexTeam/IndexTTS-2) - æœ€æ–°çš„æƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶æ¨¡å‹
- [IndexTeam/IndexTTS-1.5](https://huggingface.co/IndexTeam/IndexTTS-1.5) - æ”¹è¿›çš„ç¨³å®šæ€§å’Œè‹±è¯­æ€§èƒ½
- [IndexTeam/Index-TTS](https://huggingface.co/IndexTeam/Index-TTS) - åˆå§‹ç‰ˆæœ¬

ç›¸å…³è®ºæ–‡ï¼š
- [IndexTTS2 Paper](https://arxiv.org/abs/2506.21619) - æƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶çš„çªç ´
- [IndexTTS Paper](https://arxiv.org/abs/2502.05512) - å·¥ä¸šçº§å¯æ§é›¶æ ·æœ¬ TTS

### GPT-SoVITS TTS

- [shibing624/parrots-gpt-sovits-speaker](https://huggingface.co/shibing624/parrots-gpt-sovits-speaker)

| speaker name | è¯´è¯äººå | character | è§’è‰²ç‰¹ç‚¹ | language | è¯­è¨€ |
|--|--|--|--|--|--|
| KuileBlanc | è‘µÂ·å‹’å¸ƒæœ— | lady | æ ‡å‡†ç¾å¼å¥³å£° | en | è‹± |
| LongShouRen | é¾™å®ˆä» | gentleman | æ ‡å‡†ç¾å¼ç”·å£° | en | è‹± |
| MaiMai | å–å–| singing female anchor | å”±æ­Œå¥³ä¸»æ’­å£° | zh | ä¸­ |
| XingTong | æ˜Ÿç³ | singing ai girl | æ´»æ³¼å¥³å£° | zh | ä¸­ |
| XuanShen | ç‚«ç¥ | game male anchor | æ¸¸æˆç”·ä¸»æ’­å£° | zh | ä¸­ |
| KusanagiNene | è‰è–™å¯§ã€… | loli | èè‰å¥³å­¦ç”Ÿå£° | ja | æ—¥ |

- [shibing624/parrots-gpt-sovits-speaker-maimai](https://huggingface.co/shibing624/parrots-gpt-sovits-speaker-maimai)

| speaker name | è¯´è¯äººå | character | è§’è‰²ç‰¹ç‚¹ | language | è¯­è¨€ |
|--|--|--|--|--|--|
| MaiMai | å–å–| singing female anchor | å”±æ­Œå¥³ä¸»æ’­å£° | zh | ä¸­ |

## æ›´æ–°æ—¥å¿—

### v0.3.0 (2025-11)
- ğŸ”¥ é›†æˆ IndexTTS2 æ¨¡å‹ï¼Œæ”¯æŒæƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶çš„é›¶æ ·æœ¬è¯­éŸ³åˆæˆ
- âœ¨ æ”¯æŒå¤šç§æƒ…æ„Ÿæ§åˆ¶æ–¹å¼ï¼šéŸ³é¢‘å‚è€ƒã€æƒ…æ„Ÿå‘é‡ã€æ–‡æœ¬æè¿°
- âœ¨ å®ç°æƒ…æ„Ÿä¸è¯´è¯äººèº«ä»½è§£è€¦ï¼Œç‹¬ç«‹æ§åˆ¶éŸ³è‰²å’Œæƒ…æ„Ÿ
- âœ¨ æ”¯æŒæ‹¼éŸ³æ··åˆå»ºæ¨¡ï¼Œå®ç°ç²¾ç¡®å‘éŸ³æ§åˆ¶
- ğŸ› ä¿®å¤ transformers 4.50+ å…¼å®¹æ€§é—®é¢˜
- ğŸ› ä¿®å¤å­—å…¸å‚æ•°è®¿é—®é”™è¯¯
- ğŸ“ æ–°å¢ IndexTTS2 ä½¿ç”¨ç¤ºä¾‹å’Œæ–‡æ¡£

### v0.2.0 (2025-10)
- âœ¨ æ–°å¢æµå¼ TTS åŠŸèƒ½ï¼Œæ”¯æŒä½å»¶è¿Ÿå®æ—¶è¯­éŸ³åˆæˆ
- âœ¨ æ–°å¢ç»Ÿä¸€çš„æ—¥å¿—ç®¡ç†ç³»ç»Ÿï¼ˆåŸºäº loguruï¼‰
- ğŸ› ä¿®å¤ PyTorch 2.0+ çš„ `weight_norm` å¼ƒç”¨è­¦å‘Š
- ğŸ› ä¿®å¤ `torch.stft` çš„ `return_complex=False` å¼ƒç”¨è­¦å‘Š
- ğŸ› ä¿®å¤ librosa çš„ `resample` å’Œ `time_stretch` è­¦å‘Š
- ğŸ”§ ä¼˜åŒ–æ¨¡å‹åŠ è½½æœºåˆ¶ï¼Œæ— éœ€æ‰‹åŠ¨æ·»åŠ  `sys.path`
- ğŸ“ å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

### v0.1.0 (2024-12)
- ğŸ‰ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ¨ æ”¯æŒ ASRï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰
- âœ¨ æ”¯æŒ TTSï¼ˆè¯­éŸ³åˆæˆï¼‰
- âœ¨ æ”¯æŒä¸­ã€è‹±ã€æ—¥å¤šè¯­è¨€

## Contact

- Issue(å»ºè®®)ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/parrots.svg)](https://github.com/shibing624/parrots/issues)
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼šåŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624*, è¿›Python-NLPäº¤æµç¾¤ï¼Œå¤‡æ³¨ï¼š*å§“å-å…¬å¸å-NLP*

<img src="https://github.com/shibing624/parrots/blob/master/docs/wechat.jpeg" width="200" />


## Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†parrotsï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```latex
@misc{parrots,
  title={parrots: ASR and TTS Tool},
  author={Ming Xu},
  year={2024},
  howpublished={\url{https://github.com/shibing624/parrots}},
}
```

## License


æˆæƒåè®®ä¸º [The Apache License 2.0](/LICENSE)ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ parrotsçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚


## Contribute
é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

 - åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
 - ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚


## Reference
#### ASR(Speech Recognition)
- [EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition](https://arxiv.org/abs/2104.07474)
- [PaddlePaddle/PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech)
- [NVIDIA/NeMo](https://github.com/NVIDIA/NeMo)
#### TTS(Speech Synthesis)
- [IndexTeam/IndexTTS](https://github.com/index-tts/index-tts) - IndexTTS2 æƒ…æ„Ÿè¡¨è¾¾å’Œæ—¶é•¿æ§åˆ¶
- [coqui-ai/TTS](https://github.com/coqui-ai/TTS)
- [keonlee9420/Expressive-FastSpeech2](https://github.com/keonlee9420/Expressive-FastSpeech2)
- [TensorSpeech/TensorflowTTS](https://github.com/TensorSpeech/TensorflowTTS)
- [RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)

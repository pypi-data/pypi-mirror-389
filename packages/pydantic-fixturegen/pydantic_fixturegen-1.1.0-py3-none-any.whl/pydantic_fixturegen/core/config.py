"""Configuration loader for pydantic-fixturegen."""

from __future__ import annotations

import datetime
import os
from collections.abc import Mapping, MutableMapping, Sequence
from dataclasses import dataclass, field, replace
from importlib import import_module
from pathlib import Path
from typing import Any, TypeVar, cast

from .field_policies import FieldPolicy
from .presets import get_preset_spec, normalize_preset_name
from .seed import DEFAULT_LOCALE


def _import_tomllib() -> Any:
    try:  # pragma: no cover - runtime path
        return import_module("tomllib")
    except ModuleNotFoundError:  # pragma: no cover
        return import_module("tomli")


tomllib = cast(Any, _import_tomllib())

try:  # pragma: no cover - optional dependency
    yaml = cast(Any, import_module("yaml"))
except ModuleNotFoundError:  # pragma: no cover
    yaml = None

_DEFAULT_PYPROJECT = Path("pyproject.toml")
_DEFAULT_YAML_NAMES = (
    Path("pydantic-fixturegen.yaml"),
    Path("pydantic-fixturegen.yml"),
)

UNION_POLICIES = {"first", "random", "weighted"}
ENUM_POLICIES = {"first", "random"}

TRUTHY = {"1", "true", "yes", "on"}
FALSY = {"0", "false", "no", "off"}


class ConfigError(ValueError):
    """Raised when configuration sources contain invalid data."""


@dataclass(frozen=True)
class PytestEmitterConfig:
    style: str = "functions"
    scope: str = "function"


@dataclass(frozen=True)
class JsonConfig:
    indent: int = 2
    orjson: bool = False


@dataclass(frozen=True)
class EmittersConfig:
    pytest: PytestEmitterConfig = field(default_factory=PytestEmitterConfig)


@dataclass(frozen=True)
class AppConfig:
    preset: str | None = None
    seed: int | str | None = None
    locale: str = DEFAULT_LOCALE
    include: tuple[str, ...] = ()
    exclude: tuple[str, ...] = ()
    p_none: float | None = None
    union_policy: str = "first"
    enum_policy: str = "first"
    now: datetime.datetime | None = None
    overrides: Mapping[str, Mapping[str, Any]] = field(default_factory=dict)
    field_policies: tuple[FieldPolicy, ...] = ()
    emitters: EmittersConfig = field(default_factory=EmittersConfig)
    json: JsonConfig = field(default_factory=JsonConfig)


DEFAULT_CONFIG = AppConfig()

T = TypeVar("T")


def load_config(
    *,
    root: Path | str | None = None,
    pyproject_path: Path | str | None = None,
    yaml_path: Path | str | None = None,
    env: Mapping[str, str] | None = None,
    cli: Mapping[str, Any] | None = None,
) -> AppConfig:
    """Load configuration applying precedence CLI > env > config > defaults."""
    root_path = Path(root) if root else Path.cwd()
    pyproject = Path(pyproject_path) if pyproject_path else root_path / _DEFAULT_PYPROJECT
    yaml_file = Path(yaml_path) if yaml_path else _find_existing_yaml(root_path)

    data: dict[str, Any] = {}
    _deep_merge(data, _config_defaults_dict())

    file_config = _load_file_config(pyproject, yaml_file)
    _merge_source_with_preset(data, file_config)

    env_config = _load_env_config(env or os.environ)
    _merge_source_with_preset(data, env_config)

    if cli:
        _merge_source_with_preset(data, cli)

    return _build_app_config(data)


def _config_defaults_dict() -> dict[str, Any]:
    return {
        "preset": DEFAULT_CONFIG.preset,
        "seed": DEFAULT_CONFIG.seed,
        "locale": DEFAULT_CONFIG.locale,
        "include": list(DEFAULT_CONFIG.include),
        "exclude": list(DEFAULT_CONFIG.exclude),
        "p_none": DEFAULT_CONFIG.p_none,
        "union_policy": DEFAULT_CONFIG.union_policy,
        "enum_policy": DEFAULT_CONFIG.enum_policy,
        "now": DEFAULT_CONFIG.now,
        "field_policies": {},
        "overrides": {},
        "emitters": {
            "pytest": {
                "style": DEFAULT_CONFIG.emitters.pytest.style,
                "scope": DEFAULT_CONFIG.emitters.pytest.scope,
            }
        },
        "json": {
            "indent": DEFAULT_CONFIG.json.indent,
            "orjson": DEFAULT_CONFIG.json.orjson,
        },
    }


def _load_file_config(pyproject_path: Path, yaml_path: Path | None) -> dict[str, Any]:
    config: dict[str, Any] = {}

    if pyproject_path.is_file():
        with pyproject_path.open("rb") as fh:
            pyproject_data = tomllib.load(fh)
        tool_config = cast(Mapping[str, Any], pyproject_data.get("tool", {}))
        project_config = cast(Mapping[str, Any], tool_config.get("pydantic_fixturegen", {}))
        config = _ensure_mutable(project_config)

    if yaml_path and yaml_path.is_file():
        if yaml is None:
            raise ConfigError("YAML configuration provided but PyYAML is not installed.")
        with yaml_path.open("r", encoding="utf-8") as fh:
            yaml_data = yaml.safe_load(fh) or {}
        if not isinstance(yaml_data, Mapping):
            raise ConfigError("YAML configuration must be a mapping at the top level.")
        yaml_dict = _ensure_mutable(yaml_data)
        _deep_merge(config, yaml_dict)

    return config


def _find_existing_yaml(root: Path) -> Path | None:
    for candidate in _DEFAULT_YAML_NAMES:
        path = root / candidate
        if path.is_file():
            return path
    return None


def _load_env_config(env: Mapping[str, str]) -> dict[str, Any]:
    config: dict[str, Any] = {}
    prefix = "PFG_"

    for key, raw_value in env.items():
        if not key.startswith(prefix):
            continue
        path_segments = key[len(prefix) :].split("__")
        if not path_segments:
            continue

        top_key = path_segments[0].lower()
        nested_segments = path_segments[1:]

        target = cast(MutableMapping[str, Any], config)
        current_key = top_key
        preserve_case = top_key == "overrides"

        for index, segment in enumerate(nested_segments):
            next_key = segment if preserve_case else segment.lower()

            if index == len(nested_segments) - 1:
                value = _coerce_env_value(raw_value)
                _set_nested_value(target, current_key, next_key, value)
            else:
                next_container = cast(MutableMapping[str, Any], target.setdefault(current_key, {}))
                target = next_container
                current_key = next_key
                preserve_case = preserve_case or current_key == "overrides"

        if not nested_segments:
            value = _coerce_env_value(raw_value)
            target[current_key] = value

    return config


def _set_nested_value(
    mapping: MutableMapping[str, Any], current_key: str, next_key: str, value: Any
) -> None:
    if current_key not in mapping or not isinstance(mapping[current_key], MutableMapping):
        mapping[current_key] = {}
    nested = cast(MutableMapping[str, Any], mapping[current_key])
    nested[next_key] = value


def _coerce_env_value(value: str) -> Any:
    stripped = value.strip()
    lower = stripped.lower()

    if lower in TRUTHY:
        return True
    if lower in FALSY:
        return False

    if "," in stripped:
        return [part.strip() for part in stripped.split(",") if part.strip()]

    try:
        return int(stripped)
    except ValueError:
        pass

    try:
        return float(stripped)
    except ValueError:
        pass

    return stripped


def _build_app_config(data: Mapping[str, Any]) -> AppConfig:
    preset_value = _coerce_preset_value(data.get("preset"))

    seed = data.get("seed")
    locale = _coerce_str(data.get("locale"), "locale")
    include = _normalize_sequence(data.get("include"))
    exclude = _normalize_sequence(data.get("exclude"))

    p_none = data.get("p_none")
    if p_none is not None:
        try:
            p_val = float(p_none)
        except (TypeError, ValueError) as exc:
            raise ConfigError("p_none must be a float value.") from exc
        if not (0.0 <= p_val <= 1.0):
            raise ConfigError("p_none must be between 0.0 and 1.0 inclusive.")
        p_none_value: float | None = p_val
    else:
        p_none_value = None

    union_policy = _coerce_policy(data.get("union_policy"), UNION_POLICIES, "union_policy")
    enum_policy = _coerce_policy(data.get("enum_policy"), ENUM_POLICIES, "enum_policy")

    overrides_value = _normalize_overrides(data.get("overrides"))

    emitters_value = _normalize_emitters(data.get("emitters"))
    json_value = _normalize_json(data.get("json"))
    field_policies_value = _normalize_field_policies(data.get("field_policies"))
    now_value = _coerce_datetime(data.get("now"), "now")

    seed_value: int | str | None
    if isinstance(seed, (int, str)) or seed is None:
        seed_value = seed
    else:
        raise ConfigError("seed must be an int, str, or null.")

    config = AppConfig(
        preset=preset_value,
        seed=seed_value,
        locale=locale,
        include=include,
        exclude=exclude,
        p_none=p_none_value,
        union_policy=union_policy,
        enum_policy=enum_policy,
        now=now_value,
        overrides=overrides_value,
        field_policies=field_policies_value,
        emitters=emitters_value,
        json=json_value,
    )

    return config


def _coerce_str(value: Any, field_name: str) -> str:
    if value is None:
        return cast(str, getattr(DEFAULT_CONFIG, field_name))
    if not isinstance(value, str):
        raise ConfigError(f"{field_name} must be a string.")
    return value


def _normalize_sequence(value: Any) -> tuple[str, ...]:
    if value is None:
        return ()
    if isinstance(value, str):
        parts = [part.strip() for part in value.split(",") if part.strip()]
        return tuple(parts)
    if isinstance(value, Sequence):
        sequence_items: list[str] = []
        for item in value:
            if not isinstance(item, str):
                raise ConfigError("Sequence values must contain only strings.")
            sequence_items.append(item)
        return tuple(sequence_items)
    raise ConfigError("Expected a sequence or string value.")


def _coerce_policy(value: Any, allowed: set[str], field_name: str) -> str:
    default_value = cast(str, getattr(DEFAULT_CONFIG, field_name))
    if value is None:
        return default_value
    if not isinstance(value, str):
        raise ConfigError(f"{field_name} must be a string.")
    if value not in allowed:
        raise ConfigError(f"{field_name} must be one of {sorted(allowed)}.")
    return value


def _coerce_datetime(value: Any, field_name: str) -> datetime.datetime | None:
    if value is None:
        return None
    if isinstance(value, datetime.datetime):
        if value.tzinfo is None:
            return value.replace(tzinfo=datetime.timezone.utc)
        return value
    if isinstance(value, datetime.date):
        return datetime.datetime.combine(value, datetime.time(), tzinfo=datetime.timezone.utc)
    if isinstance(value, str):
        text = value.strip()
        if not text or text.lower() == "none":
            return None
        normalized = text.replace("Z", "+00:00")
        try:
            parsed = datetime.datetime.fromisoformat(normalized)
        except ValueError as exc:
            raise ConfigError(f"{field_name} must be an ISO 8601 datetime string.") from exc
        if parsed.tzinfo is None:
            parsed = parsed.replace(tzinfo=datetime.timezone.utc)
        return parsed
    raise ConfigError(f"{field_name} must be an ISO 8601 datetime string or datetime object.")


def _normalize_overrides(value: Any) -> Mapping[str, Mapping[str, Any]]:
    if value is None:
        return {}
    if not isinstance(value, Mapping):
        raise ConfigError("overrides must be a mapping.")

    overrides: dict[str, dict[str, Any]] = {}
    for model_key, fields in value.items():
        if not isinstance(model_key, str):
            raise ConfigError("override model keys must be strings.")
        if not isinstance(fields, Mapping):
            raise ConfigError("override fields must be mappings.")
        overrides[model_key] = {}
        for field_name, field_config in fields.items():
            if not isinstance(field_name, str):
                raise ConfigError("override field names must be strings.")
            overrides[model_key][field_name] = field_config
    return overrides


def _normalize_field_policies(value: Any) -> tuple[FieldPolicy, ...]:
    if value is None:
        return ()
    if not isinstance(value, Mapping):
        raise ConfigError("field_policies must be a mapping of pattern to policy settings.")

    policies: list[FieldPolicy] = []
    for index, (pattern, raw_options) in enumerate(value.items()):
        if not isinstance(pattern, str) or not pattern.strip():
            raise ConfigError("field policy keys must be non-empty strings.")
        if not isinstance(raw_options, Mapping):
            raise ConfigError(f"Field policy '{pattern}' must be a mapping of options.")

        p_none = raw_options.get("p_none")
        if p_none is not None:
            try:
                p_none = float(p_none)
            except (TypeError, ValueError) as exc:
                raise ConfigError(
                    f"Field policy '{pattern}' p_none must be a float value."
                ) from exc
            if not (0.0 <= p_none <= 1.0):
                raise ConfigError(f"Field policy '{pattern}' p_none must be between 0.0 and 1.0.")

        enum_policy = raw_options.get("enum_policy")
        if enum_policy is not None and (
            not isinstance(enum_policy, str) or enum_policy not in ENUM_POLICIES
        ):
            raise ConfigError(
                f"Field policy '{pattern}' enum_policy must be one of {sorted(ENUM_POLICIES)}."
            )

        union_policy = raw_options.get("union_policy")
        if union_policy is not None and (
            not isinstance(union_policy, str) or union_policy not in UNION_POLICIES
        ):
            raise ConfigError(
                f"Field policy '{pattern}' union_policy must be one of {sorted(UNION_POLICIES)}."
            )

        allowed_keys = {"p_none", "enum_policy", "union_policy"}
        for option_key in raw_options:
            if option_key not in allowed_keys:
                raise ConfigError(
                    f"Field policy '{pattern}' contains unsupported option '{option_key}'."
                )

        options = {"p_none": p_none, "enum_policy": enum_policy, "union_policy": union_policy}
        policies.append(FieldPolicy(pattern=pattern, options=options, index=index))

    return tuple(policies)


def _normalize_emitters(value: Any) -> EmittersConfig:
    pytest_config = PytestEmitterConfig()

    if value:
        if not isinstance(value, Mapping):
            raise ConfigError("emitters must be a mapping.")
        pytest_data = value.get("pytest")
        if pytest_data is not None:
            if not isinstance(pytest_data, Mapping):
                raise ConfigError("emitters.pytest must be a mapping.")
            pytest_config = replace(
                pytest_config,
                style=_coerce_optional_str(pytest_data.get("style"), "emitters.pytest.style"),
                scope=_coerce_optional_str(pytest_data.get("scope"), "emitters.pytest.scope"),
            )

    return EmittersConfig(pytest=pytest_config)


def _normalize_json(value: Any) -> JsonConfig:
    json_config = JsonConfig()

    if value is None:
        return json_config
    if not isinstance(value, Mapping):
        raise ConfigError("json configuration must be a mapping.")

    indent_raw = value.get("indent", json_config.indent)
    orjson_raw = value.get("orjson", json_config.orjson)

    indent = _coerce_indent(indent_raw)
    orjson = _coerce_bool(orjson_raw, "json.orjson")

    return JsonConfig(indent=indent, orjson=orjson)


def _coerce_indent(value: Any) -> int:
    if value is None:
        return JsonConfig().indent
    try:
        indent_val = int(value)
    except (TypeError, ValueError) as exc:
        raise ConfigError("json.indent must be an integer.") from exc
    if indent_val < 0:
        raise ConfigError("json.indent must be non-negative.")
    return indent_val


def _coerce_bool(value: Any, field_name: str) -> bool:
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        lower = value.lower()
        if lower in TRUTHY:
            return True
        if lower in FALSY:
            return False
        raise ConfigError(f"{field_name} must be a boolean string.")
    if value is None:
        attr = field_name.split(".")[-1]
        return cast(bool, getattr(DEFAULT_CONFIG.json, attr))
    raise ConfigError(f"{field_name} must be a boolean.")


def _coerce_optional_str(value: Any, field_name: str) -> str:
    if value is None:
        default = DEFAULT_CONFIG.emitters.pytest
        attr = field_name.split(".")[-1]
        return cast(str, getattr(default, attr))
    if not isinstance(value, str):
        raise ConfigError(f"{field_name} must be a string.")
    return value


def _coerce_preset_value(value: Any) -> str | None:
    if value is None:
        return None
    if not isinstance(value, str):
        raise ConfigError("preset must be a string when specified.")
    stripped = value.strip()
    if not stripped:
        return None
    normalized = normalize_preset_name(stripped)
    try:
        spec = get_preset_spec(normalized)
    except KeyError as exc:
        raise ConfigError(f"Unknown preset '{value}'.") from exc
    return spec.name


def _ensure_mutable(mapping: Mapping[str, Any]) -> dict[str, Any]:
    mutable: dict[str, Any] = {}
    for key, value in mapping.items():
        if isinstance(value, Mapping):
            mutable[key] = _ensure_mutable(value)
        elif isinstance(value, list):
            items: list[Any] = []
            for item in value:
                if isinstance(item, Mapping):
                    items.append(_ensure_mutable(item))
                else:
                    items.append(item)
            mutable[key] = items
        else:
            mutable[key] = value
    return mutable


def _deep_merge(target: MutableMapping[str, Any], source: Mapping[str, Any]) -> None:
    for key, value in source.items():
        if key in target and isinstance(target[key], MutableMapping) and isinstance(value, Mapping):
            _deep_merge(cast(MutableMapping[str, Any], target[key]), value)
        else:
            if isinstance(value, Mapping):
                target[key] = _ensure_mutable(value)
            elif isinstance(value, list):
                target[key] = list(value)
            else:
                target[key] = value


def _merge_source_with_preset(data: MutableMapping[str, Any], source: Mapping[str, Any]) -> None:
    if not source:
        return

    mutable = _ensure_mutable(source)

    if "preset" in mutable:
        preset_raw = mutable.pop("preset")
        if preset_raw is None:
            data["preset"] = None
        else:
            if not isinstance(preset_raw, str):
                raise ConfigError("preset must be a string when specified.")
            preset_name = normalize_preset_name(preset_raw)
            try:
                preset_spec = get_preset_spec(preset_name)
            except KeyError as exc:
                raise ConfigError(f"Unknown preset '{preset_raw}'.") from exc

            _deep_merge(data, _ensure_mutable(preset_spec.settings))
            data["preset"] = preset_spec.name

    _deep_merge(data, mutable)

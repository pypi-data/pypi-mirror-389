{
  "permissions": {
    "allow": [
      "Bash(ollama list:*)",
      "WebFetch(domain:*)",
      "Bash(pip show:*)",
      "Bash(curl:*)",
      "Bash(find:*)",
      "Bash(rg:*)",
      "Bash(tail:*)",
      "Bash(ls:*)",
      "Bash(grep:*)",
      "Bash(python:*)",
      "Bash(mkdir:*)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg:*)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg -B 5 -A 5 \"max_tool_calls\" abstractllm/session.py)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg \"Maximum tool call limit\" abstractllm/session.py)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg -B 5 -A 5 \"Maximum tool call limit.*reached\" abstractllm/session.py)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg -B 3 -A 3 \"max_tool_calls\" alma-minimal.py)",
      "Bash(/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/vendor/ripgrep/arm64-darwin/rg -n \"use_chat_endpoint = formatted_tools\" abstractllm/providers/ollama.py)",
      "Bash(ls:*)",
      "WebSearch",
      "Read(//Users/albou/.cache/huggingface/hub/models--mlx-community--GLM-4.5-Air-4bit/snapshots/**)",
      "Bash(xargs cat:*)",
      "Read(//Users/albou/.cache/huggingface/**)",
      "Bash(xargs ls:*)",
      "Bash(awk:*)",
      "Bash(pip install:*)",
      "Bash(pip uninstall:*)",
      "Read(//opt/anaconda3/lib/**)",
      "Bash(echo $PATH)",
      "Bash(chmod:*)",
      "Bash(./run_isolated.sh python:*)",
      "Read(//private/tmp/**)",
      "Bash(cat:*)",
      "Bash(timeout:*)",
      "Bash(xargs:*)",
      "WebFetch(domain:stackoverflow.com)",
      "Read(//Users/albou/projects/forgellm/**)",
      "Bash(git add:*)",
      "WebFetch(domain:platform.openai.com)",
      "Read(//Users/albou/.abstractllm/**)",
      "Read(//tmp/**)",
      "Bash(zcat:*)",
      "Bash(gzip:*)",
      "Bash(tree:*)",
      "Read(//Users/albou/projects/promptons/promptons_registry/**)",
      "Bash(PYTHONPATH=/Users/albou/projects/abstractllm python -c:*)",
      "Bash(PYTHONPATH=/Users/albou/projects/abstractllm python -m abstractllm.providers.lmstudio_provider)",
      "WebFetch(domain:lmstudio.ai)",
      "WebFetch(domain:medium.com)",
      "WebFetch(domain:github.com)",
      "mcp__context7__resolve-library-id",
      "mcp__context7__get-library-docs",
      "WebFetch(domain:docs.llamaindex.ai)",
      "Read(///**)",
      "Bash(ABSTRACTLLM_LOG_LEVEL=DEBUG python abstractllm/cli.py --provider ollama --model qwen3-coder:30b --stream --prompt \"list the files in the current directory\")",
      "Read(//opt/anaconda3/bin/**)",
      "WebFetch(domain:www.promptingguide.ai)",
      "WebFetch(domain:arxiv.org)",
      "WebFetch(domain:react-lm.github.io)",
      "Bash(tee:*)",
      "Read(//Users/albou/projects/abstractllm_core/abstractllm//**)",
      "Read(//Users/albou/projects/abstractllm_core/abstractllm/**)",
      "Read(//Users/albou/projects/abstractllm_core/**)",
      "Read(//Users/albou/projects/**)"
    ],
    "deny": []
  },
  "outputStyle": "Explanatory"
}
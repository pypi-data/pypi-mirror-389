[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "abstractllm"
version = "1.1.1"
authors = [
    { name = "Laurent-Philippe Albou", email = "lpalbou@gmail.com" },
]
description = "A unified interface for large language models with support for OpenAI, Anthropic, Hugging Face, Ollama, and MLX"
readme = "README.md"
requires-python = ">=3.8"
license = "MIT"
keywords = ["llm", "ai", "abstraction", "openai", "gpt", "claude", "huggingface", "ollama", "mlx", "apple silicon"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Operating System :: MacOS :: MacOS X",
    "Operating System :: POSIX :: Linux",
    "Operating System :: Microsoft :: Windows",
]
# Core dependencies that are always needed
dependencies = [
    "pydantic>=2.0.0",  # For configuration and type validation
    "typing-extensions>=4.0.0",  # For enhanced typing support
    "pillow>=9.0.0",  # For image processing (required by MLX and other providers)
]

[project.urls]
Homepage = "https://github.com/lpalbou/abstractllm"
Repository = "https://github.com/lpalbou/abstractllm.git"
"Bug Tracker" = "https://github.com/lpalbou/abstractllm/issues"

[project.optional-dependencies]
openai = ["openai>=1.0.0"]
anthropic = ["anthropic>=0.18.0"]
huggingface = [
    "transformers>=4.36.0",
    "torch>=2.0.0",
    "huggingface-hub>=0.20.0",
    "pillow>=9.0.0",  # For image processing
]
ollama = [
    "requests>=2.25.0",  # For synchronous API calls
    "aiohttp>=3.8.0",    # For asynchronous API calls
]
mlx = [
    "mlx>=0.0.25",        # Core MLX framework
    "mlx-lm>=0.0.7",      # Language model support
    "huggingface_hub>=0.15.0",
    "transformers>=4.30.0",  # For chat templating
    "numpy>=1.24.0",         # Often needed by MLX
    "humanize>=4.6.0",       # For human-readable sizes in caching utilities
    "pillow>=9.0.0",         # For image processing with vision models
]
tools = [
    "docstring-parser>=0.15",
    "pydantic>=2.0.0",
    "jsonschema>=4.0.0",
]
all = [
    "openai>=1.0.0",
    "anthropic>=0.18.0",
    "transformers>=4.36.0",
    "torch>=2.0.0",
    "huggingface-hub>=0.20.0",
    "pillow>=9.0.0",
    "requests>=2.25.0",
    "aiohttp>=3.8.0",
    "docstring-parser>=0.15",
    "pydantic>=2.0.0",
    "jsonschema>=4.0.0",
    # MLX dependencies (Apple Silicon specific, will fail gracefully on other platforms)
    "mlx>=0.0.25",
    "mlx-lm>=0.0.7",
    "numpy>=1.24.0",
    "humanize>=4.6.0",
]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "isort>=5.0.0",
]

[project.scripts]
alma = "abstractllm.cli:main"

[tool.hatch.build.targets.wheel]
packages = ["abstractllm"] 
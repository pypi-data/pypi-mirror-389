//! é«˜æ€§èƒ½äºŒè¿›åˆ¶å…ƒæ•°æ®æ ¼å¼
//! 
//! æä¾›æ¯”MessagePackæ›´å¿«çš„åºåˆ—åŒ–/ååºåˆ—åŒ–æ€§èƒ½ï¼Œä¸“ä¸ºNumPackä¼˜åŒ–

use std::collections::HashMap;
use std::fs::File;
use std::io::{Read, Write, Seek, SeekFrom, BufReader, BufWriter};
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex, RwLock};
use std::time::SystemTime;

use crate::core::error::{NpkError, NpkResult};
use crate::core::metadata::DataType;

/// äºŒè¿›åˆ¶æ ¼å¼é­”æ•° (ASCII: "NPKB")
pub const BINARY_MAGIC: u32 = 0x424B504E;

/// å½“å‰äºŒè¿›åˆ¶æ ¼å¼ç‰ˆæœ¬
pub const BINARY_VERSION: u32 = 1;

/// äºŒè¿›åˆ¶æ ¼å¼çš„æ•°æ®ç±»å‹æšä¸¾
#[derive(Debug, Clone, Copy, PartialEq)]
#[repr(u8)]
pub enum BinaryDataType {
    Bool = 0,
    Uint8 = 1,
    Uint16 = 2,
    Uint32 = 3,
    Uint64 = 4,
    Int8 = 5,
    Int16 = 6,
    Int32 = 7,
    Int64 = 8,
    Float16 = 9,
    Float32 = 10,
    Float64 = 11,
    Complex64 = 12,
    Complex128 = 13,
}

impl BinaryDataType {
    pub fn size_bytes(&self) -> usize {
        match self {
            BinaryDataType::Bool => 1,
            BinaryDataType::Uint8 => 1,
            BinaryDataType::Uint16 => 2,
            BinaryDataType::Uint32 => 4,
            BinaryDataType::Uint64 => 8,
            BinaryDataType::Int8 => 1,
            BinaryDataType::Int16 => 2,
            BinaryDataType::Int32 => 4,
            BinaryDataType::Int64 => 8,
            BinaryDataType::Float16 => 2,
            BinaryDataType::Float32 => 4,
            BinaryDataType::Float64 => 8,
            BinaryDataType::Complex64 => 8,
            BinaryDataType::Complex128 => 16,
        }
    }

    pub fn from_u8(value: u8) -> Self {
        match value {
            0 => BinaryDataType::Bool,
            1 => BinaryDataType::Uint8,
            2 => BinaryDataType::Uint16,
            3 => BinaryDataType::Uint32,
            4 => BinaryDataType::Uint64,
            5 => BinaryDataType::Int8,
            6 => BinaryDataType::Int16,
            7 => BinaryDataType::Int32,
            8 => BinaryDataType::Int64,
            9 => BinaryDataType::Float16,
            10 => BinaryDataType::Float32,
            11 => BinaryDataType::Float64,
            12 => BinaryDataType::Complex64,
            13 => BinaryDataType::Complex128,
            _ => BinaryDataType::Int32, // é»˜è®¤å€¼
        }
    }
}

impl From<DataType> for BinaryDataType {
    fn from(dt: DataType) -> Self {
        match dt {
            DataType::Bool => BinaryDataType::Bool,
            DataType::Uint8 => BinaryDataType::Uint8,
            DataType::Uint16 => BinaryDataType::Uint16,
            DataType::Uint32 => BinaryDataType::Uint32,
            DataType::Uint64 => BinaryDataType::Uint64,
            DataType::Int8 => BinaryDataType::Int8,
            DataType::Int16 => BinaryDataType::Int16,
            DataType::Int32 => BinaryDataType::Int32,
            DataType::Int64 => BinaryDataType::Int64,
            DataType::Float16 => BinaryDataType::Float16,
            DataType::Float32 => BinaryDataType::Float32,
            DataType::Float64 => BinaryDataType::Float64,
            DataType::Complex64 => BinaryDataType::Complex64,
            DataType::Complex128 => BinaryDataType::Complex128,
        }
    }
}

impl From<BinaryDataType> for DataType {
    fn from(dt: BinaryDataType) -> Self {
        match dt {
            BinaryDataType::Bool => DataType::Bool,
            BinaryDataType::Uint8 => DataType::Uint8,
            BinaryDataType::Uint16 => DataType::Uint16,
            BinaryDataType::Uint32 => DataType::Uint32,
            BinaryDataType::Uint64 => DataType::Uint64,
            BinaryDataType::Int8 => DataType::Int8,
            BinaryDataType::Int16 => DataType::Int16,
            BinaryDataType::Int32 => DataType::Int32,
            BinaryDataType::Int64 => DataType::Int64,
            BinaryDataType::Float16 => DataType::Float16,
            BinaryDataType::Float32 => DataType::Float32,
            BinaryDataType::Float64 => DataType::Float64,
            BinaryDataType::Complex64 => DataType::Complex64,
            BinaryDataType::Complex128 => DataType::Complex128,
        }
    }
}

/// å‹ç¼©ç®—æ³•æšä¸¾
#[derive(Debug, Clone, Copy, PartialEq)]
#[repr(u8)]
pub enum CompressionAlgorithm {
    None = 0,
    Zstd = 1,
}

impl CompressionAlgorithm {
    pub fn from_str(s: &str) -> Self {
        match s.to_lowercase().as_str() {
            "zstd" => CompressionAlgorithm::Zstd,
            _ => CompressionAlgorithm::None,
        }
    }

    pub fn to_string(&self) -> &'static str {
        match self {
            CompressionAlgorithm::None => "none",
            CompressionAlgorithm::Zstd => "zstd",
        }
    }

    pub fn from_u8(value: u8) -> Self {
        match value {
            1 => CompressionAlgorithm::Zstd,
            _ => CompressionAlgorithm::None,
        }
    }
}

/// å—ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct BinaryBlockInfo {
    pub offset: u64,
    pub original_size: u64,
    pub compressed_size: u64,
}

/// å—å‹ç¼©ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct BinaryBlockCompressionInfo {
    pub enabled: bool,
    pub block_size: u64,
    pub num_blocks: u64,
    pub blocks: Vec<BinaryBlockInfo>,
}

/// å‹ç¼©ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct BinaryCompressionInfo {
    pub algorithm: CompressionAlgorithm,
    pub level: u32,
    pub original_size: u64,
    pub compressed_size: u64,
    pub block_compression: Option<BinaryBlockCompressionInfo>,
}

impl Default for BinaryCompressionInfo {
    fn default() -> Self {
        Self {
            algorithm: CompressionAlgorithm::None,
            level: 0,
            original_size: 0,
            compressed_size: 0,
            block_compression: None,
        }
    }
}

/// äºŒè¿›åˆ¶æ ¼å¼çš„æ•°ç»„å…ƒæ•°æ®
#[derive(Debug, Clone)]
pub struct BinaryArrayMetadata {
    pub name: String,
    pub shape: Vec<u64>,
    pub data_file: String,
    pub last_modified: u64,
    pub size_bytes: u64,
    pub dtype: BinaryDataType,
    pub compression: BinaryCompressionInfo,
}

impl BinaryArrayMetadata {
    pub fn new(name: String, shape: Vec<u64>, data_file: String, dtype: BinaryDataType) -> Self {
        let total_elements: u64 = shape.iter().product();
        let size_bytes = total_elements * dtype.size_bytes() as u64;
        
        Self {
            name,
            shape,
            data_file,
            last_modified: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_micros() as u64,
            size_bytes,
            dtype,
            compression: BinaryCompressionInfo::default(),
        }
    }

    pub fn get_dtype(&self) -> BinaryDataType {
        self.dtype
    }

    /// å†™å…¥å…ƒæ•°æ®åˆ°äºŒè¿›åˆ¶æµ
    fn write_to_stream<W: Write>(&self, writer: &mut W) -> NpkResult<()> {
        // å†™å…¥åç§°é•¿åº¦å’Œåç§°
        let name_bytes = self.name.as_bytes();
        writer.write_all(&(name_bytes.len() as u32).to_le_bytes())?;
        writer.write_all(name_bytes)?;

        // å†™å…¥å½¢çŠ¶
        writer.write_all(&(self.shape.len() as u32).to_le_bytes())?;
        for dim in &self.shape {
            writer.write_all(&dim.to_le_bytes())?;
        }

        // å†™å…¥æ•°æ®æ–‡ä»¶å
        let data_file_bytes = self.data_file.as_bytes();
        writer.write_all(&(data_file_bytes.len() as u32).to_le_bytes())?;
        writer.write_all(data_file_bytes)?;

        // å†™å…¥åŸºæœ¬ä¿¡æ¯
        writer.write_all(&self.last_modified.to_le_bytes())?;
        writer.write_all(&self.size_bytes.to_le_bytes())?;
        writer.write_all(&[self.dtype as u8])?;

        // å†™å…¥å‹ç¼©ä¿¡æ¯
        writer.write_all(&[self.compression.algorithm as u8])?;
        writer.write_all(&self.compression.level.to_le_bytes())?;
        writer.write_all(&self.compression.original_size.to_le_bytes())?;
        writer.write_all(&self.compression.compressed_size.to_le_bytes())?;

        // å†™å…¥å—å‹ç¼©ä¿¡æ¯
        if let Some(ref block_info) = self.compression.block_compression {
            writer.write_all(&[1u8])?; // è¡¨ç¤ºæœ‰å—å‹ç¼©ä¿¡æ¯
            writer.write_all(&[if block_info.enabled { 1u8 } else { 0u8 }])?;
            writer.write_all(&block_info.block_size.to_le_bytes())?;
            writer.write_all(&block_info.num_blocks.to_le_bytes())?;
            writer.write_all(&(block_info.blocks.len() as u32).to_le_bytes())?;
            
            for block in &block_info.blocks {
                writer.write_all(&block.offset.to_le_bytes())?;
                writer.write_all(&block.original_size.to_le_bytes())?;
                writer.write_all(&block.compressed_size.to_le_bytes())?;
            }
        } else {
            writer.write_all(&[0u8])?; // è¡¨ç¤ºæ²¡æœ‰å—å‹ç¼©ä¿¡æ¯
        }

        Ok(())
    }

    /// ä»äºŒè¿›åˆ¶æµè¯»å–å…ƒæ•°æ®
    fn read_from_stream<R: Read>(reader: &mut R) -> NpkResult<Self> {
        // è¯»å–åç§°
        let mut len_buf = [0u8; 4];
        reader.read_exact(&mut len_buf)?;
        let name_len = u32::from_le_bytes(len_buf) as usize;
        let mut name_buf = vec![0u8; name_len];
        reader.read_exact(&mut name_buf)?;
        let name = String::from_utf8(name_buf)
            .map_err(|e| NpkError::InvalidMetadata(format!("Invalid name UTF-8: {}", e)))?;

        // è¯»å–å½¢çŠ¶
        reader.read_exact(&mut len_buf)?;
        let shape_len = u32::from_le_bytes(len_buf) as usize;
        let mut shape = Vec::with_capacity(shape_len);
        for _ in 0..shape_len {
            let mut dim_buf = [0u8; 8];
            reader.read_exact(&mut dim_buf)?;
            shape.push(u64::from_le_bytes(dim_buf));
        }

        // è¯»å–æ•°æ®æ–‡ä»¶å
        reader.read_exact(&mut len_buf)?;
        let data_file_len = u32::from_le_bytes(len_buf) as usize;
        let mut data_file_buf = vec![0u8; data_file_len];
        reader.read_exact(&mut data_file_buf)?;
        let data_file = String::from_utf8(data_file_buf)
            .map_err(|e| NpkError::InvalidMetadata(format!("Invalid data file UTF-8: {}", e)))?;

        // è¯»å–åŸºæœ¬ä¿¡æ¯
        let mut u64_buf = [0u8; 8];
        reader.read_exact(&mut u64_buf)?;
        let last_modified = u64::from_le_bytes(u64_buf);
        
        reader.read_exact(&mut u64_buf)?;
        let size_bytes = u64::from_le_bytes(u64_buf);
        
        let mut dtype_buf = [0u8; 1];
        reader.read_exact(&mut dtype_buf)?;
        let dtype = BinaryDataType::from_u8(dtype_buf[0]);

        // è¯»å–å‹ç¼©ä¿¡æ¯
        reader.read_exact(&mut dtype_buf)?;
        let algorithm = CompressionAlgorithm::from_u8(dtype_buf[0]);
        
        let mut u32_buf = [0u8; 4];
        reader.read_exact(&mut u32_buf)?;
        let level = u32::from_le_bytes(u32_buf);
        
        reader.read_exact(&mut u64_buf)?;
        let original_size = u64::from_le_bytes(u64_buf);
        
        reader.read_exact(&mut u64_buf)?;
        let compressed_size = u64::from_le_bytes(u64_buf);

        // è¯»å–å—å‹ç¼©ä¿¡æ¯
        reader.read_exact(&mut dtype_buf)?;
        let has_block_info = dtype_buf[0] != 0;
        
        let block_compression = if has_block_info {
            reader.read_exact(&mut dtype_buf)?;
            let enabled = dtype_buf[0] != 0;
            
            reader.read_exact(&mut u64_buf)?;
            let block_size = u64::from_le_bytes(u64_buf);
            
            reader.read_exact(&mut u64_buf)?;
            let num_blocks = u64::from_le_bytes(u64_buf);
            
            reader.read_exact(&mut u32_buf)?;
            let blocks_len = u32::from_le_bytes(u32_buf) as usize;
            
            let mut blocks = Vec::with_capacity(blocks_len);
            for _ in 0..blocks_len {
                reader.read_exact(&mut u64_buf)?;
                let offset = u64::from_le_bytes(u64_buf);
                
                reader.read_exact(&mut u64_buf)?;
                let original_size = u64::from_le_bytes(u64_buf);
                
                reader.read_exact(&mut u64_buf)?;
                let compressed_size = u64::from_le_bytes(u64_buf);
                
                blocks.push(BinaryBlockInfo {
                    offset,
                    original_size,
                    compressed_size,
                });
            }
            
            Some(BinaryBlockCompressionInfo {
                enabled,
                block_size,
                num_blocks,
                blocks,
            })
        } else {
            None
        };

        let compression = BinaryCompressionInfo {
            algorithm,
            level,
            original_size,
            compressed_size,
            block_compression,
        };

        Ok(Self {
            name,
            shape,
            data_file,
            last_modified,
            size_bytes,
            dtype,
            compression,
        })
    }
}

/// äºŒè¿›åˆ¶æ ¼å¼çš„å…ƒæ•°æ®å­˜å‚¨
#[derive(Debug)]
pub struct BinaryMetadataStore {
    pub version: u32,
    pub arrays: HashMap<String, BinaryArrayMetadata>,
    pub total_size: u64,
}

impl BinaryMetadataStore {
    pub fn new() -> Self {
        Self {
            version: BINARY_VERSION,
            arrays: HashMap::new(),
            total_size: 0,
        }
    }

    pub fn load(path: &Path) -> NpkResult<Self> {
        if !path.exists() {
            return Ok(Self::new());
        }

        let file = File::open(path)?;
        let mut reader = BufReader::new(file);

        // è¯»å–é­”æ•°
        let mut magic_buf = [0u8; 4];
        reader.read_exact(&mut magic_buf)?;
        let magic = u32::from_le_bytes(magic_buf);
        
        if magic != BINARY_MAGIC {
            return Err(NpkError::InvalidMetadata("Invalid magic number".to_string()));
        }

        // è¯»å–ç‰ˆæœ¬
        let mut version_buf = [0u8; 4];
        reader.read_exact(&mut version_buf)?;
        let version = u32::from_le_bytes(version_buf);

        // è¯»å–æ€»å¤§å°
        let mut total_size_buf = [0u8; 8];
        reader.read_exact(&mut total_size_buf)?;
        let total_size = u64::from_le_bytes(total_size_buf);

        // è¯»å–æ•°ç»„æ•°é‡
        let mut arrays_count_buf = [0u8; 4];
        reader.read_exact(&mut arrays_count_buf)?;
        let arrays_count = u32::from_le_bytes(arrays_count_buf);

        // è¯»å–æ•°ç»„å…ƒæ•°æ®
        let mut arrays = HashMap::new();
        for _ in 0..arrays_count {
            let meta = BinaryArrayMetadata::read_from_stream(&mut reader)?;
            arrays.insert(meta.name.clone(), meta);
        }

        Ok(Self {
            version,
            arrays,
            total_size,
        })
    }

    pub fn save(&self, path: &Path) -> NpkResult<()> {
        // ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶åï¼Œé¿å…å¤šçº¿ç¨‹å†²çª
        // æ ¼å¼ï¼šmetadata.npkm.tmp.{pid}_{tid}_{timestamp}
        use std::time::{SystemTime, UNIX_EPOCH};
        
        let pid = std::process::id();
        let tid = std::thread::current().id();
        let tid_str = format!("{:?}", tid).replace("ThreadId(", "").replace(")", "");
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_nanos();
        
        let temp_filename = format!(
            "{}.tmp.{}_{}_{}", 
            path.file_name().unwrap().to_string_lossy(),
            pid, 
            tid_str,
            timestamp
        );
        let temp_path = path.with_file_name(temp_filename);
        
        // å†™å…¥ä¸´æ—¶æ–‡ä»¶
        {
            let file = File::create(&temp_path)?;
            let mut writer = BufWriter::new(file);

            // å†™å…¥é­”æ•°
            writer.write_all(&BINARY_MAGIC.to_le_bytes())?;

            // å†™å…¥ç‰ˆæœ¬
            writer.write_all(&self.version.to_le_bytes())?;

            // å†™å…¥æ€»å¤§å°
            writer.write_all(&self.total_size.to_le_bytes())?;

            // å†™å…¥æ•°ç»„æ•°é‡
            writer.write_all(&(self.arrays.len() as u32).to_le_bytes())?;

            // å†™å…¥æ¯ä¸ªæ•°ç»„çš„å…ƒæ•°æ®
            for meta in self.arrays.values() {
                meta.write_to_stream(&mut writer)?;
            }

            writer.flush()?;
            // ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
            drop(writer);
        }

        // åŸå­æ€§é‡å‘½åï¼ˆå¦‚æœå¤±è´¥ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼‰
        match std::fs::rename(&temp_path, path) {
            Ok(_) => Ok(()),
            Err(e) => {
                // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                let _ = std::fs::remove_file(&temp_path);
                Err(NpkError::IoError(e))
            }
        }
    }

    pub fn add_array(&mut self, meta: BinaryArrayMetadata) {
        self.total_size = self.total_size.saturating_sub(
            self.arrays.get(&meta.name).map(|m| m.size_bytes).unwrap_or(0)
        );
        self.total_size += meta.size_bytes;
        self.arrays.insert(meta.name.clone(), meta);
    }

    pub fn remove_array(&mut self, name: &str) -> bool {
        if let Some(meta) = self.arrays.remove(name) {
            self.total_size = self.total_size.saturating_sub(meta.size_bytes);
            true
        } else {
            false
        }
    }

    pub fn get_array(&self, name: &str) -> Option<&BinaryArrayMetadata> {
        self.arrays.get(name)
    }

    pub fn list_arrays(&self) -> Vec<String> {
        self.arrays.keys().cloned().collect()
    }

    pub fn has_array(&self, name: &str) -> bool {
        self.arrays.contains_key(name)
    }
}

/// ç¼“å­˜çš„äºŒè¿›åˆ¶å…ƒæ•°æ®å­˜å‚¨
pub struct BinaryCachedStore {
    store: Arc<RwLock<BinaryMetadataStore>>,
    path: Arc<Path>,
    last_sync: Arc<Mutex<SystemTime>>,
    sync_interval: std::time::Duration,
}

impl BinaryCachedStore {
    pub fn new(path: &Path, _wal_path: Option<PathBuf>) -> NpkResult<Self> {
        let store = BinaryMetadataStore::load(path).unwrap_or_else(|_| BinaryMetadataStore::new());
        
        let cached_store = Self {
            store: Arc::new(RwLock::new(store)),
            path: Arc::from(path),
            last_sync: Arc::new(Mutex::new(SystemTime::now())),
            sync_interval: std::time::Duration::from_secs(1),
        };
        
        // ä¿å­˜åˆå§‹å­˜å‚¨
        cached_store.sync_to_disk()?;
        Ok(cached_store)
    }

    pub fn from_store(store: BinaryMetadataStore, path: &Path, _wal_path: Option<PathBuf>) -> NpkResult<Self> {
        Ok(Self {
            store: Arc::new(RwLock::new(store)),
            path: Arc::from(path),
            last_sync: Arc::new(Mutex::new(SystemTime::now())),
            sync_interval: std::time::Duration::from_secs(1),
        })
    }

    fn sync_to_disk(&self) -> NpkResult<()> {
        // å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å¯èƒ½å‡ºç°ä¸´æ—¶çš„æ–‡ä»¶è®¿é—®å†²çªï¼Œæ·»åŠ é‡è¯•æœºåˆ¶
        const MAX_RETRIES: usize = 3;
        const RETRY_DELAY_MS: u64 = 10;
        
        let mut last_error = None;
        for attempt in 0..MAX_RETRIES {
        let store = self.store.read().unwrap();
            match store.save(&self.path) {
                Ok(_) => {
                    drop(store);
        let mut last_sync = self.last_sync.lock().unwrap();
        *last_sync = SystemTime::now();
                    return Ok(());
                }
                Err(e) => {
                    last_error = Some(e);
                    drop(store);
                    
                    // æœ€åä¸€æ¬¡å°è¯•ä¸éœ€è¦ç­‰å¾…
                    if attempt < MAX_RETRIES - 1 {
                        std::thread::sleep(std::time::Duration::from_millis(RETRY_DELAY_MS));
                    }
                }
            }
        }
        
        // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›æœ€åä¸€ä¸ªé”™è¯¯
        Err(last_error.unwrap())
    }

    pub fn add_array(&self, meta: BinaryArrayMetadata) -> NpkResult<()> {
        let mut store = self.store.write().unwrap();
        store.add_array(meta);
        drop(store);
        // ğŸš€ æ€§èƒ½å…³é”®ä¼˜åŒ–ï¼šå»¶è¿ŸåŒæ­¥ï¼Œä¸ç«‹å³å†™å…¥ç£ç›˜
        // 
        // é—®é¢˜ï¼šæ¯æ¬¡add_arrayéƒ½è°ƒç”¨sync_to_diskå¯¼è‡´æ€§èƒ½ä¸‹é™2-3x
        // NumPyä¸ä¼šæ¯æ¬¡éƒ½fsyncï¼Œæ‰€ä»¥æ›´å¿«
        // 
        // è§£å†³æ–¹æ¡ˆï¼š
        // - add_arrayåªæ›´æ–°å†…å­˜ä¸­çš„å…ƒæ•°æ®
        // - å…ƒæ•°æ®ä¼šå®šæœŸè‡ªåŠ¨åŒæ­¥ï¼ˆsync_intervalæ§åˆ¶ï¼‰
        // - æˆ–åœ¨æ˜¾å¼è°ƒç”¨force_syncæ—¶åŒæ­¥
        //
        // æ³¨é‡Šæ‰ç«‹å³åŒæ­¥ï¼š
        // self.sync_to_disk()?;
        Ok(())
    }
    
    /// å¼ºåˆ¶åŒæ­¥åˆ°ç£ç›˜
    pub fn force_sync(&self) -> NpkResult<()> {
        self.sync_to_disk()
    }

    pub fn delete_array(&self, name: &str) -> NpkResult<bool> {
        let mut store = self.store.write().unwrap();
        let result = store.remove_array(name);
        drop(store);
        // ğŸš€ å»¶è¿ŸåŒæ­¥ä¼˜åŒ–
        // if result {
        //     self.sync_to_disk()?;
        // }
        Ok(result)
    }

    pub fn get_array(&self, name: &str) -> Option<BinaryArrayMetadata> {
        let store = self.store.read().unwrap();
        store.get_array(name).cloned()
    }

    pub fn list_arrays(&self) -> Vec<String> {
        let store = self.store.read().unwrap();
        store.list_arrays()
    }

    pub fn has_array(&self, name: &str) -> bool {
        let store = self.store.read().unwrap();
        store.has_array(name)
    }

    pub fn update_array_metadata(&self, name: &str, meta: BinaryArrayMetadata) -> NpkResult<()> {
        let mut store = self.store.write().unwrap();
        store.remove_array(name);
        store.add_array(meta);
        drop(store);
        // ğŸš€ å»¶è¿ŸåŒæ­¥ä¼˜åŒ–
        // self.sync_to_disk()?;
        Ok(())
    }

    pub fn reset(&self) -> NpkResult<()> {
        let mut store = self.store.write().unwrap();
        *store = BinaryMetadataStore::new();
        drop(store);
        // ğŸš€ å»¶è¿ŸåŒæ­¥ä¼˜åŒ–
        // self.sync_to_disk()?;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[test]
    fn test_binary_metadata_store() {
        let temp_dir = TempDir::new().unwrap();
        let metadata_path = temp_dir.path().join("metadata.npkm");

        let mut store = BinaryMetadataStore::new();
        
        // æ·»åŠ æµ‹è¯•æ•°ç»„
        let shape = vec![100, 200];
        let data_file = "data_test.npkd".to_string();
        let dtype = BinaryDataType::Float32;
        
        let meta = BinaryArrayMetadata::new("test_array".to_string(), shape.clone(), data_file.clone(), dtype);
        store.add_array(meta);
        
        // éªŒè¯æ•°ç»„å­˜åœ¨
        assert!(store.has_array("test_array"));
        
        let retrieved_meta = store.get_array("test_array").unwrap();
        assert_eq!(retrieved_meta.name, "test_array");
        assert_eq!(retrieved_meta.shape, shape);
        
        // ä¿å­˜å¹¶é‡æ–°åŠ è½½
        store.save(&metadata_path).unwrap();
        
        let loaded_store = BinaryMetadataStore::load(&metadata_path).unwrap();
        assert!(loaded_store.has_array("test_array"));
        
        let loaded_meta = loaded_store.get_array("test_array").unwrap();
        assert_eq!(loaded_meta.name, "test_array");
        assert_eq!(loaded_meta.shape, shape);
    }

    #[test]
    fn test_data_type_conversion() {
        let original = DataType::Float64;
        let binary: BinaryDataType = original.into();
        let converted_back: DataType = binary.into();
        
        assert_eq!(original, converted_back);
    }

    #[test]
    fn test_compression_info() {
        let compression = BinaryCompressionInfo {
            algorithm: CompressionAlgorithm::Zstd,
            level: 3,
            original_size: 1000,
            compressed_size: 500,
            block_compression: None,
        };
        
        assert_eq!(compression.algorithm, CompressionAlgorithm::Zstd);
        assert_eq!(compression.level, 3);
    }
} 
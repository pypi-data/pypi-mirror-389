Metadata-Version: 2.1
Name: langchain-teradata
Version: 20.0.0.1
Summary: Teradata package for langchain
Home-page: https://teradata.com
Author: Teradata Corporation
License: Teradata License Agreement
Keywords: Teradata
Platform: MacOS X, Windows, Linux
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.9
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: POSIX :: Linux
Classifier: Topic :: Database :: Front-Ends
Classifier: License :: Other/Proprietary License
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE-3RD-PARTY.pdf
License-File: LICENSE.pdf
Requires-Dist: langchain-core (>=0.3.72)
Requires-Dist: teradatagenai (>=20.00.00.04)


# langchain-teradata
# Teradata Package for LangChain
`langchain-teradata` is a Teradata package for Langchain that provides users with access to Teradata's Vector Store capabilities.

For community support, please visit the [Teradata Community](https://support.teradata.com/community?id=community_forum&sys_id=14fe131e1bf7f304682ca8233a4bcb1d).

For Teradata customer support, please visit [Teradata Support](https://support.teradata.com/csm).

Copyright 2025, Teradata. All Rights Reserved.

## Table of Contents
* [Documentation](#documentation)
* [Release Notes](#release-notes)
* [Installation and Requirements](#installation-and-requirements)
* [License](#license)

## Documentation
General product information, including installation instructions, is available in the [Teradata Documentation website](https://docs.teradata.com/search/documents?query=Python+package+for+Generative-AI&sort=last_update&virtual-field=title_only&content-lang=en-US).

## Release Notes
### Version 20.00.00.01
  * New features introduced in this release require Database version 20.00.28.XX
  * Added a method `rename_metadata_keys` to rename restricted metadata keys in Langchain Document objects.
  * Added support for `search_type` "mmr" and filters to TeradataVectorStoreRetriever.
  * Added support for metadata for input Langchain Document objects.
  * Added support for embedding-based Vector Store to TeradataVectorStoreRetriever.
  * Added support to delete specific chunks from a file in the vector store using `delete_by_ids`.
  * Added new parameters to pass model url parameters and ingest parameters to from_* and add_* methods during vector store creation:
    * `model_urls` - Specifies the urls and model information to be used during Vector Store creation.
    * `ingest_params` - Specifies the parameters to be used for document ingestion for NIM. Applicable only for file-based vector stores.

  * Added new parameters for similarity_search:
    * `column`: Specifies the column name which contains the question in text format.
    * `data`: Specifies the table name/DataFrame which contains the question in text format.

  * Added new parameters for ask:
    * `batch_vector_column`: Specifies the column that contains the questions in embedded form.
    * `question_vector`: Specifies the question in vector/embedded form.
    * `data`: Specifies table name or corresponding teradataml DataFrame where the question is stored (only one question/row should be present).
    * `column`: Specifies the column name which contains the question in text format.
    * `vector_column`: Specifies the column name which contains the question in embedded format.

  * Added new common parameters for similarity_search, similarity_search_by_vector and ask:
    * `top_k`: Specifies the number of top similarity matches to be generated.
    * `search_threshold`: Specifies the threshold value to consider matching tables/views while searching.
    * `search_numcluster`: Specifies the number of clusters or fraction of train_numcluster to be considered while searching. 
    * `ef_search`: Specifies the number of neighbors to consider during search in HNSW graph.  
    * `filter`: Specifies the filter to be used for filtering the results.
    * `filter_style`: Specifies whether to apply filtering before or after the similarity_search.
    * `maximal_marginal_relevance`: Specifies whether to use Maximal Marginal Relevance (MMR) for retrieving documents.
    * `lambda_multiplier`: Specifies Lambda multiplier to control the trade-off between relevance and diversity when selecting documents.
  
  * Exposed the following classes:
      * `ModelUrlParams` class to configure model and URL-related parameters for vector store creation using from_* and add_* methods on AI-Factory.
      * `IngestParams` class to configure ingestor-related parameters for file-based vector store creation using from_* and add_* methods on AI-Factory.
      * Note: Users can still pass these parameters directly while creating the vector store.
  
  * Added the following methods to set the search parameters based on the "search_algorithm":
    * `set_kmeans_search_params()` method to configure KMEANS search parameters for the vector store.
    * `set_hnsw_search_params()` method to configure HNSW search parameters for the vector store. 
    * `set_vectordistance_search_params()` method to configure VECTORDISTANCE search algorithm parameters for the vector store.

### Version 20.00.00.00
  * `langchain-teradata 20.00.00.00` marks the first release of the package.
  * Features introduced in this release require Database version 20.00.27.XX
  * Added methods for managing and creating vector stores:

  * `from_documents(name, documents, embedding=None, **kwargs)`: Creates a new vector store, either 'file-based' or 'content-based', depending on the type of input documents. If the input is PDF file(s) or file path(s), a file-based vector store is created. If the input is LangChain Document object(s), a content-based vector store is created. If the store already exists, raises an error.
  * `from_texts(name, texts, embedding=None, **kwargs)`: Creates a content-based vector store from raw text or a list of texts. Supports embedding models and chat completion models. If the store already exists, raises an error.
  * `from_datasets(name, data, embedding=None, **kwargs)`: Creates a content-based vector store from tables or DataFrames, specifying data columns and optional key columns, with embedding model support. If the store already exists, raises an error.
  * `from_embeddings(name, data, **kwargs)`: Creates an embedding-based vector store from pre-embedded tables or DataFrames, specifying the embedding columns. If the store already exists, raises an error.
  * `add_documents(documents, **kwargs)`: Adds documents (PDFs, directories, wildcards or Langchain Documents) to an existing vector store. Automatically creates the store if it does not exist.
  * `add_datasets(data, **kwargs)`: Adds tables or DataFrames to a content-based vector store. Creates the store if needed.
  * `add_embeddings(data, **kwargs)`: Adds embedding data to an embedding-based vector store.
  * `add_texts(texts, **kwargs)`: Adds raw text or list of texts to a content-based vector store.
  * `delete_documents(documents, **kwargs)`: Removes specified documents from a file-based vector store.
  * `delete_datasets(data, **kwargs)`: Removes specified datasets from a content-based vector store.
  * `delete_embeddings(data, **kwargs)`: Removes embedding data from an embedding-based vector store.
  * `similarity_search(question, **kwargs)`: Performs similarity search in the Vector Store for the input question.
  * `similarity_search_by_vector(**kwargs)`: Performs similarity search in the Vector Store for the input question vector or embedded question stored in the input table. 
  * `prepare_response(similarity_results, question, prompt, **kwargs)`: Prepare a natural language response to the user using the input question and similarity_results provided by similarity_search() method using interactive/batch mode.
  * `ask(question, prompt, **kwargs)`: Performs similarity search in the vector store for the input question followed by preparing a natural language response to the user using interactive/batch mode.
  * `update()` : Updates the search parameters of an existing vector store.
  * `as_retriever()`: Creates a TeradataVectorStoreRetriever instance that can be used to retrieve relevant documents.

## Installation and Requirements
### Package Requirements:
* Python 3.9 or later

Note: 32-bit Python is not supported.

### Minimum System Requirements:
* Windows 7 (64Bit) or later
* macOS 10.9 (64Bit) or later
* Red Hat 7 or later versions
* Ubuntu 16.04 or later versions
* CentOS 7 or later versions
* SLES 12 or later versions

### Minimum Database Requirements
* Teradata Vantage with database release 20.00.27.XX or later 
* Vector Store (Data insights) service is enabled.


### Installation
Use pip to install the Teradata Package for Langchain

Platform       | Command
-------------- | ---
macOS/Linux    | `pip install langchain-teradata`
Windows        | `python -m pip install langchain-teradata`


## License
Use of the Teradata package for LangChain is governed by the *Teradata License Agreement*. 
After installation, the `LICENSE.pdf` and `LICENSE-3RD-PARTY.pdf` files are located in the langchain-teradata directory.

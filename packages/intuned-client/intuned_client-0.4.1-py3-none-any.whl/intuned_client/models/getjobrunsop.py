"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from intuned_client.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from intuned_client.utils import FieldMetadata, PathParamMetadata, QueryParamMetadata
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class GetJobRunsGlobalsTypedDict(TypedDict):
    workspace_id: NotRequired[str]
    r"""Your workspace ID. [How to find it](/docs/guides/general/how-to-get-a-workspace-id)?"""


class GetJobRunsGlobals(BaseModel):
    workspace_id: Annotated[
        Optional[str],
        pydantic.Field(alias="workspaceId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ] = None
    r"""Your workspace ID. [How to find it](/docs/guides/general/how-to-get-a-workspace-id)?"""


class GetJobRunsRequestTypedDict(TypedDict):
    project_name: str
    r"""Your project name. It is the name you provide when creating a project."""
    job_id: str
    r"""Your job ID. It is the ID of the job you provide when creating it."""
    page_size: NotRequired[str]
    page_number: NotRequired[str]
    sort_by: NotRequired[str]


class GetJobRunsRequest(BaseModel):
    project_name: Annotated[
        str,
        pydantic.Field(alias="projectName"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""Your project name. It is the name you provide when creating a project."""

    job_id: Annotated[
        str,
        pydantic.Field(alias="jobId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""Your job ID. It is the ID of the job you provide when creating it."""

    page_size: Annotated[
        Optional[str],
        pydantic.Field(alias="pageSize"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None

    page_number: Annotated[
        Optional[str],
        pydantic.Field(alias="pageNumber"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None

    sort_by: Annotated[
        Optional[str],
        pydantic.Field(alias="sortBy"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None


GetJobRunsNotFoundCode = Literal["not-found",]
r"""The requested resource was not found
https://docs.intunedhq.com/docs/support/errors#not-found - Find more info here
"""


GetJobRunsNotFoundCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunsUnauthorizedCode = Literal["unauthorized",]
r"""The request requires user authentication
https://docs.intunedhq.com/docs/support/errors#unauthorized - Find more info here
"""


GetJobRunsUnauthorizedCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunsBadRequestCode = Literal["bad-request",]
r"""The request is invalid or malformed
https://docs.intunedhq.com/docs/support/errors#bad-request - Find more info here
"""


GetJobRunsBadRequestCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunsType = Literal[
    "MANUAL",
    "SCHEDULED",
]
r"""Type of the job run"""


GetJobRunsStatus = Literal[
    "CANCELED",
    "PENDING",
    "PAUSED",
    "PAUSING",
    "RESUMING",
    "SUCCESS",
    "FAILURE",
    "TERMINATED",
    "COMPLETED",
]
r"""Current status of the job run"""


GetJobRunsJobRunCode = Literal[
    "internal-server-error",
    "insufficient-resource-credits",
]
r"""Optional error code for more specific error identification"""


GetJobRunsJobRunCategory = Literal[
    "billing",
    "infrastructure",
]


class GetJobRunsErrorTypedDict(TypedDict):
    r"""Error information if the job run failed, stored as JSONB"""

    message: str
    r"""Error message describing the failure"""
    code: GetJobRunsJobRunCode
    r"""Optional error code for more specific error identification"""
    category: GetJobRunsJobRunCategory
    details: NotRequired[Any]
    correlation_id: NotRequired[str]
    r"""Optional correlation ID for tracking the error"""
    retirable: NotRequired[bool]
    doc_url: NotRequired[str]
    r"""Optional documentation URL for more information"""


class GetJobRunsError(BaseModel):
    r"""Error information if the job run failed, stored as JSONB"""

    message: str
    r"""Error message describing the failure"""

    code: GetJobRunsJobRunCode
    r"""Optional error code for more specific error identification"""

    category: GetJobRunsJobRunCategory

    details: Optional[Any] = None

    correlation_id: Annotated[Optional[str], pydantic.Field(alias="correlationId")] = (
        None
    )
    r"""Optional correlation ID for tracking the error"""

    retirable: Optional[bool] = False

    doc_url: Optional[str] = None
    r"""Optional documentation URL for more information"""


GetJobRunsReasonType = Literal[
    "terminated",
    "user-request",
    "auth-session-not-found",
    "auth-session-invalid-mid-job",
    "auth-session-validate-dependency-failed",
    "auth-session-locked",
    "another-job-run-active",
    "insufficient-resource-credits",
    "s3-sink-error",
]


class GetJobRunsReasonTypedDict(TypedDict):
    r"""Reason for job run  state change, stored as JSONB"""

    type: GetJobRunsReasonType
    message: str
    details: NotRequired[Any]
    doc_url: NotRequired[str]
    r"""Optional documentation URL for more information"""


class GetJobRunsReason(BaseModel):
    r"""Reason for job run  state change, stored as JSONB"""

    type: GetJobRunsReasonType

    message: str

    details: Optional[Any] = None

    doc_url: Optional[str] = None
    r"""Optional documentation URL for more information"""


class GetJobRunsRetryTypedDict(TypedDict):
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    maximum_attempts: NotRequired[int]
    r"""Maximum number of attempts to retry the run in case of failure"""


class GetJobRunsRetry(BaseModel):
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    maximum_attempts: Annotated[
        Optional[int], pydantic.Field(alias="maximumAttempts")
    ] = 3
    r"""Maximum number of attempts to retry the run in case of failure"""


class GetJobRunsConfigurationTypedDict(TypedDict):
    r"""Job configuration settings"""

    retry: NotRequired[GetJobRunsRetryTypedDict]
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""
    max_concurrent_requests: NotRequired[float]
    r"""The batch size of payloads to execute. This does not guarantee that the payloads will be executed at the same time."""
    request_timeout: NotRequired[int]
    r"""Timeout for the API request in seconds. Default is 10 minutes (600 seconds)."""


class GetJobRunsConfiguration(BaseModel):
    r"""Job configuration settings"""

    retry: Optional[GetJobRunsRetry] = None
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    max_concurrent_requests: Annotated[
        Optional[float], pydantic.Field(alias="maxConcurrentRequests")
    ] = None
    r"""The batch size of payloads to execute. This does not guarantee that the payloads will be executed at the same time."""

    request_timeout: Annotated[
        Optional[int], pydantic.Field(alias="requestTimeout")
    ] = 600
    r"""Timeout for the API request in seconds. Default is 10 minutes (600 seconds)."""


GetJobRunsTypeS3 = Literal["s3",]


class GetJobRunsS3SinkConfigurationTypedDict(TypedDict):
    r"""Configuration for the S3 sink."""

    type: GetJobRunsTypeS3
    bucket: str
    r"""The name of the S3 bucket where the data will be stored."""
    access_key_id: str
    r"""The access key ID for the S3 bucket."""
    secret_access_key: str
    r"""The secret access key for the S3 bucket."""
    region: str
    r"""The region where the S3 bucket is located."""
    prefix: NotRequired[str]
    r"""Optional prefix for the S3 objects. This can be used to organize objects within the bucket."""
    skip_on_fail: NotRequired[bool]
    r"""If enabled, failed payload runs will ***not*** be written to the bucket."""
    apis_to_send: NotRequired[List[str]]
    r"""List of API names to be sent to the S3 bucket. If not provided, all APIs will be sent."""
    endpoint: NotRequired[str]
    r"""Optional custom endpoint for the S3 bucket. This can be used for S3-compatible services."""
    force_path_style: NotRequired[bool]
    r"""If true, the S3 client will use path-style URLs instead of virtual-hosted-style URLs. This is useful for S3-compatible services that require path-style access."""


class GetJobRunsS3SinkConfiguration(BaseModel):
    r"""Configuration for the S3 sink."""

    type: GetJobRunsTypeS3

    bucket: str
    r"""The name of the S3 bucket where the data will be stored."""

    access_key_id: Annotated[str, pydantic.Field(alias="accessKeyId")]
    r"""The access key ID for the S3 bucket."""

    secret_access_key: Annotated[str, pydantic.Field(alias="secretAccessKey")]
    r"""The secret access key for the S3 bucket."""

    region: str
    r"""The region where the S3 bucket is located."""

    prefix: Optional[str] = None
    r"""Optional prefix for the S3 objects. This can be used to organize objects within the bucket."""

    skip_on_fail: Annotated[Optional[bool], pydantic.Field(alias="skipOnFail")] = False
    r"""If enabled, failed payload runs will ***not*** be written to the bucket."""

    apis_to_send: Annotated[Optional[List[str]], pydantic.Field(alias="apisToSend")] = (
        None
    )
    r"""List of API names to be sent to the S3 bucket. If not provided, all APIs will be sent."""

    endpoint: Optional[str] = None
    r"""Optional custom endpoint for the S3 bucket. This can be used for S3-compatible services."""

    force_path_style: Annotated[
        Optional[bool], pydantic.Field(alias="forcePathStyle")
    ] = None
    r"""If true, the S3 client will use path-style URLs instead of virtual-hosted-style URLs. This is useful for S3-compatible services that require path-style access."""


GetJobRunsTypeWebhook = Literal["webhook",]


class GetJobRunsWebhookSinkConfigurationTypedDict(TypedDict):
    r"""Configuration for the webhook sink."""

    type: GetJobRunsTypeWebhook
    url: str
    r"""The URL to which the webhook will send the data."""
    headers: NotRequired[Dict[str, str]]
    r"""Optional headers to be sent with the webhook request."""
    skip_on_fail: NotRequired[bool]
    r"""If true, the webhook will not be sent if the API execution fails."""
    apis_to_send: NotRequired[List[str]]
    r"""List of API names to be sent to the webhook. If not provided, all APIs will be sent."""


class GetJobRunsWebhookSinkConfiguration(BaseModel):
    r"""Configuration for the webhook sink."""

    type: GetJobRunsTypeWebhook

    url: str
    r"""The URL to which the webhook will send the data."""

    headers: Optional[Dict[str, str]] = None
    r"""Optional headers to be sent with the webhook request."""

    skip_on_fail: Annotated[Optional[bool], pydantic.Field(alias="skipOnFail")] = False
    r"""If true, the webhook will not be sent if the API execution fails."""

    apis_to_send: Annotated[Optional[List[str]], pydantic.Field(alias="apisToSend")] = (
        None
    )
    r"""List of API names to be sent to the webhook. If not provided, all APIs will be sent."""


GetJobRunsSinkTypedDict = TypeAliasType(
    "GetJobRunsSinkTypedDict",
    Union[
        GetJobRunsWebhookSinkConfigurationTypedDict,
        GetJobRunsS3SinkConfigurationTypedDict,
    ],
)
r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""


GetJobRunsSink = TypeAliasType(
    "GetJobRunsSink",
    Union[GetJobRunsWebhookSinkConfiguration, GetJobRunsS3SinkConfiguration],
)
r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""


class GetJobRunsAuthSessionTypedDict(TypedDict):
    r"""Authentication session information for the job"""

    id: str
    check_attempts: NotRequired[int]
    r"""Number of attempts to check the validity of the auth session before recreating it."""
    create_attempts: NotRequired[int]
    r"""Number of attempts to create a new auth session if the current one is invalid or expired."""


class GetJobRunsAuthSession(BaseModel):
    r"""Authentication session information for the job"""

    id: str

    check_attempts: Annotated[Optional[int], pydantic.Field(alias="checkAttempts")] = 3
    r"""Number of attempts to check the validity of the auth session before recreating it."""

    create_attempts: Annotated[
        Optional[int], pydantic.Field(alias="createAttempts")
    ] = 3
    r"""Number of attempts to create a new auth session if the current one is invalid or expired."""


GetJobRunsVersion = Literal["v1",]


class GetJobRunsProxyTypedDict(TypedDict):
    r"""Proxy configuration for the job, stored as JSONB"""

    version: GetJobRunsVersion
    url: str


class GetJobRunsProxy(BaseModel):
    r"""Proxy configuration for the job, stored as JSONB"""

    version: GetJobRunsVersion

    url: str


class GetJobRunsJobConfigurationSnapshotTypedDict(TypedDict):
    r"""Snapshot of job configuration at the time of the job run"""

    configuration: GetJobRunsConfigurationTypedDict
    r"""Job configuration settings"""
    sink: NotRequired[Nullable[GetJobRunsSinkTypedDict]]
    r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""
    auth_session: NotRequired[Nullable[GetJobRunsAuthSessionTypedDict]]
    r"""Authentication session information for the job"""
    proxy: NotRequired[Nullable[GetJobRunsProxyTypedDict]]
    r"""Proxy configuration for the job, stored as JSONB"""


class GetJobRunsJobConfigurationSnapshot(BaseModel):
    r"""Snapshot of job configuration at the time of the job run"""

    configuration: GetJobRunsConfiguration
    r"""Job configuration settings"""

    sink: OptionalNullable[GetJobRunsSink] = UNSET
    r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""

    auth_session: OptionalNullable[GetJobRunsAuthSession] = UNSET
    r"""Authentication session information for the job"""

    proxy: OptionalNullable[GetJobRunsProxy] = UNSET
    r"""Proxy configuration for the job, stored as JSONB"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["sink", "auth_session", "proxy"]
        nullable_fields = ["sink", "auth_session", "proxy"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class GetJobRunsJobRunTypedDict(TypedDict):
    id: str
    r"""Unique identifier for the job run"""
    start_time: str
    r"""Timestamp when the job run started"""
    end_time: Nullable[str]
    r"""Timestamp when the job run ended (null if still running)"""
    workspace_id: str
    r"""UUID of the workspace this job run belongs to"""
    project_id: str
    r"""UUID of the project this job run belongs to"""
    job_id: str
    r"""ID of the job this run belongs to"""
    created_at: str
    r"""Timestamp when the job run was created"""
    updated_at: str
    r"""Timestamp when the job run was last updated"""
    type: GetJobRunsType
    r"""Type of the job run"""
    status: GetJobRunsStatus
    r"""Current status of the job run"""
    payloads: Nullable[int]
    r"""Total number of payloads in the job run"""
    successful_runs: Nullable[int]
    r"""Number of successful API calls in the job run"""
    failed_runs: Nullable[int]
    r"""Number of failed API calls in the job run"""
    job_configuration_snapshot: GetJobRunsJobConfigurationSnapshotTypedDict
    r"""Snapshot of job configuration at the time of the job run"""
    error: NotRequired[Nullable[GetJobRunsErrorTypedDict]]
    r"""Error information if the job run failed, stored as JSONB"""
    reason: NotRequired[Nullable[GetJobRunsReasonTypedDict]]
    r"""Reason for job run  state change, stored as JSONB"""


class GetJobRunsJobRun(BaseModel):
    id: str
    r"""Unique identifier for the job run"""

    start_time: str
    r"""Timestamp when the job run started"""

    end_time: Nullable[str]
    r"""Timestamp when the job run ended (null if still running)"""

    workspace_id: str
    r"""UUID of the workspace this job run belongs to"""

    project_id: str
    r"""UUID of the project this job run belongs to"""

    job_id: str
    r"""ID of the job this run belongs to"""

    created_at: str
    r"""Timestamp when the job run was created"""

    updated_at: str
    r"""Timestamp when the job run was last updated"""

    type: GetJobRunsType
    r"""Type of the job run"""

    status: GetJobRunsStatus
    r"""Current status of the job run"""

    payloads: Nullable[int]
    r"""Total number of payloads in the job run"""

    successful_runs: Nullable[int]
    r"""Number of successful API calls in the job run"""

    failed_runs: Nullable[int]
    r"""Number of failed API calls in the job run"""

    job_configuration_snapshot: GetJobRunsJobConfigurationSnapshot
    r"""Snapshot of job configuration at the time of the job run"""

    error: OptionalNullable[GetJobRunsError] = UNSET
    r"""Error information if the job run failed, stored as JSONB"""

    reason: OptionalNullable[GetJobRunsReason] = UNSET
    r"""Reason for job run  state change, stored as JSONB"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["error", "reason"]
        nullable_fields = [
            "end_time",
            "payloads",
            "successful_runs",
            "failed_runs",
            "error",
            "reason",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class GetJobRunsResponseTypedDict(TypedDict):
    r"""Array of job runs with pagination info"""

    job_runs: List[GetJobRunsJobRunTypedDict]
    total_count: int
    r"""Total number of job runs available"""


class GetJobRunsResponse(BaseModel):
    r"""Array of job runs with pagination info"""

    job_runs: Annotated[List[GetJobRunsJobRun], pydantic.Field(alias="jobRuns")]

    total_count: Annotated[int, pydantic.Field(alias="totalCount")]
    r"""Total number of job runs available"""

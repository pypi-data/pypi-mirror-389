"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from intuned_client.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from intuned_client.utils import FieldMetadata, PathParamMetadata
import pydantic
from pydantic import model_serializer
from typing import Any, Dict, List, Literal, Optional, Union
from typing_extensions import Annotated, NotRequired, TypeAliasType, TypedDict


class GetJobRunGlobalsTypedDict(TypedDict):
    workspace_id: NotRequired[str]
    r"""Your workspace ID. [How to find it](/docs/guides/general/how-to-get-a-workspace-id)?"""


class GetJobRunGlobals(BaseModel):
    workspace_id: Annotated[
        Optional[str],
        pydantic.Field(alias="workspaceId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ] = None
    r"""Your workspace ID. [How to find it](/docs/guides/general/how-to-get-a-workspace-id)?"""


class GetJobRunRequestTypedDict(TypedDict):
    project_name: str
    r"""Your project name. It is the name you provide when creating a project."""
    job_id: str
    r"""Your job ID. It is the ID of the job you provide when creating it."""
    job_run_id: str
    r"""The job run ID. This can be obtained from the get job runs endpoint or from the result of the trigger endpoint for a job."""


class GetJobRunRequest(BaseModel):
    project_name: Annotated[
        str,
        pydantic.Field(alias="projectName"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""Your project name. It is the name you provide when creating a project."""

    job_id: Annotated[
        str,
        pydantic.Field(alias="jobId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""Your job ID. It is the ID of the job you provide when creating it."""

    job_run_id: Annotated[
        str,
        pydantic.Field(alias="jobRunId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""The job run ID. This can be obtained from the get job runs endpoint or from the result of the trigger endpoint for a job."""


GetJobRunNotFoundCode = Literal["not-found",]
r"""The requested resource was not found
https://docs.intunedhq.com/docs/support/errors#not-found - Find more info here
"""


GetJobRunNotFoundCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunUnauthorizedCode = Literal["unauthorized",]
r"""The request requires user authentication
https://docs.intunedhq.com/docs/support/errors#unauthorized - Find more info here
"""


GetJobRunUnauthorizedCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunBadRequestCode = Literal["bad-request",]
r"""The request is invalid or malformed
https://docs.intunedhq.com/docs/support/errors#bad-request - Find more info here
"""


GetJobRunBadRequestCategory = Literal["user",]
r"""Errors caused by user actions or input
https://docs.intunedhq.com/docs/support/errors#user - Find more info here
"""


GetJobRunType = Literal[
    "MANUAL",
    "SCHEDULED",
]
r"""Type of the job run"""


GetJobRunStatus = Literal[
    "CANCELED",
    "PENDING",
    "PAUSED",
    "PAUSING",
    "RESUMING",
    "SUCCESS",
    "FAILURE",
    "TERMINATED",
    "COMPLETED",
]
r"""Current status of the job run"""


GetJobRunJobRunCode = Literal[
    "internal-server-error",
    "insufficient-resource-credits",
]
r"""Optional error code for more specific error identification"""


GetJobRunJobRunCategory = Literal[
    "billing",
    "infrastructure",
]


class GetJobRunErrorTypedDict(TypedDict):
    r"""Error information if the job run failed, stored as JSONB"""

    message: str
    r"""Error message describing the failure"""
    code: GetJobRunJobRunCode
    r"""Optional error code for more specific error identification"""
    category: GetJobRunJobRunCategory
    details: NotRequired[Any]
    correlation_id: NotRequired[str]
    r"""Optional correlation ID for tracking the error"""
    retirable: NotRequired[bool]
    doc_url: NotRequired[str]
    r"""Optional documentation URL for more information"""


class GetJobRunError(BaseModel):
    r"""Error information if the job run failed, stored as JSONB"""

    message: str
    r"""Error message describing the failure"""

    code: GetJobRunJobRunCode
    r"""Optional error code for more specific error identification"""

    category: GetJobRunJobRunCategory

    details: Optional[Any] = None

    correlation_id: Annotated[Optional[str], pydantic.Field(alias="correlationId")] = (
        None
    )
    r"""Optional correlation ID for tracking the error"""

    retirable: Optional[bool] = False

    doc_url: Optional[str] = None
    r"""Optional documentation URL for more information"""


GetJobRunReasonType = Literal[
    "terminated",
    "user-request",
    "auth-session-not-found",
    "auth-session-invalid-mid-job",
    "auth-session-validate-dependency-failed",
    "auth-session-locked",
    "another-job-run-active",
    "insufficient-resource-credits",
    "s3-sink-error",
]


class GetJobRunReasonTypedDict(TypedDict):
    r"""Reason for job run  state change, stored as JSONB"""

    type: GetJobRunReasonType
    message: str
    details: NotRequired[Any]
    doc_url: NotRequired[str]
    r"""Optional documentation URL for more information"""


class GetJobRunReason(BaseModel):
    r"""Reason for job run  state change, stored as JSONB"""

    type: GetJobRunReasonType

    message: str

    details: Optional[Any] = None

    doc_url: Optional[str] = None
    r"""Optional documentation URL for more information"""


class GetJobRunRetryTypedDict(TypedDict):
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    maximum_attempts: NotRequired[int]
    r"""Maximum number of attempts to retry the run in case of failure"""


class GetJobRunRetry(BaseModel):
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    maximum_attempts: Annotated[
        Optional[int], pydantic.Field(alias="maximumAttempts")
    ] = 3
    r"""Maximum number of attempts to retry the run in case of failure"""


class GetJobRunConfigurationTypedDict(TypedDict):
    r"""Job configuration settings"""

    retry: NotRequired[GetJobRunRetryTypedDict]
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""
    max_concurrent_requests: NotRequired[float]
    r"""The batch size of payloads to execute. This does not guarantee that the payloads will be executed at the same time."""
    request_timeout: NotRequired[int]
    r"""Timeout for the API request in seconds. Default is 10 minutes (600 seconds)."""


class GetJobRunConfiguration(BaseModel):
    r"""Job configuration settings"""

    retry: Optional[GetJobRunRetry] = None
    r"""The retry policy of the job. Configure how many retries and the delay between them for each payload."""

    max_concurrent_requests: Annotated[
        Optional[float], pydantic.Field(alias="maxConcurrentRequests")
    ] = None
    r"""The batch size of payloads to execute. This does not guarantee that the payloads will be executed at the same time."""

    request_timeout: Annotated[
        Optional[int], pydantic.Field(alias="requestTimeout")
    ] = 600
    r"""Timeout for the API request in seconds. Default is 10 minutes (600 seconds)."""


GetJobRunTypeS3 = Literal["s3",]


class GetJobRunS3SinkConfigurationTypedDict(TypedDict):
    r"""Configuration for the S3 sink."""

    type: GetJobRunTypeS3
    bucket: str
    r"""The name of the S3 bucket where the data will be stored."""
    access_key_id: str
    r"""The access key ID for the S3 bucket."""
    secret_access_key: str
    r"""The secret access key for the S3 bucket."""
    region: str
    r"""The region where the S3 bucket is located."""
    prefix: NotRequired[str]
    r"""Optional prefix for the S3 objects. This can be used to organize objects within the bucket."""
    skip_on_fail: NotRequired[bool]
    r"""If enabled, failed payload runs will ***not*** be written to the bucket."""
    apis_to_send: NotRequired[List[str]]
    r"""List of API names to be sent to the S3 bucket. If not provided, all APIs will be sent."""
    endpoint: NotRequired[str]
    r"""Optional custom endpoint for the S3 bucket. This can be used for S3-compatible services."""
    force_path_style: NotRequired[bool]
    r"""If true, the S3 client will use path-style URLs instead of virtual-hosted-style URLs. This is useful for S3-compatible services that require path-style access."""


class GetJobRunS3SinkConfiguration(BaseModel):
    r"""Configuration for the S3 sink."""

    type: GetJobRunTypeS3

    bucket: str
    r"""The name of the S3 bucket where the data will be stored."""

    access_key_id: Annotated[str, pydantic.Field(alias="accessKeyId")]
    r"""The access key ID for the S3 bucket."""

    secret_access_key: Annotated[str, pydantic.Field(alias="secretAccessKey")]
    r"""The secret access key for the S3 bucket."""

    region: str
    r"""The region where the S3 bucket is located."""

    prefix: Optional[str] = None
    r"""Optional prefix for the S3 objects. This can be used to organize objects within the bucket."""

    skip_on_fail: Annotated[Optional[bool], pydantic.Field(alias="skipOnFail")] = False
    r"""If enabled, failed payload runs will ***not*** be written to the bucket."""

    apis_to_send: Annotated[Optional[List[str]], pydantic.Field(alias="apisToSend")] = (
        None
    )
    r"""List of API names to be sent to the S3 bucket. If not provided, all APIs will be sent."""

    endpoint: Optional[str] = None
    r"""Optional custom endpoint for the S3 bucket. This can be used for S3-compatible services."""

    force_path_style: Annotated[
        Optional[bool], pydantic.Field(alias="forcePathStyle")
    ] = None
    r"""If true, the S3 client will use path-style URLs instead of virtual-hosted-style URLs. This is useful for S3-compatible services that require path-style access."""


GetJobRunTypeWebhook = Literal["webhook",]


class GetJobRunWebhookSinkConfigurationTypedDict(TypedDict):
    r"""Configuration for the webhook sink."""

    type: GetJobRunTypeWebhook
    url: str
    r"""The URL to which the webhook will send the data."""
    headers: NotRequired[Dict[str, str]]
    r"""Optional headers to be sent with the webhook request."""
    skip_on_fail: NotRequired[bool]
    r"""If true, the webhook will not be sent if the API execution fails."""
    apis_to_send: NotRequired[List[str]]
    r"""List of API names to be sent to the webhook. If not provided, all APIs will be sent."""


class GetJobRunWebhookSinkConfiguration(BaseModel):
    r"""Configuration for the webhook sink."""

    type: GetJobRunTypeWebhook

    url: str
    r"""The URL to which the webhook will send the data."""

    headers: Optional[Dict[str, str]] = None
    r"""Optional headers to be sent with the webhook request."""

    skip_on_fail: Annotated[Optional[bool], pydantic.Field(alias="skipOnFail")] = False
    r"""If true, the webhook will not be sent if the API execution fails."""

    apis_to_send: Annotated[Optional[List[str]], pydantic.Field(alias="apisToSend")] = (
        None
    )
    r"""List of API names to be sent to the webhook. If not provided, all APIs will be sent."""


GetJobRunSinkTypedDict = TypeAliasType(
    "GetJobRunSinkTypedDict",
    Union[
        GetJobRunWebhookSinkConfigurationTypedDict,
        GetJobRunS3SinkConfigurationTypedDict,
    ],
)
r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""


GetJobRunSink = TypeAliasType(
    "GetJobRunSink",
    Union[GetJobRunWebhookSinkConfiguration, GetJobRunS3SinkConfiguration],
)
r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""


class GetJobRunAuthSessionTypedDict(TypedDict):
    r"""Authentication session information for the job"""

    id: str
    check_attempts: NotRequired[int]
    r"""Number of attempts to check the validity of the auth session before recreating it."""
    create_attempts: NotRequired[int]
    r"""Number of attempts to create a new auth session if the current one is invalid or expired."""


class GetJobRunAuthSession(BaseModel):
    r"""Authentication session information for the job"""

    id: str

    check_attempts: Annotated[Optional[int], pydantic.Field(alias="checkAttempts")] = 3
    r"""Number of attempts to check the validity of the auth session before recreating it."""

    create_attempts: Annotated[
        Optional[int], pydantic.Field(alias="createAttempts")
    ] = 3
    r"""Number of attempts to create a new auth session if the current one is invalid or expired."""


GetJobRunVersion = Literal["v1",]


class GetJobRunProxyTypedDict(TypedDict):
    r"""Proxy configuration for the job, stored as JSONB"""

    version: GetJobRunVersion
    url: str


class GetJobRunProxy(BaseModel):
    r"""Proxy configuration for the job, stored as JSONB"""

    version: GetJobRunVersion

    url: str


class GetJobRunJobConfigurationSnapshotTypedDict(TypedDict):
    r"""Snapshot of job configuration at the time of the job run"""

    configuration: GetJobRunConfigurationTypedDict
    r"""Job configuration settings"""
    sink: NotRequired[Nullable[GetJobRunSinkTypedDict]]
    r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""
    auth_session: NotRequired[Nullable[GetJobRunAuthSessionTypedDict]]
    r"""Authentication session information for the job"""
    proxy: NotRequired[Nullable[GetJobRunProxyTypedDict]]
    r"""Proxy configuration for the job, stored as JSONB"""


class GetJobRunJobConfigurationSnapshot(BaseModel):
    r"""Snapshot of job configuration at the time of the job run"""

    configuration: GetJobRunConfiguration
    r"""Job configuration settings"""

    sink: OptionalNullable[GetJobRunSink] = UNSET
    r"""Optional sink configuration for the job. Can be a webhook or S3 Compatible sink."""

    auth_session: OptionalNullable[GetJobRunAuthSession] = UNSET
    r"""Authentication session information for the job"""

    proxy: OptionalNullable[GetJobRunProxy] = UNSET
    r"""Proxy configuration for the job, stored as JSONB"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["sink", "auth_session", "proxy"]
        nullable_fields = ["sink", "auth_session", "proxy"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class GetJobRunJobRunTypedDict(TypedDict):
    id: str
    r"""Unique identifier for the job run"""
    start_time: str
    r"""Timestamp when the job run started"""
    end_time: Nullable[str]
    r"""Timestamp when the job run ended (null if still running)"""
    workspace_id: str
    r"""UUID of the workspace this job run belongs to"""
    project_id: str
    r"""UUID of the project this job run belongs to"""
    job_id: str
    r"""ID of the job this run belongs to"""
    created_at: str
    r"""Timestamp when the job run was created"""
    updated_at: str
    r"""Timestamp when the job run was last updated"""
    type: GetJobRunType
    r"""Type of the job run"""
    status: GetJobRunStatus
    r"""Current status of the job run"""
    payloads: Nullable[int]
    r"""Total number of payloads in the job run"""
    successful_runs: Nullable[int]
    r"""Number of successful API calls in the job run"""
    failed_runs: Nullable[int]
    r"""Number of failed API calls in the job run"""
    job_configuration_snapshot: GetJobRunJobConfigurationSnapshotTypedDict
    r"""Snapshot of job configuration at the time of the job run"""
    error: NotRequired[Nullable[GetJobRunErrorTypedDict]]
    r"""Error information if the job run failed, stored as JSONB"""
    reason: NotRequired[Nullable[GetJobRunReasonTypedDict]]
    r"""Reason for job run  state change, stored as JSONB"""


class GetJobRunJobRun(BaseModel):
    id: str
    r"""Unique identifier for the job run"""

    start_time: str
    r"""Timestamp when the job run started"""

    end_time: Nullable[str]
    r"""Timestamp when the job run ended (null if still running)"""

    workspace_id: str
    r"""UUID of the workspace this job run belongs to"""

    project_id: str
    r"""UUID of the project this job run belongs to"""

    job_id: str
    r"""ID of the job this run belongs to"""

    created_at: str
    r"""Timestamp when the job run was created"""

    updated_at: str
    r"""Timestamp when the job run was last updated"""

    type: GetJobRunType
    r"""Type of the job run"""

    status: GetJobRunStatus
    r"""Current status of the job run"""

    payloads: Nullable[int]
    r"""Total number of payloads in the job run"""

    successful_runs: Nullable[int]
    r"""Number of successful API calls in the job run"""

    failed_runs: Nullable[int]
    r"""Number of failed API calls in the job run"""

    job_configuration_snapshot: GetJobRunJobConfigurationSnapshot
    r"""Snapshot of job configuration at the time of the job run"""

    error: OptionalNullable[GetJobRunError] = UNSET
    r"""Error information if the job run failed, stored as JSONB"""

    reason: OptionalNullable[GetJobRunReason] = UNSET
    r"""Reason for job run  state change, stored as JSONB"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["error", "reason"]
        nullable_fields = [
            "end_time",
            "payloads",
            "successful_runs",
            "failed_runs",
            "error",
            "reason",
        ]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


class ResultsTypedDict(TypedDict):
    signed_url: str
    format_: str
    signed_url_expiration: NotRequired[str]
    size: NotRequired[float]
    key: NotRequired[str]


class Results(BaseModel):
    signed_url: str

    format_: Annotated[str, pydantic.Field(alias="format")]

    signed_url_expiration: Optional[str] = None

    size: Optional[float] = None

    key: Optional[str] = None


class GetJobRunResponseTypedDict(TypedDict):
    r"""Job run information and results"""

    job_run: GetJobRunJobRunTypedDict
    results: NotRequired[ResultsTypedDict]


class GetJobRunResponse(BaseModel):
    r"""Job run information and results"""

    job_run: Annotated[GetJobRunJobRun, pydantic.Field(alias="jobRun")]

    results: Optional[Results] = None

/******************************************************************************
Â© 2012-2025 ANSYS, Inc. All rights reserved. Unauthorized use, distribution, or
  duplication is prohibited.
THIS ANSYS SOFTWARE PRODUCT AND PROGRAM DOCUMENTATION INCLUDE TRADE SECRETS AND
ARE CONFIDENTIAL AND PROPRIETARY PRODUCTS OF ANSYS, INC., ITS SUBSIDIARIES, OR 
LICENSORS. The software products and documentation are furnished by ANSYS, 
Inc., its subsidiaries, or affiliates under a software license agreement that 
contains provisions concerning non-disclosure, copying, length and nature of 
use, compliance with exporting laws, warranties, disclaimers, limitations of 
liability, and remedies, and other provisions.  The software products and 
documentation may be used, disclosed, transferred, or copied only in accordance 
with the terms and conditions of that software license agreement.
******************************************************************************/
/**
*
* This file describes the sensor data formats and types used in notifications 
* and request messages.
*/
syntax = "proto3";

package ansys.api.avxcelerate.sensors.v1;

// The possible file formats and data types of the data produced by a camera.
//
// The data types correspond to the types of image (irradiance map, temperature 
// map, etc.) and are only used to describe images stored in shared memory.
//
// The file formats correspond to the file format of the images 
// (e.g. bmp, gif) and are only used to write images to disk. These data 
// formats are therefore not available for storing data in shared memory.
//
enum CameraDataFormat {
  // Undefined value (default value will apply).
  //
  UNDEFINED_CAMERA_FORMAT = 0;
  
  // RAW format (default).
  //
  // Note: Can be used for dumping images or describing images stored in 
  // shared memory.
  //
  RAW = 1;
  
  // BMP file format.
  //
  BMP = 2;
  
  // GIF file format.
  //
  GIF = 3;
  
  // JPEG file format.
  //
  JPEG = 4;
  
  // PNG file format.
  //
  PNG = 5;
  
  // Temperature map (data type for thermal camera output).
  //
  TEMPERATURE_MAP = 6;

  // Spectral irradiance map (data type for camera lens output).
  //
  SPECTRAL_IRRADIANCE_MAP = 7;
    
  // Custom data (data type for custom GPU post-processing).
  //
  CUSTOM_DATA = 8;
}

// The possible pixel formats of the data generated by a camera.
//
// This format describes the type of data stored (byte or float) as well as 
// how the data is arranged.
//
// Note: In addition to the usages mentioned below, 
// each pixel format is possible for the output of a camera with 
// custom post-processing, based on the Custom Output Format 
// defined in the camera model.
//
enum PixelFormat {
  // Undefined value (default value will apply).
  //
  UNDEFINED_PIXEL_FORMAT = 0;
  
  // Rgba32 represents the sRGB format with an alpha channel and 32 bits per 
  // pixel. Each channel (red, green, blue, and alpha) is assigned 8 bits per 
  // pixel. (This is the default value.)
  //
  // Format used for Camera Output (Image) and Imager Output (Injection) 
  // when alpha channel is enabled in the simulation parameters.
  //
  RGBA32 = 1;

  // Rgb24 represents the sRGB format with 24 bits per pixel. Each channel 
  // (red, green, blue) is assigned 8 bits per pixel.
  //
  // Format used for Camera Output (Image) and Imager Output (Injection) 
  // when alpha channel is disabled in the simulation parameters, as well as 
  // for ground truth pixel segmentation output.
  //
  RGB24 = 3;
  
  // Gray8 pixel format which displays one grayscale channel with 8 bits per 
  // pixel, allowing 256 shades of gray.
  //
  // Format used for thermal camera image output.
  //
  GRAY8 = 2;
  
  // The Float32 pixel format represents a float channel with 32 bits per 
  // pixel. 
  //
  // Format used for thermal camera temperature map output and ground 
  // truth depth map output.
  //
  FLOAT32 = 4;
  
  // The Float64 pixel format represents 2 channels of floating point numbers 
  // with 32 bits per pixel. Each channel is assigned 32 bits per pixel.
  //
  // Format used for ground truth optical flow output.
  //
  FLOAT64 = 5;
  
  // The Float128 pixel format represents 4 channels of floating point numbers 
  // with 32 bits per pixel. Each channel is assigned 32 bits per pixel.
  //
  // Format used for Lens Output (Light).
  //
  FLOAT128 = 6;
}

// The possible data formats for lidar sensors' output.
//
enum LidarDataFormat {
  // Undefined value (default value will apply).
  //
  UNDEFINED_LIDAR_FORMAT = 0;
  
  // Point cloud data format (default value).
  //
  POINT_CLOUD = 1;
  
  // Waveform data format.
  //
  WAVEFORM = 2;
  
  // Contributions data format.
  //
  CONTRIBUTIONS = 3;

  // Lens output data format.
  //
  LENS_OUTPUT = 4;
}

// The possible data formats for radar sensors' output.
//
enum RadarDataFormat {
  // Undefined value (default will apply).
  //
  UNDEFINED_RADAR_FORMAT = 0;
  
  // Full radar output (default).
  //
  RADAR_OUTPUT = 1;
  
  // Range doppler data format.
  //
  RANGE_DOPPLER = 2;
  
  // Frequency pulse data format.
  //
  FREQUENCY_PULSE = 3;
  
  // Digital sample data format.
  //
  DIGITAL_SAMPLES = 4;
}

// The possible recording formats available for radar and lidar 
// sensors' output.
//
enum OutputFormat {
  // Undefined value (default will apply).
  //
  UNDEFINED = 0;
  
  // Text format (default).
  //
  TEXT = 1;
  
  // Protobuf format.
  //
  PROTOBUF = 2;
}

// The possible recording formats available for Ground Truth data.
//
enum CameraGroundTruthDataFormat {
  // Undefined value.
  //
  UNDEFINED_GROUND_TRUTH_FORMAT = 0;
  
  // Depth map format.
  // Represented by a byte array of 32 bits per pixel (RGBA image).
  //
  DEPTH_MAP = 1;
  
  // Optical flow format.
  // Represented by a byte array of 2 x 32 bits per pixel (horizontal speed 
  // first, then vertical speed).
  //
  OPTICAL_FLOW = 2;
  
  // Pixel Segmentation format.
  // Represented by a byte array of 24 bits per pixel (RGB image).
  //
  PIXEL_SEGMENTATION = 3;
}
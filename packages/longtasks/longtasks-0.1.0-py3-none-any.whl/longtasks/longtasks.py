# -*- coding:utf-8 -*-
import asyncio
import aioredis
from random import randint
import json
import time
from typing import Any, Dict
from appPublic.worker import get_event_loop, schedule_interval, schedule_once
from appPublic.uniqueID import getID
from appPublic.log import debug, exception

class LongTasks:
	def __init__(self, redis_url, taskname, worker_cnt=2, stuck_seconds=600, max_age_hours=3):
		self.redis_url = redis_url
		self.worker_cnt = worker_cnt
		self.taskname = taskname
		self.max_age_seconds = max_age_hours * 3600
		self.task_queue = f'{taskname}_pending'
		self.processing_queue = f'{taskname}_processing'
		self.stuck_seconds = stuck_seconds
		self.redis = None
	
	async def repush_pending_task(self):
		async for key in self.redis.scan_iter(match=f"{self.taskname}:task:*"):
			task = await self.redis.hgetall(key)
			if task['status'] == 'PENDING':
				jstr = json.dumps({
					"task_id": task['task_id'],
					"payload": json.loads(task['payload'])
				})
				await self.redis.rpush(self.task_queue, jstr)
				debug(f'{jstr=}, {self.task_queue=}')
		
	async def cleanup_expired_tasks(self):
		"""æ¸…ç†è¶…è¿‡ max_age_hours çš„ä»»åŠ¡"""
		now = time.time()
		debug('cleanup_expired_tasks() called ...')
		async for key in self.redis.scan_iter(match=f"{self.taskname}:task:*"):
			taskid = key.split(':')[-1]
			task = await self.redis.hgetall(key)
			if not task:
				debug(f'{key} task not found')
				await self.redis.delete(key)
				await self.redis.lrem(self.task_queue, 0, key)  # ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆå¯é€‰ï¼‰
				continue

			created_at = task.get("created_at")
			if not created_at:
				await self.redis.delete(key)
				await self.redis.lrem(self.task_queue, 0, key)  # ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆå¯é€‰ï¼‰
				await self.delete_redis_task(taskid)
				debug(f'{key}, {task} no created_at key')
				continue

			created_at = float(created_at)
			if created_at + self.max_age_seconds < now:
				debug(f"ğŸ§¹ åˆ é™¤è¿‡æœŸä»»åŠ¡: {key}, {task}")
				await self.redis.delete(key)
				await self.redis.lrem(self.task_queue, 0, key)  # ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆå¯é€‰ï¼‰
			status = task.get('status')
			if status not in ['SUCCEEDED', 'FAILED', 'RUNNING', 'PENDING']:
				debug(f"ğŸ§¹ åˆ é™¤ä»»åŠ¡: {key}, {task}")
				await self.redis.delete(key)
				await self.redis.lrem(self.task_queue, 0, key)  # ä»ä»»åŠ¡é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆå¯é€‰ï¼‰

	async def process_task(self, payload:dict, workid:int=None):
		sec = randint(0,5)
		await asyncio.sleep(sec)
		debug(f'{payload=} done')
		return {
			'result': 'OK'
		}

	async def start_redis(self):
		self.redis = await aioredis.from_url(self.redis_url, decode_responses=True)

	async def run(self):
		await self.start_redis()
		await self.cleanup_expired_tasks()
		schedule_interval(3600, self.cleanup_expired_tasks)
		schedule_interval(300, self.recover_stuck_tasks)
		workers = [asyncio.create_task(self.worker_loop(i)) for i in range(self.worker_cnt)]
		try:
			await asyncio.gather(*workers)
		except asyncio.CancelledError:
			for w in workers:
				w.cancel()
		finally:
			await self.redis.close()

	async def update_task_hash(self, task_id: str, mapping: Dict[str, Any]):
		# all values must be str
		# str_map = {k: json.dumps(v) if not isinstance(v, str) else v for k, v in mapping.items()}
		await self.set_redis_task(task_id, mapping)
	
	async def recover_stuck_tasks(self):
		"""
		å¯åŠ¨æ—¶æˆ–å®šæœŸè°ƒç”¨ï¼Œæ£€æŸ¥ processing_queue ä¸­å¯èƒ½å¡ä½çš„ä»»åŠ¡ï¼Œ
		å¦‚æœæŸä»»åŠ¡çš„ task:{id}.started_at è·ç°åœ¨ > self.stuck_secondsï¼Œåˆ™è®¤ä¸ºå¡ä½å¹¶é‡æ–°å…¥é˜Ÿæˆ–æ ‡è®°ä¸º failedã€‚
		"""
		# è¯»å–æ•´ä¸ª processing_queueï¼ˆæ³¨æ„ï¼šå½“é˜Ÿåˆ—éå¸¸å¤§æ—¶éœ€æ”¹æˆåˆ†é¡µï¼‰
		debug('recover_stuck_tasks() called')
		items = await self.redis.lrange(self.processing_queue, 0, -1)
		now = time.time()
		for task_id in items:
			info = await self.get_redis_task(task_id)
			if not info:
				# å¦‚æœ task hash ä¸å­˜åœ¨ï¼Œå¯é€‰æ‹©ç›´æ¥åˆ é™¤æˆ–é‡æ–° enqueue
				# è¿™é‡Œæˆ‘ä»¬é€‰æ‹©é‡æ–°å…¥é˜Ÿå¹¶åˆ é™¤ processing entry
				await self.redis.rpush(self.task_queue, task_id)
				await self.redis.lrem(self.processing_queue, 1, task_id)
				debug(f"[recover] requeued missing-hash {task_id}")
				continue

			started_at = float(info.get("started_at") or 0)
			status = info.get("status")
			if status == "RUNNING" and (now - started_at) > self.stuck_seconds:
				# ä»»åŠ¡å¡ä½ -> é‡æ–°å…¥é˜Ÿå¹¶æ›´æ–° attempts æˆ–ç›´æ¥æ ‡è®°å¤±è´¥
				# ç¤ºä¾‹ï¼šé‡æ–°å…¥é˜Ÿå¹¶å¢åŠ  attempts å­—æ®µ
				attempts = int(json.loads(info.get("attempts") or "0"))
				attempts += 1
				await self.update_task_hash(task_id, {"status": "PENDING", "attempts": attempts})
				await self.redis.rpush(self.task_queue, task_id)
				await self.redis.lrem(self.processing_queue, 1, task_id)
				debug(f"[recover] task {task_id} requeued due to stuck")
			# else: æ­£å¸¸ running æˆ–å…¶ä»–çŠ¶æ€ï¼Œä¸å¤„ç†

	async def worker_loop(self, worker_id: int):
		debug(f"[worker {worker_id}] start")
		while True:
			try:
				# BRPOPLPUSH: ä» task_queue å¼¹å‡ºï¼ˆé˜»å¡ï¼‰ï¼Œå¹¶ push åˆ° processing_queueï¼ˆåŸå­ï¼‰
				# aioredis: brpoplpush(source, destination, timeout)
				# debug(f"Before BRPOPLPUSH: {self.task_queue} length = {await self.redis.llen(self.task_queue)}")
				task_id = await self.redis.brpoplpush(self.task_queue, self.processing_queue, timeout=5)
				if not task_id:
					await asyncio.sleep(0.1)
					# debug(f'No task in task queue {self.task_queue=}, {self.processing_queue=}')
					# await self.repush_pending_task()
					continue
				else:
					debug(f'get task_id={task_id}')

				task_obj = await self.get_redis_task(task_id)
				payload = task_obj["payload"]

				# 1) æ›´æ–° task hash ä¸º runningï¼ˆè¿™ä¸€æ­¥å¾ˆé‡è¦ï¼šå®¢æˆ·ç«¯è¯»å–åˆ°çŠ¶æ€ï¼‰
				started_at = time.time()
				await self.update_task_hash(task_id, {
					"status": "RUNNING",
					"started_at": started_at,
					# optional: increment attempts
				})

				# 2) æ‰§è¡Œä»»åŠ¡ï¼ˆcatch exceptionsï¼‰
				try:
					result = await self.process_task(worker_id, payload)
				except asyncio.CancelledError:
					# è‹¥å¸Œæœ›æ”¯æŒå–æ¶ˆï¼Œå¯æŠŠ status è®¾ä¸º cancelling ç­‰
					await self.update_task_hash(task_id, {"status": "FAILED", "error": "cancelled"})
					# ç§»é™¤ processing_queue é¡¹ï¼ˆå·²å¤„ç†ï¼‰
					await self.redis.lrem(self.processing_queue, 1, task_id)
					continue
				except Exception as e:
					# å†™å›å¤±è´¥ä¿¡æ¯
					await self.update_task_hash(task_id, {
						"status": "FAILED",
						"error": str(e),
						"finished_at": time.time()
					})
					# ä» processing_queue ç§»é™¤è¯¥é¡¹
					await self.redis.lrem(self.processing_queue, 1, task_id)
					continue

				# 3) å†™å›æˆåŠŸç»“æœå¹¶ç§»é™¤ processing_queue é¡¹
				await self.update_task_hash(task_id, {
					"status": "SUCCEEDED",
					"result": result,
					"finished_at": time.time()
				})
				# æœ€åä¸€æ­¥ï¼šä» processing_queue ä¸­ç§»é™¤ä»»åŠ¡é¡¹ï¼ˆLREMï¼‰
				await self.redis.lrem(self.processing_queue, 1, task_id)
				debug(f"[worker {worker_id}] finished {task_id}")

			except asyncio.CancelledError:
				break
			except Exception as e:
				exception(f"[worker {worker_id}] loop error: {e}")
				await asyncio.sleep(1)

	async def submit_task(self, payload):
		taskid = getID()
		task_data = {
			"task_id": taskid,
			"status": "PENDING",
			"created_at": time.time(),
			"payload": json.dumps(payload)
		}
		await self.set_redis_task(taskid, task_data)
		await self.redis.rpush(self.task_queue, taskid)
		return {'task_id': taskid}
	
	async def all_taks_status(self):
		x = False
		async for key in self.redis.scan_iter(match=f"{self.taskname}:task:*"):
			taskid = key.split(':')[-1]
			task = await self.get_redis_task(taskid)
			print(f'{task}')
			x = True
		return x

	async def set_redis_task(self, taskid, task_data):
		str_map = {k: json.dumps(v) if not isinstance(v, str) else v for k, v in task_data.items()}
		await self.redis.hset(f"{self.taskname}:task:{taskid}", mapping=str_map)

	async def get_redis_task(self, taskid):
		task = await self.redis.hgetall(f'{self.taskname}:task:{taskid}')
		return task

	async def delete_redis_task(self, taskid):
		await self.redis.delete(f'{self.taskname}:task:{taskid}')

	async def get_status(self, taskid:str):
		task = await self.get_redis_task(taskid)
		if not task:
			return {'error': 'no task'}
		return task

if __name__ == '__main__':
	async def main(lt):
		for i in range(0, 10):
			payload = {
				"task": f"task {i}"
			}
			x = await lt.submit_task(payload)
		while True:
			x = await lt.all_taks_status()
			if not x:
				break
			print('\n')
			await asyncio.sleep(10)

	lt = LongTasks('redis://127.0.0.1:6379', 'test')
	loop = get_event_loop()
	loop.create_task(lt.run())
	loop.run_until_complete(main(lt))

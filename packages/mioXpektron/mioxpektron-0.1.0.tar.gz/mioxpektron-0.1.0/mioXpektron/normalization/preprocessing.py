# Data import function

import os
import glob
from pathlib import Path
from multiprocessing import Pool, cpu_count
from typing import List, Optional, Tuple

import numpy as np
import polars as pl

from ..utils.file_management import import_data
from .normalization import tic_normalization

def data_preprocessing(
        file_path,
        mz_min=None,
        mz_max=None,
        normalization_target=1e6,
        verbose=True,
        return_all=False
    ):
    """
    Import and preprocess ToF-SIMS data from a text file.

    Parameters:
    -----------
    file_path : str
        Path to the ToF-SIMS data file
    mz_min, mz_max : float, optional
        m/z range to import
    normalization_target : float or None
        Target TIC for normalization, or None to skip
    verbose : bool
        Print progress if True
    return_all : bool
        If True, return all intermediate arrays

    Returns:
    --------
    mz_values : numpy.ndarray
    normalized_intensities : numpy.ndarray
    sample_name : str
    group : str
    (optionally: intermediate arrays)
    """
    if not os.path.isfile(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    mz_values, intensity, sample_name, group = import_data(file_path, mz_min, mz_max)
    if verbose: print("Imported data:",sample_name, mz_values.shape, intensity.shape)

    # TIC normalization
    if normalization_target:
        normalized_intensities = tic_normalization(intensity, target_tic=normalization_target)
        if verbose: print("TIC normalized.")
    else:
        normalized_intensities = intensity

    if return_all:
        return (sample_name, group, mz_values,  
                intensity, normalized_intensities)
    else:
        return sample_name, group, mz_values, normalized_intensities


# Batch preprocessing helper
def batch_tic_norm(input_files: str,
                     output_dir: str = "normalized_spectra",
                     mz_min: float | None = None,
                     mz_max: float | None = None,
                     normalization_target: float | None = 1e6,
                     verbose: bool = False) -> list[str]:
    """
    Batch‑import and preprocess multiple ToF‑SIMS spectra, then save the
    (m/z, normalized_intensity) arrays for each file as a tab‑separated text
    file in *output_dir*.

    Parameters
    ----------
    input_pattern : str
        Glob pattern (e.g. 'spectra/*.txt') that expands to the input files.
    output_dir : str
        Folder where '<original‑name>_normalized.txt' will be written;
        created if it does not already exist.
    mz_min, mz_max, normalization_target, verbose
        Passed through to :pyfunc:`data_preprocessing`.
    Returns
    -------
    list[str]
        Paths of the files written, in processing order.
    """
    import glob
    import numpy as np

    files = sorted(glob.glob(input_files))
    if not files:
        raise FileNotFoundError(f"No files matched pattern '{input_files}'")

    os.makedirs(output_dir, exist_ok=True)

    written: list[str] = []
    for fp in files:
        sample_name, group, mz_vals, norm_intens = data_preprocessing(
            fp,
            mz_min=mz_min,
            mz_max=mz_max,
            normalization_target=normalization_target,
            verbose=verbose,
            return_all=False,
        )

        base = os.path.splitext(os.path.basename(fp))[0]
        out_path = os.path.join(output_dir, f"{base}_normalized.txt")

        np.savetxt(
            out_path,
            np.column_stack((mz_vals, norm_intens)),
            fmt="%.6f\t%.6e",
            header="m/z\tIntensity",
            comments=""
        )
        if verbose:
            print(f"Wrote {out_path}")
        written.append(out_path)

    return written


class BatchTicNorm:
    """
    Batch TIC normalization for multiple spectra files using Polars and multiprocessing.

    Supports both CSV and TXT file formats:
    - CSV: Uses 'corrected_intensity' if available, otherwise 'intensity'
    - TXT: Tab-separated m/z and intensity values

    Output files contain: channel, mz, intensity (normalized)
    """

    def __init__(
        self,
        input_pattern: str,
        output_dir: str = "normalized_spectra",
        normalization_target: float = 1e6,
        n_workers: int = 16,
        verbose: bool = True
    ):
        """
        Initialize BatchTicNorm processor.

        Parameters
        ----------
        input_pattern : str
            Glob pattern for input files (e.g., 'data/*.csv' or 'data/*.txt')
        output_dir : str
            Directory to save normalized files
        normalization_target : float
            Target TIC value for normalization (default: 1e6)
        n_workers : int
            Number of parallel workers (default: 16)
        verbose : bool
            Print progress information
        """
        self.input_pattern = input_pattern
        self.output_dir = Path(output_dir)
        self.normalization_target = normalization_target
        self.n_workers = min(n_workers, cpu_count())
        self.verbose = verbose

        # Create output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Find input files
        self.input_files = sorted(glob.glob(input_pattern))
        if not self.input_files:
            raise FileNotFoundError(f"No files matched pattern: {input_pattern}")

        if self.verbose:
            print(f"Found {len(self.input_files)} files to process")
            print(f"Using {self.n_workers} workers")

    def _read_file(self, file_path: str) -> pl.DataFrame:
        """
        Read a single file (CSV or TXT) and return a Polars DataFrame.

        Parameters
        ----------
        file_path : str
            Path to the input file

        Returns
        -------
        pl.DataFrame
            DataFrame with columns: channel, mz, intensity
        """
        file_ext = Path(file_path).suffix.lower()

        if file_ext == '.csv':
            # Read CSV file
            df = pl.read_csv(file_path)

            # Select intensity column (prefer corrected_intensity if available)
            if 'corrected_intensity' in df.columns:
                intensity_col = 'corrected_intensity'
            elif 'intensity' in df.columns:
                intensity_col = 'intensity'
            else:
                raise ValueError(f"No intensity column found in {file_path}")

            # Check if channel column exists
            if 'channel' not in df.columns:
                # Create channel column if missing
                df = df.with_row_index(name='channel')

            # Select and rename columns
            result = df.select([
                pl.col('channel'),
                pl.col('mz'),
                pl.col(intensity_col).alias('intensity')
            ])

        elif file_ext in ['.txt', '.tsv']:
            # Read TXT/TSV file (assumes tab-separated m/z and intensity)
            df = pl.read_csv(
                file_path,
                separator='\t',
                has_header=True,
                skip_rows_after_header=0
            )

            # If no header or only 2 columns, assume m/z and intensity
            if df.shape[1] == 2:
                df.columns = ['mz', 'intensity']

            # Add channel column
            result = df.with_row_index(name='channel').select([
                pl.col('channel'),
                pl.col('mz'),
                pl.col('intensity')
            ])

        else:
            raise ValueError(f"Unsupported file format: {file_ext}")

        return result

    def _normalize_single_file(self, file_path: str) -> Tuple[str, bool]:
        """
        Process and normalize a single file.

        Parameters
        ----------
        file_path : str
            Path to the input file

        Returns
        -------
        Tuple[str, bool]
            (output_path, success)
        """
        try:
            # Read file
            df = self._read_file(file_path)

            # Extract intensity as numpy array for normalization
            intensities = df['intensity'].to_numpy()

            # Perform TIC normalization
            normalized_intensities = tic_normalization(
                intensities,
                target_tic=self.normalization_target
            )

            # Create output DataFrame
            output_df = df.with_columns(
                pl.Series('intensity', normalized_intensities)
            )

            # Generate output path
            base_name = Path(file_path).stem
            output_path = self.output_dir / f"{base_name}_normalized.csv"

            # Write to CSV
            output_df.write_csv(output_path)

            if self.verbose:
                tic_before = np.sum(intensities)
                tic_after = np.sum(normalized_intensities)
                print(f"✓ {Path(file_path).name}: TIC {tic_before:.2e} → {tic_after:.2e}")

            return str(output_path), True

        except Exception as e:
            if self.verbose:
                print(f"✗ Error processing {Path(file_path).name}: {str(e)}")
            return "", False

    def process(self) -> List[str]:
        """
        Process all files using multiprocessing.

        Returns
        -------
        List[str]
            List of output file paths that were successfully created
        """
        if self.verbose:
            print(f"\nProcessing {len(self.input_files)} files...")
            print(f"Normalization target: {self.normalization_target:.2e}")
            print(f"Output directory: {self.output_dir}")
            print("-" * 60)

        # Process files in parallel
        with Pool(processes=self.n_workers) as pool:
            results = pool.map(self._normalize_single_file, self.input_files)

        # Collect successful outputs
        output_files = [path for path, success in results if success]

        if self.verbose:
            print("-" * 60)
            print(f"\nCompleted: {len(output_files)}/{len(self.input_files)} files normalized")
            print(f"Output location: {self.output_dir.absolute()}")

        return output_files

    def get_tic_statistics(self) -> pl.DataFrame:
        """
        Calculate TIC statistics for all input files before normalization.

        Returns
        -------
        pl.DataFrame
            DataFrame with columns: filename, tic_original, tic_million
        """
        stats = []

        for file_path in self.input_files:
            try:
                df = self._read_file(file_path)
                tic = df['intensity'].sum()
                stats.append({
                    'filename': Path(file_path).name,
                    'tic_original': tic,
                    'tic_million': tic / 1e6
                })
            except Exception as e:
                if self.verbose:
                    print(f"Error reading {file_path}: {e}")

        stats_df = pl.DataFrame(stats)

        if self.verbose and len(stats) > 0:
            print("\nTIC Statistics (before normalization):")
            print(f"  Mean TIC:   {stats_df['tic_million'].mean():.2f} Million")
            print(f"  Median TIC: {stats_df['tic_million'].median():.2f} Million")
            print(f"  Min TIC:    {stats_df['tic_million'].min():.2f} Million")
            print(f"  Max TIC:    {stats_df['tic_million'].max():.2f} Million")

        return stats_df

# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# pylint: disable=C0330, g-bad-import-order, g-multiple-import

"""Defines helper functions for media tagging entrypoints."""

import functools
import logging
import os

import pandas as pd
import pydantic
import smart_open

from media_tagging import exceptions


class InputConfig(pydantic.BaseModel):
  """Parameters for reading media urls from a file.

  Attributes:
    path: Path to a file that contains media urls (either CSV or txt).
    column_name: Column name in a file that contains media_urls.
    skip_rows: Number of rows to skip in a file.
  """

  model_config = pydantic.ConfigDict(extra='ignore')

  path: os.PathLike[str] | str
  column_name: str | None = None
  skip_rows: int = 0


def get_media_paths_from_file(input_config: InputConfig) -> set[str]:
  """Reads media urls from a file and returns unique ones.

  Args:
    input_config: Config for reading data from a file.

  Returns:
    Unique media urls.

  Raises:
    MediaTaggingError:
      When specified column with media_urls is not found
      or too many rows skipped.
  """
  if str(input_config.path).endswith('.txt'):
    with smart_open.open(input_config.path, 'r', encoding='utf-8') as f:
      data = f.readlines()
    if skip_rows := input_config.skip_rows:
      if skip_rows < len(data):
        raise exceptions.MediaTaggingError(
          f'Skipping too many rows, data has {len(data)} rows, '
          f'skipping {skip_rows}'
        )
      data = data[skip_rows:]
    return {url.strip() for url in data}

  data = pd.read_csv(
    smart_open.open(input_config.path), skiprows=input_config.skip_rows
  )
  if len(data.columns) == 1:
    column_name = data.columns[0]
  elif (column_name := input_config.column_name) not in data.columns:
    raise exceptions.MediaTaggingError(f'Column {column_name} not found')
  return set(data[column_name].tolist())


def parse_typer_arguments(
  arguments: list[str] | None,
) -> tuple[list[str], list[str]]:
  if not arguments:
    return [], []
  found_arguments = []
  parameters = []
  for argument in arguments:
    if argument.startswith('--'):
      parameters.append(argument)
    else:
      found_arguments.append(argument)
  return found_arguments, parameters


def log_shutdown(func):
  @functools.wraps(func)
  def fn(*args, **kwargs):
    func(*args, **kwargs)
    logging.shutdown()

  return fn

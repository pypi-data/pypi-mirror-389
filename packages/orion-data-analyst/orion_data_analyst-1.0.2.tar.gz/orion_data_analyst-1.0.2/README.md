# Orion - Data Analysis LangGraph Agent

An AI-powered Data Analysis Agent that connects to Google BigQuery's public e-commerce dataset and performs intelligent data exploration through natural language interaction.

ðŸ”— **Repository**: https://github.com/gavrielhan/orion-data-analyst

## Overview

Orion is an intelligent business analyst that:
- Connects to BigQuery's `thelook_ecommerce` dataset
- Generates dynamic SQL queries from natural language
- Performs statistical analysis and data visualization
- Provides actionable business insights

## Architecture

Built with **LangGraph**, Orion uses a modular node-based architecture:

```
User Query â†’ InputNode â†’ QueryBuilderNode â†’ BigQueryExecutorNode â†’ OutputNode
```

Each node handles a distinct analytical step, creating a directed graph of reasoning.

## Features (MVP)

âœ… Natural language query processing  
âœ… Dynamic SQL generation with Gemini via Vertex AI  
âœ… BigQuery integration  
âœ… Basic result display  
âœ… CLI interface  

## Setup

### Prerequisites

- Python 3.10+
- Google account for Google Cloud and Gemini API access

### Quick Start

1. **Install dependencies**:
```bash
pip install -r requirements.txt
```

2. **Get your API keys** - Follow this guide:
   - **ðŸ‘‰ [GETTING_KEYS.md](GETTING_KEYS.md) - Start here!** 
   
   Or see [SETUP.md](SETUP.md) for detailed setup instructions.

3. **Configure your `.env` file**:
```bash
cp .env.example .env
# Edit .env with your credentials
```

4. **Run Orion**:
```bash
python -m src.cli
```

## Usage

Start the interactive CLI:

```bash
python -m src.cli
```

Example queries:
- "What are total sales?"
- "Show me the number of orders by status"
- "List the top 10 products by revenue"

## Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                 # Command-line interface
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ graph.py          # LangGraph orchestration
â”‚   â”‚   â”œâ”€â”€ nodes.py          # All agent nodes
â”‚   â”‚   â””â”€â”€ state.py          # Agent state management
â”‚   â”œâ”€â”€ config.py             # Configuration loader
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ bigquery.py       # BigQuery utilities
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Dataset

The project uses Google BigQuery's public e-commerce dataset:
- **Dataset**: `bigquery-public-data.thelook_ecommerce`
- **Tables**: orders, order_items, products, users

## Development

Run tests:
```bash
pytest tests/
```

## License

MIT

## Roadmap

- [x] Milestone 1: Foundation & Happy Path MVP
- [ ] Milestone 2: Validation & Error Handling
- [ ] Milestone 3: Advanced Analysis & Visualization
- [ ] Milestone 4: Conversation Memory
- [ ] Milestone 5: Production Readiness

